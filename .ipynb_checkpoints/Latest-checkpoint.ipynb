{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7db9985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2675bd3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_excel('Course Project - Data for Classification - Electric Vehicles.xls')\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7593525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23070e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df['Q16'].unique()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f0af2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Q16'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5a39c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd25157f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q11_1</th>\n",
       "      <th>Q11_2</th>\n",
       "      <th>Q11_3</th>\n",
       "      <th>Q11_4</th>\n",
       "      <th>Q11_5</th>\n",
       "      <th>Q11_6</th>\n",
       "      <th>Q11_7</th>\n",
       "      <th>Q11_8</th>\n",
       "      <th>Q11_9</th>\n",
       "      <th>Q11_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q18_17</th>\n",
       "      <th>Q18_18</th>\n",
       "      <th>Q18_19</th>\n",
       "      <th>Q18_20</th>\n",
       "      <th>Q18_21</th>\n",
       "      <th>Q18_22</th>\n",
       "      <th>Q18_23</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q11_1  Q11_2  Q11_3  Q11_4  Q11_5  Q11_6  Q11_7  Q11_8  Q11_9  Q11_10  ...  \\\n",
       "0      0      0      0      1      1      0      0      1      0       0  ...   \n",
       "1      1      0      0      1      0      0      1      0      0       1  ...   \n",
       "2      1      1      0      1      0      0      1      1      0       1  ...   \n",
       "3      0      0      0      0      0      0      0      0      0       0  ...   \n",
       "4      1      1      0      1      0      0      1      1      0       1  ...   \n",
       "\n",
       "   Q18_17  Q18_18  Q18_19  Q18_20  Q18_21  Q18_22  Q18_23  Q20  Q21  Q16  \n",
       "0     5.0     5.0     5.0     5.0     5.0     5.0     5.0    3    3    A  \n",
       "1     4.0     2.0     4.0     2.0     2.0     2.0     2.0    3    3    D  \n",
       "2     4.0     4.0     NaN     NaN     4.0     2.0     4.0    4    1    A  \n",
       "3     NaN     NaN     NaN     NaN     NaN     NaN     NaN    3    3    C  \n",
       "4     NaN     NaN     1.0     1.0     NaN     NaN     NaN    3    3    D  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace non-numeric values with NaN\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36ed904e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.impute import KNNImputer\\n\\nexclude_column_name = 'Q16'\\ncolumn_to_exclude = df[exclude_column_name]\\n\\n# Create a list of k values\\nk_values = [1, 3, 5, 7, 9,11]\\n\\n# Loop through each k value\\nfor k in k_values:\\n    # Drop the column you want to exclude\\n    columns_to_impute = df.drop(columns=[exclude_column_name])\\n    \\n    # Apply KNN imputation for the current k value\\n    imputer = KNNImputer(n_neighbors=k)\\n    imputed_data = imputer.fit_transform(columns_to_impute)\\n    \\n    \\n    imputed_df = pd.DataFrame(imputed_data, columns=columns_to_impute.columns)\\n    imputed_df[exclude_column_name] = column_to_exclude\\n\\nimputed_df.head()\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.impute import KNNImputer\n",
    "\n",
    "exclude_column_name = 'Q16'\n",
    "column_to_exclude = df[exclude_column_name]\n",
    "\n",
    "# Create a list of k values\n",
    "k_values = [1, 3, 5, 7, 9,11]\n",
    "\n",
    "# Loop through each k value\n",
    "for k in k_values:\n",
    "    # Drop the column you want to exclude\n",
    "    columns_to_impute = df.drop(columns=[exclude_column_name])\n",
    "    \n",
    "    # Apply KNN imputation for the current k value\n",
    "    imputer = KNNImputer(n_neighbors=k)\n",
    "    imputed_data = imputer.fit_transform(columns_to_impute)\n",
    "    \n",
    "    \n",
    "    imputed_df = pd.DataFrame(imputed_data, columns=columns_to_impute.columns)\n",
    "    imputed_df[exclude_column_name] = column_to_exclude\n",
    "\n",
    "imputed_df.head()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "273caba3-4506-4a95-9c97-086c89b07519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Replace '?' with NaN for proper handling\n",
    "df.replace('?', pd.NA, inplace=True)\n",
    "original_df = df.copy()\n",
    "# Specify the imputation strategy (mean or median)\n",
    "strategy = 'mean'  # or 'median'\n",
    "df = df.drop(columns=['Q16'])\n",
    "# Create the imputer\n",
    "imputer = SimpleImputer(strategy=strategy)\n",
    "\n",
    "# Apply imputation\n",
    "imputed_data = imputer.fit_transform(df)\n",
    "\n",
    "# Convert the result back to a DataFrame\n",
    "imputed_df = pd.DataFrame(imputed_data, columns=df.columns)\n",
    "imputed_df['Q16'] = original_df['Q16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe1c6427-068b-4fa1-96bb-bad6d7fcb6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked Features:\n",
      "Q17       0.224561\n",
      "Q14       0.206916\n",
      "Q18_1     0.147273\n",
      "Q21       0.140421\n",
      "Q18_14    0.132706\n",
      "            ...   \n",
      "Q11_11    0.000000\n",
      "Q11_12    0.000000\n",
      "Q12_11    0.000000\n",
      "Q11_2     0.000000\n",
      "Q11_1     0.000000\n",
      "Length: 74, dtype: float64\n",
      "Ranked Features:\n",
      "Q17              0.224561\n",
      "Q14              0.206916\n",
      "Q18_1            0.147273\n",
      "Q21              0.140421\n",
      "Q18_14           0.132706\n",
      "Q12_14           0.131629\n",
      "Q13_16           0.109409\n",
      "Q18_2            0.087651\n",
      "Q18_8            0.087258\n",
      "Q18_3            0.085064\n",
      "Q18_13           0.084805\n",
      "Q18_15           0.083066\n",
      "Q18_10           0.079679\n",
      "Q18_17           0.075503\n",
      "Q18_9            0.072702\n",
      "Q18_4            0.068149\n",
      "Q18_19           0.060458\n",
      "Q18_16           0.059305\n",
      "Q18_6            0.059277\n",
      "Q18_23           0.059258\n",
      "Q18_21           0.058283\n",
      "Q18_7            0.055852\n",
      "Q18_20           0.053579\n",
      "Q18_12           0.046462\n",
      "Q18_11           0.046268\n",
      "Q13_7            0.045927\n",
      "Q18_5            0.044511\n",
      "Q18_22           0.040771\n",
      "Q13_Dont_Know    0.040609\n",
      "Q18_18           0.040368\n",
      "Q15              0.039124\n",
      "Q12_4            0.038199\n",
      "Q11_Dont_Know    0.038166\n",
      "Q11_5            0.030830\n",
      "Q20              0.030348\n",
      "Q13_2            0.029885\n",
      "Q12_3            0.027957\n",
      "Q13_5            0.025754\n",
      "Q12_10           0.025024\n",
      "Q12_Dont_Know    0.024379\n",
      "Q12_5            0.024085\n",
      "Q11_3            0.023650\n",
      "Q13_10           0.022009\n",
      "Q13_6            0.021949\n",
      "Q13_1            0.021367\n",
      "Q11_13           0.020154\n",
      "Q13_3            0.019973\n",
      "Q12_1            0.019139\n",
      "Q12_7            0.017506\n",
      "Q13_14           0.017094\n",
      "Q12_2            0.015975\n",
      "Q12_12           0.015846\n",
      "Q13_9            0.013057\n",
      "Q11_6            0.012240\n",
      "Q13_12           0.011124\n",
      "Q12_9            0.010852\n",
      "Q11_7            0.010820\n",
      "Q13_13           0.008095\n",
      "Q13_15           0.007999\n",
      "Q11_10           0.006367\n",
      "Q11_8            0.006198\n",
      "Q12_6            0.005346\n",
      "Q11_4            0.004784\n",
      "Q13_11           0.001431\n",
      "Q13_8            0.001334\n",
      "Q12_13           0.001296\n",
      "Q13_4            0.001252\n",
      "Q11_9            0.000523\n",
      "Q12_8            0.000000\n",
      "Q11_11           0.000000\n",
      "Q11_12           0.000000\n",
      "Q12_11           0.000000\n",
      "Q11_2            0.000000\n",
      "Q11_1            0.000000\n",
      "dtype: float64\n",
      "Non-zero Mutual Information Scores for Features:\n",
      "Q17              0.224561\n",
      "Q14              0.206916\n",
      "Q18_1            0.147273\n",
      "Q21              0.140421\n",
      "Q18_14           0.132706\n",
      "Q12_14           0.131629\n",
      "Q13_16           0.109409\n",
      "Q18_2            0.087651\n",
      "Q18_8            0.087258\n",
      "Q18_3            0.085064\n",
      "Q18_13           0.084805\n",
      "Q18_15           0.083066\n",
      "Q18_10           0.079679\n",
      "Q18_17           0.075503\n",
      "Q18_9            0.072702\n",
      "Q18_4            0.068149\n",
      "Q18_19           0.060458\n",
      "Q18_16           0.059305\n",
      "Q18_6            0.059277\n",
      "Q18_23           0.059258\n",
      "Q18_21           0.058283\n",
      "Q18_7            0.055852\n",
      "Q18_20           0.053579\n",
      "Q18_12           0.046462\n",
      "Q18_11           0.046268\n",
      "Q13_7            0.045927\n",
      "Q18_5            0.044511\n",
      "Q18_22           0.040771\n",
      "Q13_Dont_Know    0.040609\n",
      "Q18_18           0.040368\n",
      "Q15              0.039124\n",
      "Q12_4            0.038199\n",
      "Q11_Dont_Know    0.038166\n",
      "Q11_5            0.030830\n",
      "Q20              0.030348\n",
      "Q13_2            0.029885\n",
      "Q12_3            0.027957\n",
      "Q13_5            0.025754\n",
      "Q12_10           0.025024\n",
      "Q12_Dont_Know    0.024379\n",
      "Q12_5            0.024085\n",
      "Q11_3            0.023650\n",
      "Q13_10           0.022009\n",
      "Q13_6            0.021949\n",
      "Q13_1            0.021367\n",
      "Q11_13           0.020154\n",
      "Q13_3            0.019973\n",
      "Q12_1            0.019139\n",
      "Q12_7            0.017506\n",
      "Q13_14           0.017094\n",
      "Q12_2            0.015975\n",
      "Q12_12           0.015846\n",
      "Q13_9            0.013057\n",
      "Q11_6            0.012240\n",
      "Q13_12           0.011124\n",
      "Q12_9            0.010852\n",
      "Q11_7            0.010820\n",
      "Q13_13           0.008095\n",
      "Q13_15           0.007999\n",
      "Q11_10           0.006367\n",
      "Q11_8            0.006198\n",
      "Q12_6            0.005346\n",
      "Q11_4            0.004784\n",
      "Q13_11           0.001431\n",
      "Q13_8            0.001334\n",
      "Q12_13           0.001296\n",
      "Q13_4            0.001252\n",
      "dtype: float64\n",
      "        Q17       Q14     Q18_1  Q21    Q18_14  Q12_14  Q13_16     Q18_2  \\\n",
      "0  3.000000  1.000000  5.000000  3.0  5.000000     0.0     0.0  5.000000   \n",
      "1  3.000000  3.000000  4.000000  3.0  4.000000     0.0     0.0  3.000000   \n",
      "2  1.000000  1.000000  5.000000  1.0  4.000000     0.0     0.0  3.555279   \n",
      "3  2.182072  2.383222  3.479726  3.0  3.280962     1.0     1.0  3.555279   \n",
      "4  2.182072  2.383222  3.479726  3.0  3.280962     0.0     0.0  4.000000   \n",
      "\n",
      "      Q18_8     Q18_3  ...  Q13_15  Q11_10  Q11_8  Q12_6  Q11_4  Q13_11  \\\n",
      "0  5.000000  5.000000  ...     0.0     0.0    1.0    0.0    1.0     0.0   \n",
      "1  3.000000  2.000000  ...     0.0     1.0    0.0    0.0    1.0     1.0   \n",
      "2  4.000000  4.000000  ...     0.0     1.0    1.0    0.0    1.0     0.0   \n",
      "3  3.185137  3.276596  ...     0.0     0.0    0.0    0.0    0.0     0.0   \n",
      "4  3.185137  3.276596  ...     0.0     1.0    1.0    0.0    1.0     0.0   \n",
      "\n",
      "   Q13_8  Q12_13  Q13_4  Q16  \n",
      "0    0.0     0.0    0.0    A  \n",
      "1    0.0     0.0    0.0    D  \n",
      "2    0.0     0.0    0.0    A  \n",
      "3    0.0     0.0    0.0    C  \n",
      "4    0.0     0.0    0.0    D  \n",
      "\n",
      "[5 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "###MUTUAL INFO\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "target_column = 'Q16'\n",
    "threshold = 0.01  # Set your desired correlation threshold\n",
    "\n",
    "# Copy the DataFrame to avoid modifying the original\n",
    "imputed_df_copy = imputed_df.copy()\n",
    "\n",
    "# Use mutual_info_classif for feature selection with categorical target\n",
    "X = imputed_df_copy.drop(columns=[target_column])\n",
    "y = imputed_df_copy[target_column]\n",
    "\n",
    "# Calculate mutual information between features and target\n",
    "mutual_info_values = mutual_info_classif(X, y)\n",
    "\n",
    "# Create a Series with feature names and their mutual information scores\n",
    "feature_mutual_info = pd.Series(mutual_info_values, index=X.columns)\n",
    "\n",
    "# Select features based on the mutual information threshold\n",
    "selected_features = feature_mutual_info[feature_mutual_info > threshold].index.tolist()\n",
    "\n",
    "# Rank features by mutual information scores\n",
    "ranked_features = feature_mutual_info.sort_values(ascending=False)\n",
    "\n",
    "# Display the ranked features\n",
    "print(\"Ranked Features:\")\n",
    "print(ranked_features)\n",
    "\n",
    "# Set pandas display options to show all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Print the ranked features\n",
    "print(\"Ranked Features:\")\n",
    "print(ranked_features)\n",
    "\n",
    "\n",
    "non_zero_features = ranked_features[ranked_features >= 0.001]\n",
    "\n",
    "# Display non-zero features and their mutual information scores\n",
    "print(\"Non-zero Mutual Information Scores for Features:\")\n",
    "print(non_zero_features)\n",
    "pd.reset_option('display.max_rows')\n",
    "\n",
    "non_zero_columns = non_zero_features.index.tolist()\n",
    "\n",
    "# Create a new DataFrame with only the non-zero columns\n",
    "new_df = imputed_df[non_zero_columns].copy()\n",
    "new_df['Q16'] = imputed_df['Q16']\n",
    "print(new_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0883737f-abc1-493c-9374-b70638af2cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q17</th>\n",
       "      <th>Q14</th>\n",
       "      <th>Q18_1</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q18_14</th>\n",
       "      <th>Q12_14</th>\n",
       "      <th>Q13_16</th>\n",
       "      <th>Q18_2</th>\n",
       "      <th>Q18_8</th>\n",
       "      <th>Q18_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Q13_15</th>\n",
       "      <th>Q11_10</th>\n",
       "      <th>Q11_8</th>\n",
       "      <th>Q12_6</th>\n",
       "      <th>Q11_4</th>\n",
       "      <th>Q13_11</th>\n",
       "      <th>Q13_8</th>\n",
       "      <th>Q12_13</th>\n",
       "      <th>Q13_4</th>\n",
       "      <th>Q16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q17  Q14  Q18_1  Q21  Q18_14  Q12_14  Q13_16  Q18_2  Q18_8  Q18_3  ...  \\\n",
       "0  0.0  0.0    1.0  0.0     1.0     0.0     0.0    1.0    1.0    1.0  ...   \n",
       "1  0.0  0.0    0.0  0.0     0.0     0.0     0.0    0.0    0.0    0.0  ...   \n",
       "2  0.0  0.0    1.0  0.0     0.0     0.0     0.0    0.0    0.0    0.0  ...   \n",
       "3  0.0  0.0    0.0  0.0     0.0     1.0     1.0    0.0    0.0    0.0  ...   \n",
       "4  0.0  0.0    0.0  0.0     0.0     0.0     0.0    0.0    0.0    0.0  ...   \n",
       "\n",
       "   Q13_15  Q11_10  Q11_8  Q12_6  Q11_4  Q13_11  Q13_8  Q12_13  Q13_4  Q16  \n",
       "0     0.0     0.0    1.0    0.0    1.0     0.0    0.0     0.0    0.0    A  \n",
       "1     0.0     1.0    0.0    0.0    1.0     1.0    0.0     0.0    0.0    D  \n",
       "2     0.0     1.0    1.0    0.0    1.0     0.0    0.0     0.0    0.0    A  \n",
       "3     0.0     0.0    0.0    0.0    0.0     0.0    0.0     0.0    0.0    C  \n",
       "4     0.0     1.0    1.0    0.0    1.0     0.0    0.0     0.0    0.0    D  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()\n",
    "scaled_columns = new_df.iloc[:, :-1].apply(lambda x: (x - x.min()) / (x.max() - x.min()) if pd.api.types.is_numeric_dtype(x) else x, axis=0)\n",
    "\n",
    "# Concatenate the original DataFrame with the scaled columns\n",
    "new_df = pd.concat([scaled_columns, new_df['Q16']], axis=1)\n",
    "\n",
    "# Convert values to binary (0 or 1) based on the condition\n",
    "new_df.iloc[:, :-1] = new_df.iloc[:, :-1].apply(lambda x: x.map(lambda val: 1 if pd.notna(val) and float(val) > 0.80 else 0))\n",
    "\n",
    "# Convert to integer to make them binary\n",
    "new_df.iloc[:, :-1] = new_df.iloc[:, :-1].astype(float)\n",
    "\n",
    "\n",
    "new_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f6f6ad-7ec5-488b-a152-3c9c0319ecf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts:\n",
      "Q16\n",
      "A    2883\n",
      "B    1526\n",
      "C     892\n",
      "D     807\n",
      "Name: count, dtype: int64\n",
      "Class Counts after outlier:\n",
      "Q16\n",
      "A    1789\n",
      "B     785\n",
      "D     342\n",
      "C     227\n",
      "Name: count, dtype: int64\n",
      "Class Counts after SMOTE:\n",
      "Q16\n",
      "A    1789\n",
      "D    1789\n",
      "B    1789\n",
      "C    1789\n",
      "Name: count, dtype: int64\n",
      "Model Accuracy: 0.7849\n",
      "Confusion Matrix:\n",
      " [[209  68  10  61]\n",
      " [ 36 241  26  58]\n",
      " [  1   1 328  21]\n",
      " [  9   9   8 346]]\n",
      "Precision: 0.7907\n",
      "Recall: 0.7849\n",
      "F1-score: 0.7791\n",
      "ROC AUC: 0.9496\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, RobustScaler\n",
    "from scipy import stats\n",
    "\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "print(\"Class Counts:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Aykırı değerleri ele //\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "\n",
    "print(\"Class Counts after outlier:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Genişletilmiş özellik setini oluştur\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X = poly.fit_transform(X)\n",
    "\n",
    "# Özellikleri RobustScaler ile ölçeklendirme\n",
    "scaler = RobustScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Apply SMOTE to the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X, y = smote.fit_resample(X, y)\n",
    "print(\"Class Counts after SMOTE:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "#previosly calculated class weights\n",
    "class_weight_dict = {'A': 0.5246993127147767, 'B': 1.0078382838283828, 'C': 1.6918282548476453, 'D': 1.9575320512820513}\n",
    "\n",
    "# Veriyi train ve test setlerine ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create RandomForestClassifier with the best parameters\n",
    "rf_classifier = RandomForestClassifier(max_depth= 10, min_samples_leaf= 2, min_samples_split= 5, n_estimators= 200, class_weight=class_weight_dict)\n",
    "\n",
    "# Modeli eğitin\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Precision, Recall, and F1-score\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# Area under the ROC curve\n",
    "# Note: For multi-class classification, you need to use one-hot encoded labels or a binary problem\n",
    "# Here, assuming binary classification for demonstration\n",
    "roc_auc = roc_auc_score(y_test, rf_classifier.predict_proba(X_test), multi_class='ovr')\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "\n",
    "# Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_accuracy = cross_val_score(rf_classifier, X, y, cv=cv, scoring='accuracy')\n",
    "cv_precision = cross_val_score(rf_classifier, X, y, cv=cv, scoring='precision_weighted')\n",
    "cv_recall = cross_val_score(rf_classifier, X, y, cv=cv, scoring='recall_weighted')\n",
    "cv_f1 = cross_val_score(rf_classifier, X, y, cv=cv, scoring='f1_weighted')\n",
    "\n",
    "print(f\"Cross-Validation Accuracy: {cv_accuracy.mean():.4f}\")\n",
    "print(f\"Cross-Validation Precision: {cv_precision.mean():.4f}\")\n",
    "print(f\"Cross-Validation Recall: {cv_recall.mean():.4f}\")\n",
    "print(f\"Cross-Validation F1-score: {cv_f1.mean():.4f}\")\n",
    "\n",
    "print(f\"Cross-Validation ROC AUC: {cv_roc_auc.mean():.4f}\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming 'y' is your target variable\n",
    "sns.countplot(x='Q16', data=imputed_df)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c268ba2a-677c-4459-85f9-dfe0e1edb403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "# Assuming imputed_df is your DataFrame\n",
    "\n",
    "# Generate a synthetic imbalanced dataset for demonstration purposes\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identify categorical features indices (assuming Q16 is categorical)\n",
    "categorical_features = X.columns.tolist()\n",
    "\n",
    "# Apply SMOTE-NC to address class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "# Define class weights for models that support it\n",
    "class_weight_dict = {'A': 0.5246993127147767, 'B': 1.0078382838283828, 'C': 1.6918282548476453, 'D': 1.9575320512820513}\n",
    "\n",
    "# Create and train various classifiers\n",
    "classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(class_weight=class_weight_dict, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "    'SVM': SVC(class_weight=class_weight_dict, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(class_weight=class_weight_dict, random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Neural Network': MLPClassifier(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate classifiers\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    clf.fit(X_train_resampled, y_train_resampled)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Evaluate using multiple metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e88f40-05bc-4e4c-a72f-2e0214a31c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "# Aykırı değerleri ele\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "\n",
    "# Genişletilmiş özellik setini oluştur\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Özellikleri RobustScaler ile ölçeklendirme\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_poly)\n",
    "\n",
    "# Veriyi train ve test setlerine ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression modeli\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# RFECV'yi kullanarak özellik seçimi yapın\n",
    "rfecv = RFECV(estimator=logreg, step=1, cv=5, scoring='accuracy')  # cv=5, 5-fold cross-validation kullanıyoruz\n",
    "X_train_rfecv = rfecv.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eğitin\n",
    "logreg.fit(X_train_rfecv, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "X_test_rfecv = rfecv.transform(X_test)\n",
    "y_pred = logreg.predict(X_test_rfecv)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Model Accuracy with RFECV: {accuracy:.4f}\")\n",
    "\n",
    "# Modelin performansını 5 katlı çapraz doğrulama ile değerlendirin\n",
    "cv_scores = cross_val_score(logreg, X_train_rfecv, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = cv_scores.mean()\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d767b487-8642-4e64-bd93-881c1e521545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression modeli\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# RFECV'yi kullanarak özellik seçimi yapın\n",
    "rfecv = RFECV(estimator=logreg, step=1, cv=5, scoring='accuracy')  # cv=5, 5-fold cross-validation kullanıyoruz\n",
    "X_train_rfecv = rfecv.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eğitin\n",
    "logreg.fit(X_train_rfecv, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "X_test_rfecv = rfecv.transform(X_test)\n",
    "y_pred = logreg.predict(X_test_rfecv)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Model Accuracy with RFECV: {accuracy:.4f}\")\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_rfecv)\n",
    "X_test_scaled = scaler.transform(X_test_rfecv)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "y_pred_scaled = logreg.predict(X_test_scaled)\n",
    "\n",
    "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
    "print(f\"Logistic Regression Model Accuracy with RFECV and Scaling: {accuracy_scaled:.4f}\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Model Accuracy: {accuracy_rf:.4f}\")\n",
    "\n",
    "# Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "print(f\"Gradient Boosting Model Accuracy: {accuracy_gb:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9afc2e-686a-469c-b5fa-95bc98a284c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression modeli\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# RFECV'yi kullanarak özellik seçimi yapın\n",
    "rfecv = RFECV(estimator=logreg, step=1, cv=5, scoring='accuracy')  # cv=5, 5-fold cross-validation kullanıyoruz\n",
    "X_train_rfecv = rfecv.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eğitin\n",
    "logreg.fit(X_train_rfecv, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "X_test_rfecv = rfecv.transform(X_test)\n",
    "y_pred = logreg.predict(X_test_rfecv)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Model Accuracy with RFECV: {accuracy:.4f}\")\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_rfecv)\n",
    "X_test_scaled = scaler.transform(X_test_rfecv)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "y_pred_scaled = logreg.predict(X_test_scaled)\n",
    "\n",
    "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
    "print(f\"Logistic Regression Model Accuracy with RFECV and Scaling: {accuracy_scaled:.4f}\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Model Accuracy with MinMax Scaling: {accuracy_rf:.4f}\")\n",
    "\n",
    "# Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "print(f\"Gradient Boosting Model Accuracy with MinMax Scaling: {accuracy_gb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a1ce8d-1885-4cd1-922b-c6aac67d6f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "\n",
    "\n",
    "# Extract features and target variable\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "##################################################################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have already calculated class weights\n",
    "class_weight_dict = {'A': 0.5246993127147767, 'B': 1.0078382838283828, 'C': 1.6918282548476453, 'D': 1.9575320512820513}\n",
    "class_counts = Counter(y)\n",
    "weighted_counts_df = pd.DataFrame({'Class': list(class_counts.keys()), 'Weighted Count': [class_counts[class_] * weight for class_, weight in class_weight_dict.items()]})\n",
    "print(\"\\nWeighted Class Counts:\")\n",
    "print(weighted_counts_df)\n",
    "# Random Forest Classifier with class weights\n",
    "rf_classifier = RandomForestClassifier(random_state=42, class_weight=class_weight_dict)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy with Class Weights: {accuracy_rf:.4f}\")\n",
    "\n",
    "# Support Vector Classifier (SVC) with class weights\n",
    "svc_classifier = SVC(random_state=42, class_weight=class_weight_dict)\n",
    "svc_classifier.fit(X_train, y_train)\n",
    "y_pred_svc = svc_classifier.predict(X_test)\n",
    "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
    "print(f\"SVC Accuracy with Class Weights: {accuracy_svc:.4f}\")\n",
    "\n",
    "##################################################################\n",
    "\n",
    "\n",
    "# Logistic Regression modeli\n",
    "logreg = LogisticRegression(max_iter=1000, class_weight=class_weight_dict)\n",
    "\n",
    "# RFECV'yi kullanarak özellik seçimi yapın\n",
    "rfecv = RFECV(estimator=logreg, step=1, cv=5, scoring='accuracy')  # cv=5, 5-fold cross-validation kullanıyoruz\n",
    "X_train_rfecv = rfecv.fit_transform(X_train, y_train)\n",
    "\n",
    "quantile_transformer = QuantileTransformer(output_distribution='normal',random_state=0)\n",
    "X_train_quantile = quantile_transformer.fit_transform(X_train_rfecv)\n",
    "X_test_quantile = quantile_transformer.transform(rfecv.transform(X_test))\n",
    "\n",
    "\n",
    "# Modeli eğitin\n",
    "logreg.fit(X_train_quantile, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "X_test_rfecv = rfecv.transform(X_test)\n",
    "y_pred = logreg.predict(X_test_quantile)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Model Accuracy with RFECV: {accuracy:.4f}\")\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_quantile)\n",
    "X_test_scaled = scaler.transform(X_test_quantile)\n",
    "\n",
    "\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "y_pred_scaled = logreg.predict(X_test_scaled)\n",
    "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
    "print(f\"Logistic Regression Model Accuracy with RFECV and Scaling: {accuracy_scaled:.4f}\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Model Accuracy with MinMax Scaling: {accuracy_rf:.4f}\")\n",
    "\n",
    "# Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test_scaled)\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "print(f\"Gradient Boosting Model Accuracy with MinMax Scaling: {accuracy_gb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0758ec-2671-4a03-9013-e2be640cad7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
