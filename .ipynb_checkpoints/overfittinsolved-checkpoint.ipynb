{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e7db9985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2675bd3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q11_1</th>\n",
       "      <th>Q11_2</th>\n",
       "      <th>Q11_3</th>\n",
       "      <th>Q11_4</th>\n",
       "      <th>Q11_5</th>\n",
       "      <th>Q11_6</th>\n",
       "      <th>Q11_7</th>\n",
       "      <th>Q11_8</th>\n",
       "      <th>Q11_9</th>\n",
       "      <th>Q11_10</th>\n",
       "      <th>Q11_11</th>\n",
       "      <th>Q11_12</th>\n",
       "      <th>Q11_13</th>\n",
       "      <th>Q11_Dont_Know</th>\n",
       "      <th>Q12_1</th>\n",
       "      <th>Q12_2</th>\n",
       "      <th>Q12_3</th>\n",
       "      <th>Q12_4</th>\n",
       "      <th>Q12_5</th>\n",
       "      <th>Q12_6</th>\n",
       "      <th>Q12_7</th>\n",
       "      <th>Q12_8</th>\n",
       "      <th>Q12_9</th>\n",
       "      <th>Q12_10</th>\n",
       "      <th>Q12_11</th>\n",
       "      <th>Q12_12</th>\n",
       "      <th>Q12_13</th>\n",
       "      <th>Q12_14</th>\n",
       "      <th>Q12_Dont_Know</th>\n",
       "      <th>Q13_1</th>\n",
       "      <th>Q13_2</th>\n",
       "      <th>Q13_3</th>\n",
       "      <th>Q13_4</th>\n",
       "      <th>Q13_5</th>\n",
       "      <th>Q13_6</th>\n",
       "      <th>Q13_7</th>\n",
       "      <th>Q13_8</th>\n",
       "      <th>Q13_9</th>\n",
       "      <th>Q13_10</th>\n",
       "      <th>Q13_11</th>\n",
       "      <th>Q13_12</th>\n",
       "      <th>Q13_13</th>\n",
       "      <th>Q13_14</th>\n",
       "      <th>Q13_15</th>\n",
       "      <th>Q13_16</th>\n",
       "      <th>Q13_Dont_Know</th>\n",
       "      <th>Q14</th>\n",
       "      <th>Q15</th>\n",
       "      <th>Q17</th>\n",
       "      <th>Q18_1</th>\n",
       "      <th>Q18_2</th>\n",
       "      <th>Q18_3</th>\n",
       "      <th>Q18_4</th>\n",
       "      <th>Q18_5</th>\n",
       "      <th>Q18_6</th>\n",
       "      <th>Q18_7</th>\n",
       "      <th>Q18_8</th>\n",
       "      <th>Q18_9</th>\n",
       "      <th>Q18_10</th>\n",
       "      <th>Q18_11</th>\n",
       "      <th>Q18_12</th>\n",
       "      <th>Q18_13</th>\n",
       "      <th>Q18_14</th>\n",
       "      <th>Q18_15</th>\n",
       "      <th>Q18_16</th>\n",
       "      <th>Q18_17</th>\n",
       "      <th>Q18_18</th>\n",
       "      <th>Q18_19</th>\n",
       "      <th>Q18_20</th>\n",
       "      <th>Q18_21</th>\n",
       "      <th>Q18_22</th>\n",
       "      <th>Q18_23</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q11_1  Q11_2  Q11_3  Q11_4  Q11_5  Q11_6  Q11_7  Q11_8  Q11_9  Q11_10  \\\n",
       "0      0      0      0      1      1      0      0      1      0       0   \n",
       "1      1      0      0      1      0      0      1      0      0       1   \n",
       "2      1      1      0      1      0      0      1      1      0       1   \n",
       "3      0      0      0      0      0      0      0      0      0       0   \n",
       "4      1      1      0      1      0      0      1      1      0       1   \n",
       "\n",
       "   Q11_11  Q11_12  Q11_13  Q11_Dont_Know  Q12_1  Q12_2  Q12_3  Q12_4  Q12_5  \\\n",
       "0       1       0       0              0      0      0      1      1      0   \n",
       "1       0       0       0              0      0      0      1      1      0   \n",
       "2       0       0       0              0      1      0      1      1      0   \n",
       "3       0       0       0              1      0      0      0      0      0   \n",
       "4       1       0       0              0      0      0      0      1      0   \n",
       "\n",
       "   Q12_6  Q12_7  Q12_8  Q12_9  Q12_10  Q12_11  Q12_12  Q12_13  Q12_14  \\\n",
       "0      0      0      1      0       0       1       0       0       0   \n",
       "1      0      0      0      0       1       0       0       0       0   \n",
       "2      0      0      1      0       1       0       0       0       0   \n",
       "3      0      0      0      0       0       0       0       0       1   \n",
       "4      0      0      0      0       0       0       0       0       0   \n",
       "\n",
       "   Q12_Dont_Know  Q13_1  Q13_2  Q13_3  Q13_4  Q13_5  Q13_6  Q13_7  Q13_8  \\\n",
       "0              0      0      0      1      0      1      0      0      0   \n",
       "1              0      0      0      0      0      1      1      0      0   \n",
       "2              0      1      1      0      0      1      1      0      0   \n",
       "3              0      0      0      0      0      0      0      0      0   \n",
       "4              0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "   Q13_9  Q13_10  Q13_11  Q13_12  Q13_13  Q13_14  Q13_15  Q13_16  \\\n",
       "0      1       0       0       0       1       1       0       0   \n",
       "1      1       0       1       0       0       0       0       0   \n",
       "2      1       0       0       0       0       1       0       0   \n",
       "3      0       0       0       0       0       0       0       1   \n",
       "4      0       0       0       0       0       1       0       0   \n",
       "\n",
       "   Q13_Dont_Know Q14 Q15 Q17 Q18_1 Q18_2 Q18_3 Q18_4 Q18_5 Q18_6 Q18_7 Q18_8  \\\n",
       "0              0   1   2   3     5     5     5     5     5     5     5     5   \n",
       "1              0   3   2   3     4     3     2     4     3     2     2     3   \n",
       "2              0   1   2   1     5     ?     4     ?     4     4     4     4   \n",
       "3              0   ?   2   ?     ?     ?     ?     ?     ?     ?     ?     ?   \n",
       "4              0   ?   2   ?     ?     4     ?     ?     2     ?     ?     ?   \n",
       "\n",
       "  Q18_9 Q18_10 Q18_11 Q18_12 Q18_13 Q18_14 Q18_15 Q18_16 Q18_17 Q18_18 Q18_19  \\\n",
       "0     5      5      5      5      5      5      5      5      5      5      5   \n",
       "1     3      3      2      1      2      4      2      2      4      2      4   \n",
       "2     4      4      ?      4      ?      4      ?      ?      4      4      ?   \n",
       "3     ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?   \n",
       "4     ?      ?      ?      ?      ?      ?      2      ?      ?      ?      1   \n",
       "\n",
       "  Q18_20 Q18_21 Q18_22 Q18_23  Q20  Q21 Q16  \n",
       "0      5      5      5      5    3    3   A  \n",
       "1      2      2      2      2    3    3   D  \n",
       "2      ?      4      2      4    4    1   A  \n",
       "3      ?      ?      ?      ?    3    3   C  \n",
       "4      1      ?      ?      ?    3    3   D  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel('Course Project - Data for Classification - Electric Vehicles.xls')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b7593525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q11_1      int64\n",
      "Q11_2      int64\n",
      "Q11_3      int64\n",
      "Q11_4      int64\n",
      "Q11_5      int64\n",
      "           ...  \n",
      "Q18_22    object\n",
      "Q18_23    object\n",
      "Q20        int64\n",
      "Q21        int64\n",
      "Q16       object\n",
      "Length: 75, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "23070e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A' 'D' 'C' 'B']\n"
     ]
    }
   ],
   "source": [
    "print(df['Q16'].unique()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4f0af2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    2883\n",
       "B    1526\n",
       "C     892\n",
       "D     807\n",
       "Name: Q16, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Q16'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e5a39c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q11_1</th>\n",
       "      <th>Q11_2</th>\n",
       "      <th>Q11_3</th>\n",
       "      <th>Q11_4</th>\n",
       "      <th>Q11_5</th>\n",
       "      <th>Q11_6</th>\n",
       "      <th>Q11_7</th>\n",
       "      <th>Q11_8</th>\n",
       "      <th>Q11_9</th>\n",
       "      <th>Q11_10</th>\n",
       "      <th>Q11_11</th>\n",
       "      <th>Q11_12</th>\n",
       "      <th>Q11_13</th>\n",
       "      <th>Q11_Dont_Know</th>\n",
       "      <th>Q12_1</th>\n",
       "      <th>Q12_2</th>\n",
       "      <th>Q12_3</th>\n",
       "      <th>Q12_4</th>\n",
       "      <th>Q12_5</th>\n",
       "      <th>Q12_6</th>\n",
       "      <th>Q12_7</th>\n",
       "      <th>Q12_8</th>\n",
       "      <th>Q12_9</th>\n",
       "      <th>Q12_10</th>\n",
       "      <th>Q12_11</th>\n",
       "      <th>Q12_12</th>\n",
       "      <th>Q12_13</th>\n",
       "      <th>Q12_14</th>\n",
       "      <th>Q12_Dont_Know</th>\n",
       "      <th>Q13_1</th>\n",
       "      <th>Q13_2</th>\n",
       "      <th>Q13_3</th>\n",
       "      <th>Q13_4</th>\n",
       "      <th>Q13_5</th>\n",
       "      <th>Q13_6</th>\n",
       "      <th>Q13_7</th>\n",
       "      <th>Q13_8</th>\n",
       "      <th>Q13_9</th>\n",
       "      <th>Q13_10</th>\n",
       "      <th>Q13_11</th>\n",
       "      <th>Q13_12</th>\n",
       "      <th>Q13_13</th>\n",
       "      <th>Q13_14</th>\n",
       "      <th>Q13_15</th>\n",
       "      <th>Q13_16</th>\n",
       "      <th>Q13_Dont_Know</th>\n",
       "      <th>Q14</th>\n",
       "      <th>Q15</th>\n",
       "      <th>Q17</th>\n",
       "      <th>Q18_1</th>\n",
       "      <th>Q18_2</th>\n",
       "      <th>Q18_3</th>\n",
       "      <th>Q18_4</th>\n",
       "      <th>Q18_5</th>\n",
       "      <th>Q18_6</th>\n",
       "      <th>Q18_7</th>\n",
       "      <th>Q18_8</th>\n",
       "      <th>Q18_9</th>\n",
       "      <th>Q18_10</th>\n",
       "      <th>Q18_11</th>\n",
       "      <th>Q18_12</th>\n",
       "      <th>Q18_13</th>\n",
       "      <th>Q18_14</th>\n",
       "      <th>Q18_15</th>\n",
       "      <th>Q18_16</th>\n",
       "      <th>Q18_17</th>\n",
       "      <th>Q18_18</th>\n",
       "      <th>Q18_19</th>\n",
       "      <th>Q18_20</th>\n",
       "      <th>Q18_21</th>\n",
       "      <th>Q18_22</th>\n",
       "      <th>Q18_23</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q11_1  Q11_2  Q11_3  Q11_4  Q11_5  Q11_6  Q11_7  Q11_8  Q11_9  Q11_10  \\\n",
       "0      0      0      0      1      1      0      0      1      0       0   \n",
       "1      1      0      0      1      0      0      1      0      0       1   \n",
       "2      1      1      0      1      0      0      1      1      0       1   \n",
       "3      0      0      0      0      0      0      0      0      0       0   \n",
       "4      1      1      0      1      0      0      1      1      0       1   \n",
       "\n",
       "   Q11_11  Q11_12  Q11_13  Q11_Dont_Know  Q12_1  Q12_2  Q12_3  Q12_4  Q12_5  \\\n",
       "0       1       0       0              0      0      0      1      1      0   \n",
       "1       0       0       0              0      0      0      1      1      0   \n",
       "2       0       0       0              0      1      0      1      1      0   \n",
       "3       0       0       0              1      0      0      0      0      0   \n",
       "4       1       0       0              0      0      0      0      1      0   \n",
       "\n",
       "   Q12_6  Q12_7  Q12_8  Q12_9  Q12_10  Q12_11  Q12_12  Q12_13  Q12_14  \\\n",
       "0      0      0      1      0       0       1       0       0       0   \n",
       "1      0      0      0      0       1       0       0       0       0   \n",
       "2      0      0      1      0       1       0       0       0       0   \n",
       "3      0      0      0      0       0       0       0       0       1   \n",
       "4      0      0      0      0       0       0       0       0       0   \n",
       "\n",
       "   Q12_Dont_Know  Q13_1  Q13_2  Q13_3  Q13_4  Q13_5  Q13_6  Q13_7  Q13_8  \\\n",
       "0              0      0      0      1      0      1      0      0      0   \n",
       "1              0      0      0      0      0      1      1      0      0   \n",
       "2              0      1      1      0      0      1      1      0      0   \n",
       "3              0      0      0      0      0      0      0      0      0   \n",
       "4              0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "   Q13_9  Q13_10  Q13_11  Q13_12  Q13_13  Q13_14  Q13_15  Q13_16  \\\n",
       "0      1       0       0       0       1       1       0       0   \n",
       "1      1       0       1       0       0       0       0       0   \n",
       "2      1       0       0       0       0       1       0       0   \n",
       "3      0       0       0       0       0       0       0       1   \n",
       "4      0       0       0       0       0       1       0       0   \n",
       "\n",
       "   Q13_Dont_Know Q14 Q15 Q17 Q18_1 Q18_2 Q18_3 Q18_4 Q18_5 Q18_6 Q18_7 Q18_8  \\\n",
       "0              0   1   2   3     5     5     5     5     5     5     5     5   \n",
       "1              0   3   2   3     4     3     2     4     3     2     2     3   \n",
       "2              0   1   2   1     5     ?     4     ?     4     4     4     4   \n",
       "3              0   ?   2   ?     ?     ?     ?     ?     ?     ?     ?     ?   \n",
       "4              0   ?   2   ?     ?     4     ?     ?     2     ?     ?     ?   \n",
       "\n",
       "  Q18_9 Q18_10 Q18_11 Q18_12 Q18_13 Q18_14 Q18_15 Q18_16 Q18_17 Q18_18 Q18_19  \\\n",
       "0     5      5      5      5      5      5      5      5      5      5      5   \n",
       "1     3      3      2      1      2      4      2      2      4      2      4   \n",
       "2     4      4      ?      4      ?      4      ?      ?      4      4      ?   \n",
       "3     ?      ?      ?      ?      ?      ?      ?      ?      ?      ?      ?   \n",
       "4     ?      ?      ?      ?      ?      ?      2      ?      ?      ?      1   \n",
       "\n",
       "  Q18_20 Q18_21 Q18_22 Q18_23  Q20  Q21 Q16  \n",
       "0      5      5      5      5    3    3   A  \n",
       "1      2      2      2      2    3    3   D  \n",
       "2      ?      4      2      4    4    1   A  \n",
       "3      ?      ?      ?      ?    3    3   C  \n",
       "4      1      ?      ?      ?    3    3   D  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dd25157f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q11_1</th>\n",
       "      <th>Q11_2</th>\n",
       "      <th>Q11_3</th>\n",
       "      <th>Q11_4</th>\n",
       "      <th>Q11_5</th>\n",
       "      <th>Q11_6</th>\n",
       "      <th>Q11_7</th>\n",
       "      <th>Q11_8</th>\n",
       "      <th>Q11_9</th>\n",
       "      <th>Q11_10</th>\n",
       "      <th>Q11_11</th>\n",
       "      <th>Q11_12</th>\n",
       "      <th>Q11_13</th>\n",
       "      <th>Q11_Dont_Know</th>\n",
       "      <th>Q12_1</th>\n",
       "      <th>Q12_2</th>\n",
       "      <th>Q12_3</th>\n",
       "      <th>Q12_4</th>\n",
       "      <th>Q12_5</th>\n",
       "      <th>Q12_6</th>\n",
       "      <th>Q12_7</th>\n",
       "      <th>Q12_8</th>\n",
       "      <th>Q12_9</th>\n",
       "      <th>Q12_10</th>\n",
       "      <th>Q12_11</th>\n",
       "      <th>Q12_12</th>\n",
       "      <th>Q12_13</th>\n",
       "      <th>Q12_14</th>\n",
       "      <th>Q12_Dont_Know</th>\n",
       "      <th>Q13_1</th>\n",
       "      <th>Q13_2</th>\n",
       "      <th>Q13_3</th>\n",
       "      <th>Q13_4</th>\n",
       "      <th>Q13_5</th>\n",
       "      <th>Q13_6</th>\n",
       "      <th>Q13_7</th>\n",
       "      <th>Q13_8</th>\n",
       "      <th>Q13_9</th>\n",
       "      <th>Q13_10</th>\n",
       "      <th>Q13_11</th>\n",
       "      <th>Q13_12</th>\n",
       "      <th>Q13_13</th>\n",
       "      <th>Q13_14</th>\n",
       "      <th>Q13_15</th>\n",
       "      <th>Q13_16</th>\n",
       "      <th>Q13_Dont_Know</th>\n",
       "      <th>Q14</th>\n",
       "      <th>Q15</th>\n",
       "      <th>Q17</th>\n",
       "      <th>Q18_1</th>\n",
       "      <th>Q18_2</th>\n",
       "      <th>Q18_3</th>\n",
       "      <th>Q18_4</th>\n",
       "      <th>Q18_5</th>\n",
       "      <th>Q18_6</th>\n",
       "      <th>Q18_7</th>\n",
       "      <th>Q18_8</th>\n",
       "      <th>Q18_9</th>\n",
       "      <th>Q18_10</th>\n",
       "      <th>Q18_11</th>\n",
       "      <th>Q18_12</th>\n",
       "      <th>Q18_13</th>\n",
       "      <th>Q18_14</th>\n",
       "      <th>Q18_15</th>\n",
       "      <th>Q18_16</th>\n",
       "      <th>Q18_17</th>\n",
       "      <th>Q18_18</th>\n",
       "      <th>Q18_19</th>\n",
       "      <th>Q18_20</th>\n",
       "      <th>Q18_21</th>\n",
       "      <th>Q18_22</th>\n",
       "      <th>Q18_23</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q11_1  Q11_2  Q11_3  Q11_4  Q11_5  Q11_6  Q11_7  Q11_8  Q11_9  Q11_10  \\\n",
       "0      0      0      0      1      1      0      0      1      0       0   \n",
       "1      1      0      0      1      0      0      1      0      0       1   \n",
       "2      1      1      0      1      0      0      1      1      0       1   \n",
       "3      0      0      0      0      0      0      0      0      0       0   \n",
       "4      1      1      0      1      0      0      1      1      0       1   \n",
       "\n",
       "   Q11_11  Q11_12  Q11_13  Q11_Dont_Know  Q12_1  Q12_2  Q12_3  Q12_4  Q12_5  \\\n",
       "0       1       0       0              0      0      0      1      1      0   \n",
       "1       0       0       0              0      0      0      1      1      0   \n",
       "2       0       0       0              0      1      0      1      1      0   \n",
       "3       0       0       0              1      0      0      0      0      0   \n",
       "4       1       0       0              0      0      0      0      1      0   \n",
       "\n",
       "   Q12_6  Q12_7  Q12_8  Q12_9  Q12_10  Q12_11  Q12_12  Q12_13  Q12_14  \\\n",
       "0      0      0      1      0       0       1       0       0       0   \n",
       "1      0      0      0      0       1       0       0       0       0   \n",
       "2      0      0      1      0       1       0       0       0       0   \n",
       "3      0      0      0      0       0       0       0       0       1   \n",
       "4      0      0      0      0       0       0       0       0       0   \n",
       "\n",
       "   Q12_Dont_Know  Q13_1  Q13_2  Q13_3  Q13_4  Q13_5  Q13_6  Q13_7  Q13_8  \\\n",
       "0              0      0      0      1      0      1      0      0      0   \n",
       "1              0      0      0      0      0      1      1      0      0   \n",
       "2              0      1      1      0      0      1      1      0      0   \n",
       "3              0      0      0      0      0      0      0      0      0   \n",
       "4              0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "   Q13_9  Q13_10  Q13_11  Q13_12  Q13_13  Q13_14  Q13_15  Q13_16  \\\n",
       "0      1       0       0       0       1       1       0       0   \n",
       "1      1       0       1       0       0       0       0       0   \n",
       "2      1       0       0       0       0       1       0       0   \n",
       "3      0       0       0       0       0       0       0       1   \n",
       "4      0       0       0       0       0       1       0       0   \n",
       "\n",
       "   Q13_Dont_Know  Q14  Q15  Q17  Q18_1  Q18_2  Q18_3  Q18_4  Q18_5  Q18_6  \\\n",
       "0              0  1.0  2.0  3.0    5.0    5.0    5.0    5.0    5.0    5.0   \n",
       "1              0  3.0  2.0  3.0    4.0    3.0    2.0    4.0    3.0    2.0   \n",
       "2              0  1.0  2.0  1.0    5.0    NaN    4.0    NaN    4.0    4.0   \n",
       "3              0  NaN  2.0  NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "4              0  NaN  2.0  NaN    NaN    4.0    NaN    NaN    2.0    NaN   \n",
       "\n",
       "   Q18_7  Q18_8  Q18_9  Q18_10  Q18_11  Q18_12  Q18_13  Q18_14  Q18_15  \\\n",
       "0    5.0    5.0    5.0     5.0     5.0     5.0     5.0     5.0     5.0   \n",
       "1    2.0    3.0    3.0     3.0     2.0     1.0     2.0     4.0     2.0   \n",
       "2    4.0    4.0    4.0     4.0     NaN     4.0     NaN     4.0     NaN   \n",
       "3    NaN    NaN    NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "4    NaN    NaN    NaN     NaN     NaN     NaN     NaN     NaN     2.0   \n",
       "\n",
       "   Q18_16  Q18_17  Q18_18  Q18_19  Q18_20  Q18_21  Q18_22  Q18_23  Q20  Q21  \\\n",
       "0     5.0     5.0     5.0     5.0     5.0     5.0     5.0     5.0    3    3   \n",
       "1     2.0     4.0     2.0     4.0     2.0     2.0     2.0     2.0    3    3   \n",
       "2     NaN     4.0     4.0     NaN     NaN     4.0     2.0     4.0    4    1   \n",
       "3     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN    3    3   \n",
       "4     NaN     NaN     NaN     1.0     1.0     NaN     NaN     NaN    3    3   \n",
       "\n",
       "  Q16  \n",
       "0   A  \n",
       "1   D  \n",
       "2   A  \n",
       "3   C  \n",
       "4   D  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'df' is your DataFrame\n",
    "import numpy as np\n",
    "\n",
    "# Replace non-numeric values with NaN\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "36ed904e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed data shape for k=1: (6108, 74)\n",
      "Imputed data shape for k=3: (6108, 74)\n",
      "Imputed data shape for k=5: (6108, 74)\n",
      "Imputed data shape for k=7: (6108, 74)\n",
      "Imputed data shape for k=9: (6108, 74)\n",
      "Imputed data shape for k=11: (6108, 74)\n",
      "Imputed data shape for k=15: (6108, 74)\n",
      "Imputed data shape for k=19: (6108, 74)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'exclude_column_name' is the column to exclude\n",
    "exclude_column_name = 'Q16'\n",
    "column_to_exclude = df[exclude_column_name]\n",
    "\n",
    "# Create a list of k values\n",
    "k_values = [1, 3, 5, 7, 9,11,15,19]\n",
    "\n",
    "# Loop through each k value\n",
    "for k in k_values:\n",
    "    # Drop the column you want to exclude\n",
    "    columns_to_impute = df.drop(columns=[exclude_column_name])\n",
    "    \n",
    "    # Apply KNN imputation for the current k value\n",
    "    imputer = KNNImputer(n_neighbors=k)\n",
    "    imputed_data = imputer.fit_transform(columns_to_impute)\n",
    "    \n",
    "    # Use the imputed data for further processing or modeling\n",
    "    # ...\n",
    "    imputed_df = pd.DataFrame(imputed_data, columns=columns_to_impute.columns)\n",
    "    imputed_df[exclude_column_name] = column_to_exclude\n",
    "\n",
    "    # Example: Print imputed data shape\n",
    "    print(f\"Imputed data shape for k={k}: {imputed_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8aadeb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q11_1: float64\n",
      "Q11_2: float64\n",
      "Q11_3: float64\n",
      "Q11_4: float64\n",
      "Q11_5: float64\n",
      "Q11_6: float64\n",
      "Q11_7: float64\n",
      "Q11_8: float64\n",
      "Q11_9: float64\n",
      "Q11_10: float64\n",
      "Q11_11: float64\n",
      "Q11_12: float64\n",
      "Q11_13: float64\n",
      "Q11_Dont_Know: float64\n",
      "Q12_1: float64\n",
      "Q12_2: float64\n",
      "Q12_3: float64\n",
      "Q12_4: float64\n",
      "Q12_5: float64\n",
      "Q12_6: float64\n",
      "Q12_7: float64\n",
      "Q12_8: float64\n",
      "Q12_9: float64\n",
      "Q12_10: float64\n",
      "Q12_11: float64\n",
      "Q12_12: float64\n",
      "Q12_13: float64\n",
      "Q12_14: float64\n",
      "Q12_Dont_Know: float64\n",
      "Q13_1: float64\n",
      "Q13_2: float64\n",
      "Q13_3: float64\n",
      "Q13_4: float64\n",
      "Q13_5: float64\n",
      "Q13_6: float64\n",
      "Q13_7: float64\n",
      "Q13_8: float64\n",
      "Q13_9: float64\n",
      "Q13_10: float64\n",
      "Q13_11: float64\n",
      "Q13_12: float64\n",
      "Q13_13: float64\n",
      "Q13_14: float64\n",
      "Q13_15: float64\n",
      "Q13_16: float64\n",
      "Q13_Dont_Know: float64\n",
      "Q14: float64\n",
      "Q15: float64\n",
      "Q17: float64\n",
      "Q18_1: float64\n",
      "Q18_2: float64\n",
      "Q18_3: float64\n",
      "Q18_4: float64\n",
      "Q18_5: float64\n",
      "Q18_6: float64\n",
      "Q18_7: float64\n",
      "Q18_8: float64\n",
      "Q18_9: float64\n",
      "Q18_10: float64\n",
      "Q18_11: float64\n",
      "Q18_12: float64\n",
      "Q18_13: float64\n",
      "Q18_14: float64\n",
      "Q18_15: float64\n",
      "Q18_16: float64\n",
      "Q18_17: float64\n",
      "Q18_18: float64\n",
      "Q18_19: float64\n",
      "Q18_20: float64\n",
      "Q18_21: float64\n",
      "Q18_22: float64\n",
      "Q18_23: float64\n",
      "Q20: float64\n",
      "Q21: float64\n",
      "Q16: object\n"
     ]
    }
   ],
   "source": [
    "for column, dtype in imputed_df.dtypes.items():\n",
    "    print(f\"{column}: {dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1d27a1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked Features:\n",
      "Q17       0.238422\n",
      "Q14       0.202065\n",
      "Q18_1     0.156811\n",
      "Q18_14    0.154159\n",
      "Q21       0.129484\n",
      "            ...   \n",
      "Q12_6     0.000000\n",
      "Q11_10    0.000000\n",
      "Q11_9     0.000000\n",
      "Q12_9     0.000000\n",
      "Q12_13    0.000000\n",
      "Length: 74, dtype: float64\n",
      "Ranked Features:\n",
      "Q17              0.238422\n",
      "Q14              0.202065\n",
      "Q18_1            0.156811\n",
      "Q18_14           0.154159\n",
      "Q21              0.129484\n",
      "Q12_14           0.119388\n",
      "Q13_16           0.110477\n",
      "Q18_3            0.109182\n",
      "Q18_2            0.104111\n",
      "Q18_8            0.101736\n",
      "Q18_10           0.092061\n",
      "Q18_17           0.088152\n",
      "Q18_9            0.084793\n",
      "Q18_21           0.080249\n",
      "Q18_13           0.077158\n",
      "Q18_20           0.076767\n",
      "Q18_19           0.075867\n",
      "Q18_7            0.074193\n",
      "Q18_5            0.072384\n",
      "Q18_15           0.071909\n",
      "Q18_23           0.070949\n",
      "Q18_6            0.067389\n",
      "Q13_2            0.066936\n",
      "Q18_4            0.064241\n",
      "Q18_16           0.063476\n",
      "Q18_11           0.061858\n",
      "Q18_12           0.060541\n",
      "Q18_22           0.052910\n",
      "Q18_18           0.049072\n",
      "Q12_4            0.047799\n",
      "Q13_Dont_Know    0.043434\n",
      "Q12_10           0.036040\n",
      "Q11_5            0.033721\n",
      "Q20              0.033694\n",
      "Q15              0.033631\n",
      "Q13_7            0.033168\n",
      "Q11_Dont_Know    0.032760\n",
      "Q13_5            0.028669\n",
      "Q13_3            0.027350\n",
      "Q12_5            0.026832\n",
      "Q13_6            0.026360\n",
      "Q12_Dont_Know    0.025649\n",
      "Q12_2            0.024590\n",
      "Q12_3            0.023208\n",
      "Q13_1            0.022644\n",
      "Q11_7            0.022212\n",
      "Q13_14           0.017932\n",
      "Q12_1            0.017911\n",
      "Q11_8            0.015110\n",
      "Q13_11           0.013149\n",
      "Q13_8            0.012502\n",
      "Q12_7            0.010577\n",
      "Q13_13           0.009187\n",
      "Q11_4            0.009066\n",
      "Q13_9            0.008999\n",
      "Q11_12           0.008808\n",
      "Q11_6            0.007779\n",
      "Q12_12           0.007641\n",
      "Q11_2            0.007407\n",
      "Q11_13           0.007360\n",
      "Q11_3            0.006826\n",
      "Q11_11           0.006562\n",
      "Q13_10           0.006021\n",
      "Q13_12           0.005936\n",
      "Q13_4            0.003336\n",
      "Q12_8            0.002782\n",
      "Q12_11           0.002438\n",
      "Q13_15           0.001327\n",
      "Q11_1            0.000002\n",
      "Q12_6            0.000000\n",
      "Q11_10           0.000000\n",
      "Q11_9            0.000000\n",
      "Q12_9            0.000000\n",
      "Q12_13           0.000000\n",
      "dtype: float64\n",
      "Non-zero Mutual Information Scores for Features:\n",
      "Q17              0.238422\n",
      "Q14              0.202065\n",
      "Q18_1            0.156811\n",
      "Q18_14           0.154159\n",
      "Q21              0.129484\n",
      "Q12_14           0.119388\n",
      "Q13_16           0.110477\n",
      "Q18_3            0.109182\n",
      "Q18_2            0.104111\n",
      "Q18_8            0.101736\n",
      "Q18_10           0.092061\n",
      "Q18_17           0.088152\n",
      "Q18_9            0.084793\n",
      "Q18_21           0.080249\n",
      "Q18_13           0.077158\n",
      "Q18_20           0.076767\n",
      "Q18_19           0.075867\n",
      "Q18_7            0.074193\n",
      "Q18_5            0.072384\n",
      "Q18_15           0.071909\n",
      "Q18_23           0.070949\n",
      "Q18_6            0.067389\n",
      "Q13_2            0.066936\n",
      "Q18_4            0.064241\n",
      "Q18_16           0.063476\n",
      "Q18_11           0.061858\n",
      "Q18_12           0.060541\n",
      "Q18_22           0.052910\n",
      "Q18_18           0.049072\n",
      "Q12_4            0.047799\n",
      "Q13_Dont_Know    0.043434\n",
      "Q12_10           0.036040\n",
      "Q11_5            0.033721\n",
      "Q20              0.033694\n",
      "Q15              0.033631\n",
      "Q13_7            0.033168\n",
      "Q11_Dont_Know    0.032760\n",
      "Q13_5            0.028669\n",
      "Q13_3            0.027350\n",
      "Q12_5            0.026832\n",
      "Q13_6            0.026360\n",
      "Q12_Dont_Know    0.025649\n",
      "Q12_2            0.024590\n",
      "Q12_3            0.023208\n",
      "Q13_1            0.022644\n",
      "Q11_7            0.022212\n",
      "Q13_14           0.017932\n",
      "Q12_1            0.017911\n",
      "Q11_8            0.015110\n",
      "Q13_11           0.013149\n",
      "Q13_8            0.012502\n",
      "Q12_7            0.010577\n",
      "Q13_13           0.009187\n",
      "Q11_4            0.009066\n",
      "Q13_9            0.008999\n",
      "Q11_12           0.008808\n",
      "Q11_6            0.007779\n",
      "Q12_12           0.007641\n",
      "Q11_2            0.007407\n",
      "Q11_13           0.007360\n",
      "Q11_3            0.006826\n",
      "Q11_11           0.006562\n",
      "Q13_10           0.006021\n",
      "Q13_12           0.005936\n",
      "Q13_4            0.003336\n",
      "Q12_8            0.002782\n",
      "Q12_11           0.002438\n",
      "Q13_15           0.001327\n",
      "dtype: float64\n",
      "        Q17       Q14     Q18_1    Q18_14  Q21  Q12_14  Q13_16     Q18_3  \\\n",
      "0  3.000000  1.000000  5.000000  5.000000  3.0     0.0     0.0  5.000000   \n",
      "1  3.000000  3.000000  4.000000  4.000000  3.0     0.0     0.0  2.000000   \n",
      "2  1.000000  1.000000  5.000000  4.000000  1.0     0.0     0.0  4.000000   \n",
      "3  3.263158  3.315789  3.421053  3.578947  3.0     1.0     1.0  3.315789   \n",
      "4  2.315789  3.105263  3.473684  3.210526  3.0     0.0     0.0  3.052632   \n",
      "\n",
      "      Q18_2     Q18_8    Q18_10    Q18_17     Q18_9    Q18_21    Q18_13  \\\n",
      "0  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000   \n",
      "1  3.000000  3.000000  3.000000  4.000000  3.000000  2.000000  2.000000   \n",
      "2  4.315789  4.000000  4.000000  4.000000  4.000000  4.000000  3.631579   \n",
      "3  3.421053  3.210526  3.368421  2.894737  3.315789  3.105263  2.789474   \n",
      "4  4.000000  2.894737  3.052632  2.315789  3.578947  2.052632  2.210526   \n",
      "\n",
      "     Q18_20    Q18_19     Q18_7     Q18_5    Q18_15    Q18_23     Q18_6  \\\n",
      "0  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000   \n",
      "1  2.000000  4.000000  2.000000  3.000000  2.000000  2.000000  2.000000   \n",
      "2  2.368421  3.736842  4.000000  4.000000  3.789474  4.000000  4.000000   \n",
      "3  3.000000  3.105263  3.210526  3.315789  3.263158  2.684211  2.631579   \n",
      "4  1.000000  1.000000  2.210526  2.000000  2.000000  2.000000  2.315789   \n",
      "\n",
      "   Q13_2     Q18_4    Q18_16    Q18_11    Q18_12    Q18_22    Q18_18  Q12_4  \\\n",
      "0    0.0  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000    1.0   \n",
      "1    0.0  4.000000  2.000000  2.000000  1.000000  2.000000  2.000000    1.0   \n",
      "2    1.0  4.000000  3.473684  3.368421  4.000000  2.000000  4.000000    1.0   \n",
      "3    0.0  3.421053  3.263158  2.947368  2.421053  2.789474  2.842105    0.0   \n",
      "4    0.0  2.894737  1.894737  2.210526  2.105263  1.473684  1.842105    1.0   \n",
      "\n",
      "   Q13_Dont_Know  Q12_10  Q11_5  Q20  Q15  Q13_7  Q11_Dont_Know  Q13_5  Q13_3  \\\n",
      "0            0.0     0.0    1.0  3.0  2.0    0.0            0.0    1.0    1.0   \n",
      "1            0.0     1.0    0.0  3.0  2.0    0.0            0.0    1.0    0.0   \n",
      "2            0.0     1.0    0.0  4.0  2.0    0.0            0.0    1.0    0.0   \n",
      "3            0.0     0.0    0.0  3.0  2.0    0.0            1.0    0.0    0.0   \n",
      "4            0.0     0.0    0.0  3.0  2.0    0.0            0.0    0.0    0.0   \n",
      "\n",
      "   Q12_5  Q13_6  Q12_Dont_Know  Q12_2  Q12_3  Q13_1  Q11_7  Q13_14  Q12_1  \\\n",
      "0    0.0    0.0            0.0    0.0    1.0    0.0    0.0     1.0    0.0   \n",
      "1    0.0    1.0            0.0    0.0    1.0    0.0    1.0     0.0    0.0   \n",
      "2    0.0    1.0            0.0    0.0    1.0    1.0    1.0     1.0    1.0   \n",
      "3    0.0    0.0            0.0    0.0    0.0    0.0    0.0     0.0    0.0   \n",
      "4    0.0    0.0            0.0    0.0    0.0    0.0    1.0     1.0    0.0   \n",
      "\n",
      "   Q11_8  Q13_11  Q13_8  Q12_7  Q13_13  Q11_4  Q13_9  Q11_12  Q11_6  Q12_12  \\\n",
      "0    1.0     0.0    0.0    0.0     1.0    1.0    1.0     0.0    0.0     0.0   \n",
      "1    0.0     1.0    0.0    0.0     0.0    1.0    1.0     0.0    0.0     0.0   \n",
      "2    1.0     0.0    0.0    0.0     0.0    1.0    1.0     0.0    0.0     0.0   \n",
      "3    0.0     0.0    0.0    0.0     0.0    0.0    0.0     0.0    0.0     0.0   \n",
      "4    1.0     0.0    0.0    0.0     0.0    1.0    0.0     0.0    0.0     0.0   \n",
      "\n",
      "   Q11_2  Q11_13  Q11_3  Q11_11  Q13_10  Q13_12  Q13_4  Q12_8  Q12_11  Q13_15  \\\n",
      "0    0.0     0.0    0.0     1.0     0.0     0.0    0.0    1.0     1.0     0.0   \n",
      "1    0.0     0.0    0.0     0.0     0.0     0.0    0.0    0.0     0.0     0.0   \n",
      "2    1.0     0.0    0.0     0.0     0.0     0.0    0.0    1.0     0.0     0.0   \n",
      "3    0.0     0.0    0.0     0.0     0.0     0.0    0.0    0.0     0.0     0.0   \n",
      "4    1.0     0.0    0.0     1.0     0.0     0.0    0.0    0.0     0.0     0.0   \n",
      "\n",
      "  Q16  \n",
      "0   A  \n",
      "1   D  \n",
      "2   A  \n",
      "3   C  \n",
      "4   D  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "###MUTUAL INFO\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "target_column = 'Q16'\n",
    "threshold = 0.01  # Set your desired correlation threshold\n",
    "\n",
    "# Copy the DataFrame to avoid modifying the original\n",
    "imputed_df_copy = imputed_df.copy()\n",
    "\n",
    "# Use mutual_info_classif for feature selection with categorical target\n",
    "X = imputed_df_copy.drop(columns=[target_column])\n",
    "y = imputed_df_copy[target_column]\n",
    "\n",
    "# Calculate mutual information between features and target\n",
    "mutual_info_values = mutual_info_classif(X, y)\n",
    "\n",
    "# Create a Series with feature names and their mutual information scores\n",
    "feature_mutual_info = pd.Series(mutual_info_values, index=X.columns)\n",
    "\n",
    "# Select features based on the mutual information threshold\n",
    "selected_features = feature_mutual_info[feature_mutual_info > threshold].index.tolist()\n",
    "\n",
    "# Rank features by mutual information scores\n",
    "ranked_features = feature_mutual_info.sort_values(ascending=False)\n",
    "\n",
    "# Display the ranked features\n",
    "print(\"Ranked Features:\")\n",
    "print(ranked_features)\n",
    "\n",
    "# Set pandas display options to show all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Print the ranked features\n",
    "print(\"Ranked Features:\")\n",
    "print(ranked_features)\n",
    "\n",
    "\n",
    "non_zero_features = ranked_features[ranked_features >= 0.001]\n",
    "\n",
    "# Display non-zero features and their mutual information scores\n",
    "print(\"Non-zero Mutual Information Scores for Features:\")\n",
    "print(non_zero_features)\n",
    "pd.reset_option('display.max_rows')\n",
    "\n",
    "non_zero_columns = non_zero_features.index.tolist()\n",
    "\n",
    "# Create a new DataFrame with only the non-zero columns\n",
    "new_df = imputed_df[non_zero_columns].copy()\n",
    "new_df['Q16'] = imputed_df['Q16']\n",
    "print(new_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "42b12ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q11_1     0\n",
      "Q11_2     0\n",
      "Q11_3     0\n",
      "Q11_4     0\n",
      "Q11_5     0\n",
      "         ..\n",
      "Q18_22    0\n",
      "Q18_23    0\n",
      "Q20       0\n",
      "Q21       0\n",
      "Q16       0\n",
      "Length: 75, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(imputed_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3ca0b9b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q17</th>\n",
       "      <th>Q14</th>\n",
       "      <th>Q18_1</th>\n",
       "      <th>Q18_14</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q12_14</th>\n",
       "      <th>Q13_16</th>\n",
       "      <th>Q18_3</th>\n",
       "      <th>Q18_2</th>\n",
       "      <th>Q18_8</th>\n",
       "      <th>Q18_10</th>\n",
       "      <th>Q18_17</th>\n",
       "      <th>Q18_9</th>\n",
       "      <th>Q18_21</th>\n",
       "      <th>Q18_13</th>\n",
       "      <th>Q18_20</th>\n",
       "      <th>Q18_19</th>\n",
       "      <th>Q18_7</th>\n",
       "      <th>Q18_5</th>\n",
       "      <th>Q18_15</th>\n",
       "      <th>Q18_23</th>\n",
       "      <th>Q18_6</th>\n",
       "      <th>Q13_2</th>\n",
       "      <th>Q18_4</th>\n",
       "      <th>Q18_16</th>\n",
       "      <th>Q18_11</th>\n",
       "      <th>Q18_12</th>\n",
       "      <th>Q18_22</th>\n",
       "      <th>Q18_18</th>\n",
       "      <th>Q12_4</th>\n",
       "      <th>Q13_Dont_Know</th>\n",
       "      <th>Q12_10</th>\n",
       "      <th>Q11_5</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q15</th>\n",
       "      <th>Q13_7</th>\n",
       "      <th>Q11_Dont_Know</th>\n",
       "      <th>Q13_5</th>\n",
       "      <th>Q13_3</th>\n",
       "      <th>Q12_5</th>\n",
       "      <th>Q13_6</th>\n",
       "      <th>Q12_Dont_Know</th>\n",
       "      <th>Q12_2</th>\n",
       "      <th>Q12_3</th>\n",
       "      <th>Q13_1</th>\n",
       "      <th>Q11_7</th>\n",
       "      <th>Q13_14</th>\n",
       "      <th>Q12_1</th>\n",
       "      <th>Q11_8</th>\n",
       "      <th>Q13_11</th>\n",
       "      <th>Q13_8</th>\n",
       "      <th>Q12_7</th>\n",
       "      <th>Q13_13</th>\n",
       "      <th>Q11_4</th>\n",
       "      <th>Q13_9</th>\n",
       "      <th>Q11_12</th>\n",
       "      <th>Q11_6</th>\n",
       "      <th>Q12_12</th>\n",
       "      <th>Q11_2</th>\n",
       "      <th>Q11_13</th>\n",
       "      <th>Q11_3</th>\n",
       "      <th>Q11_11</th>\n",
       "      <th>Q13_10</th>\n",
       "      <th>Q13_12</th>\n",
       "      <th>Q13_4</th>\n",
       "      <th>Q12_8</th>\n",
       "      <th>Q12_11</th>\n",
       "      <th>Q13_15</th>\n",
       "      <th>Q16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q17  Q14  Q18_1  Q18_14  Q21  Q12_14  Q13_16  Q18_3  Q18_2  Q18_8  Q18_10  \\\n",
       "0    0    0      1       1    0       0       0      1      1      1       1   \n",
       "1    0    0      0       0    0       0       0      0      0      0       0   \n",
       "2    0    0      1       0    0       0       0      0      1      0       0   \n",
       "3    0    0      0       0    0       1       1      0      0      0       0   \n",
       "4    0    0      0       0    0       0       0      0      0      0       0   \n",
       "\n",
       "   Q18_17  Q18_9  Q18_21  Q18_13  Q18_20  Q18_19  Q18_7  Q18_5  Q18_15  \\\n",
       "0       1      1       1       1       1       1      1      1       1   \n",
       "1       0      0       0       0       0       0      0      0       0   \n",
       "2       0      0       0       0       0       0      0      0       0   \n",
       "3       0      0       0       0       0       0      0      0       0   \n",
       "4       0      0       0       0       0       0      0      0       0   \n",
       "\n",
       "   Q18_23  Q18_6  Q13_2  Q18_4  Q18_16  Q18_11  Q18_12  Q18_22  Q18_18  Q12_4  \\\n",
       "0       1      1      0      1       1       1       1       1       1      1   \n",
       "1       0      0      0      0       0       0       0       0       0      1   \n",
       "2       0      0      1      0       0       0       0       0       0      1   \n",
       "3       0      0      0      0       0       0       0       0       0      0   \n",
       "4       0      0      0      0       0       0       0       0       0      1   \n",
       "\n",
       "   Q13_Dont_Know  Q12_10  Q11_5  Q20  Q15  Q13_7  Q11_Dont_Know  Q13_5  Q13_3  \\\n",
       "0              0       0      1    0    1      0              0      1      1   \n",
       "1              0       1      0    0    1      0              0      1      0   \n",
       "2              0       1      0    0    1      0              0      1      0   \n",
       "3              0       0      0    0    1      0              1      0      0   \n",
       "4              0       0      0    0    1      0              0      0      0   \n",
       "\n",
       "   Q12_5  Q13_6  Q12_Dont_Know  Q12_2  Q12_3  Q13_1  Q11_7  Q13_14  Q12_1  \\\n",
       "0      0      0              0      0      1      0      0       1      0   \n",
       "1      0      1              0      0      1      0      1       0      0   \n",
       "2      0      1              0      0      1      1      1       1      1   \n",
       "3      0      0              0      0      0      0      0       0      0   \n",
       "4      0      0              0      0      0      0      1       1      0   \n",
       "\n",
       "   Q11_8  Q13_11  Q13_8  Q12_7  Q13_13  Q11_4  Q13_9  Q11_12  Q11_6  Q12_12  \\\n",
       "0      1       0      0      0       1      1      1       0      0       0   \n",
       "1      0       1      0      0       0      1      1       0      0       0   \n",
       "2      1       0      0      0       0      1      1       0      0       0   \n",
       "3      0       0      0      0       0      0      0       0      0       0   \n",
       "4      1       0      0      0       0      1      0       0      0       0   \n",
       "\n",
       "   Q11_2  Q11_13  Q11_3  Q11_11  Q13_10  Q13_12  Q13_4  Q12_8  Q12_11  Q13_15  \\\n",
       "0      0       0      0       1       0       0      0      1       1       0   \n",
       "1      0       0      0       0       0       0      0      0       0       0   \n",
       "2      1       0      0       0       0       0      0      1       0       0   \n",
       "3      0       0      0       0       0       0      0      0       0       0   \n",
       "4      1       0      0       1       0       0      0      0       0       0   \n",
       "\n",
       "  Q16  \n",
       "0   A  \n",
       "1   D  \n",
       "2   A  \n",
       "3   C  \n",
       "4   D  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()\n",
    "scaled_columns = new_df.iloc[:, :-1].apply(lambda x: (x - x.min()) / (x.max() - x.min()) if pd.api.types.is_numeric_dtype(x) else x, axis=0)\n",
    "\n",
    "# Concatenate the original DataFrame with the scaled columns\n",
    "new_df = pd.concat([scaled_columns, new_df['Q16']], axis=1)\n",
    "\n",
    "# Convert values to binary (0 or 1) based on the condition\n",
    "new_df.iloc[:, :-1] = new_df.iloc[:, :-1].apply(lambda x: x.map(lambda val: 1 if pd.notna(val) and float(val) > 0.80 else 0))\n",
    "\n",
    "# Convert to integer to make them binary\n",
    "new_df.iloc[:, :-1] = new_df.iloc[:, :-1].astype(int)\n",
    "\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "660de3de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q17</th>\n",
       "      <th>Q14</th>\n",
       "      <th>Q18_1</th>\n",
       "      <th>Q18_14</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q12_14</th>\n",
       "      <th>Q13_16</th>\n",
       "      <th>Q18_3</th>\n",
       "      <th>Q18_2</th>\n",
       "      <th>Q18_8</th>\n",
       "      <th>Q18_10</th>\n",
       "      <th>Q18_17</th>\n",
       "      <th>Q18_9</th>\n",
       "      <th>Q18_21</th>\n",
       "      <th>Q18_13</th>\n",
       "      <th>Q18_20</th>\n",
       "      <th>Q18_19</th>\n",
       "      <th>Q18_7</th>\n",
       "      <th>Q18_5</th>\n",
       "      <th>Q18_15</th>\n",
       "      <th>Q18_23</th>\n",
       "      <th>Q18_6</th>\n",
       "      <th>Q13_2</th>\n",
       "      <th>Q18_4</th>\n",
       "      <th>Q18_16</th>\n",
       "      <th>Q18_11</th>\n",
       "      <th>Q18_12</th>\n",
       "      <th>Q18_22</th>\n",
       "      <th>Q18_18</th>\n",
       "      <th>Q12_4</th>\n",
       "      <th>Q13_Dont_Know</th>\n",
       "      <th>Q12_10</th>\n",
       "      <th>Q11_5</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q15</th>\n",
       "      <th>Q13_7</th>\n",
       "      <th>Q11_Dont_Know</th>\n",
       "      <th>Q13_5</th>\n",
       "      <th>Q13_3</th>\n",
       "      <th>Q12_5</th>\n",
       "      <th>Q13_6</th>\n",
       "      <th>Q12_Dont_Know</th>\n",
       "      <th>Q12_2</th>\n",
       "      <th>Q12_3</th>\n",
       "      <th>Q13_1</th>\n",
       "      <th>Q11_7</th>\n",
       "      <th>Q13_14</th>\n",
       "      <th>Q12_1</th>\n",
       "      <th>Q11_8</th>\n",
       "      <th>Q13_11</th>\n",
       "      <th>Q13_8</th>\n",
       "      <th>Q12_7</th>\n",
       "      <th>Q13_13</th>\n",
       "      <th>Q11_4</th>\n",
       "      <th>Q13_9</th>\n",
       "      <th>Q11_12</th>\n",
       "      <th>Q11_6</th>\n",
       "      <th>Q12_12</th>\n",
       "      <th>Q11_2</th>\n",
       "      <th>Q11_13</th>\n",
       "      <th>Q11_3</th>\n",
       "      <th>Q11_11</th>\n",
       "      <th>Q13_10</th>\n",
       "      <th>Q13_12</th>\n",
       "      <th>Q13_4</th>\n",
       "      <th>Q12_8</th>\n",
       "      <th>Q12_11</th>\n",
       "      <th>Q13_15</th>\n",
       "      <th>Q16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q17  Q14  Q18_1  Q18_14  Q21  Q12_14  Q13_16  Q18_3  Q18_2  Q18_8  Q18_10  \\\n",
       "0    0    0      1       1    0       0       0      1      1      1       1   \n",
       "1    0    0      0       0    0       0       0      0      0      0       0   \n",
       "2    0    0      1       0    0       0       0      0      1      0       0   \n",
       "3    0    0      0       0    0       1       1      0      0      0       0   \n",
       "4    0    0      0       0    0       0       0      0      0      0       0   \n",
       "\n",
       "   Q18_17  Q18_9  Q18_21  Q18_13  Q18_20  Q18_19  Q18_7  Q18_5  Q18_15  \\\n",
       "0       1      1       1       1       1       1      1      1       1   \n",
       "1       0      0       0       0       0       0      0      0       0   \n",
       "2       0      0       0       0       0       0      0      0       0   \n",
       "3       0      0       0       0       0       0      0      0       0   \n",
       "4       0      0       0       0       0       0      0      0       0   \n",
       "\n",
       "   Q18_23  Q18_6  Q13_2  Q18_4  Q18_16  Q18_11  Q18_12  Q18_22  Q18_18  Q12_4  \\\n",
       "0       1      1      0      1       1       1       1       1       1      1   \n",
       "1       0      0      0      0       0       0       0       0       0      1   \n",
       "2       0      0      1      0       0       0       0       0       0      1   \n",
       "3       0      0      0      0       0       0       0       0       0      0   \n",
       "4       0      0      0      0       0       0       0       0       0      1   \n",
       "\n",
       "   Q13_Dont_Know  Q12_10  Q11_5  Q20  Q15  Q13_7  Q11_Dont_Know  Q13_5  Q13_3  \\\n",
       "0              0       0      1    0    1      0              0      1      1   \n",
       "1              0       1      0    0    1      0              0      1      0   \n",
       "2              0       1      0    0    1      0              0      1      0   \n",
       "3              0       0      0    0    1      0              1      0      0   \n",
       "4              0       0      0    0    1      0              0      0      0   \n",
       "\n",
       "   Q12_5  Q13_6  Q12_Dont_Know  Q12_2  Q12_3  Q13_1  Q11_7  Q13_14  Q12_1  \\\n",
       "0      0      0              0      0      1      0      0       1      0   \n",
       "1      0      1              0      0      1      0      1       0      0   \n",
       "2      0      1              0      0      1      1      1       1      1   \n",
       "3      0      0              0      0      0      0      0       0      0   \n",
       "4      0      0              0      0      0      0      1       1      0   \n",
       "\n",
       "   Q11_8  Q13_11  Q13_8  Q12_7  Q13_13  Q11_4  Q13_9  Q11_12  Q11_6  Q12_12  \\\n",
       "0      1       0      0      0       1      1      1       0      0       0   \n",
       "1      0       1      0      0       0      1      1       0      0       0   \n",
       "2      1       0      0      0       0      1      1       0      0       0   \n",
       "3      0       0      0      0       0      0      0       0      0       0   \n",
       "4      1       0      0      0       0      1      0       0      0       0   \n",
       "\n",
       "   Q11_2  Q11_13  Q11_3  Q11_11  Q13_10  Q13_12  Q13_4  Q12_8  Q12_11  Q13_15  \\\n",
       "0      0       0      0       1       0       0      0      1       1       0   \n",
       "1      0       0      0       0       0       0      0      0       0       0   \n",
       "2      1       0      0       0       0       0      0      1       0       0   \n",
       "3      0       0      0       0       0       0      0      0       0       0   \n",
       "4      1       0      0       1       0       0      0      0       0       0   \n",
       "\n",
       "  Q16  \n",
       "0   A  \n",
       "1   D  \n",
       "2   A  \n",
       "3   C  \n",
       "4   D  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_df = new_df.copy()\n",
    "imputed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9e4b0f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"imputed_df.loc[:, imputed_df.columns != 'Q16'] = imputed_df.loc[:, imputed_df.columns != 'Q16'].astype(float)\\nimputed_df.head()\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"imputed_df.loc[:, imputed_df.columns != 'Q16'] = imputed_df.loc[:, imputed_df.columns != 'Q16'].astype(float)\n",
    "imputed_df.head()\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c0ca55a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for column, dtype in imputed_df.dtypes.items():\\n    print(f\"{column}: {dtype}\")'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for column, dtype in imputed_df.dtypes.items():\n",
    "    print(f\"{column}: {dtype}\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ca5caf35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q17        int32\n",
      "Q14        int32\n",
      "Q18_1      int32\n",
      "Q18_14     int32\n",
      "Q21        int32\n",
      "           ...  \n",
      "Q13_4      int32\n",
      "Q12_8      int32\n",
      "Q12_11     int32\n",
      "Q13_15     int32\n",
      "Q16       object\n",
      "Length: 69, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(imputed_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9339b831",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q17       0\n",
      "Q14       0\n",
      "Q18_1     0\n",
      "Q18_14    0\n",
      "Q21       0\n",
      "         ..\n",
      "Q13_4     0\n",
      "Q12_8     0\n",
      "Q12_11    0\n",
      "Q13_15    0\n",
      "Q16       0\n",
      "Length: 69, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(imputed_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9a357f7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q17</th>\n",
       "      <th>Q14</th>\n",
       "      <th>Q18_1</th>\n",
       "      <th>Q18_14</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q12_14</th>\n",
       "      <th>Q13_16</th>\n",
       "      <th>Q18_3</th>\n",
       "      <th>Q18_2</th>\n",
       "      <th>Q18_8</th>\n",
       "      <th>Q18_10</th>\n",
       "      <th>Q18_17</th>\n",
       "      <th>Q18_9</th>\n",
       "      <th>Q18_21</th>\n",
       "      <th>Q18_13</th>\n",
       "      <th>Q18_20</th>\n",
       "      <th>Q18_19</th>\n",
       "      <th>Q18_7</th>\n",
       "      <th>Q18_5</th>\n",
       "      <th>Q18_15</th>\n",
       "      <th>Q18_23</th>\n",
       "      <th>Q18_6</th>\n",
       "      <th>Q13_2</th>\n",
       "      <th>Q18_4</th>\n",
       "      <th>Q18_16</th>\n",
       "      <th>Q18_11</th>\n",
       "      <th>Q18_12</th>\n",
       "      <th>Q18_22</th>\n",
       "      <th>Q18_18</th>\n",
       "      <th>Q12_4</th>\n",
       "      <th>Q13_Dont_Know</th>\n",
       "      <th>Q12_10</th>\n",
       "      <th>Q11_5</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q15</th>\n",
       "      <th>Q13_7</th>\n",
       "      <th>Q11_Dont_Know</th>\n",
       "      <th>Q13_5</th>\n",
       "      <th>Q13_3</th>\n",
       "      <th>Q12_5</th>\n",
       "      <th>Q13_6</th>\n",
       "      <th>Q12_Dont_Know</th>\n",
       "      <th>Q12_2</th>\n",
       "      <th>Q12_3</th>\n",
       "      <th>Q13_1</th>\n",
       "      <th>Q11_7</th>\n",
       "      <th>Q13_14</th>\n",
       "      <th>Q12_1</th>\n",
       "      <th>Q11_8</th>\n",
       "      <th>Q13_11</th>\n",
       "      <th>Q13_8</th>\n",
       "      <th>Q12_7</th>\n",
       "      <th>Q13_13</th>\n",
       "      <th>Q11_4</th>\n",
       "      <th>Q13_9</th>\n",
       "      <th>Q11_12</th>\n",
       "      <th>Q11_6</th>\n",
       "      <th>Q12_12</th>\n",
       "      <th>Q11_2</th>\n",
       "      <th>Q11_13</th>\n",
       "      <th>Q11_3</th>\n",
       "      <th>Q11_11</th>\n",
       "      <th>Q13_10</th>\n",
       "      <th>Q13_12</th>\n",
       "      <th>Q13_4</th>\n",
       "      <th>Q12_8</th>\n",
       "      <th>Q12_11</th>\n",
       "      <th>Q13_15</th>\n",
       "      <th>Q16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q17  Q14  Q18_1  Q18_14  Q21  Q12_14  Q13_16  Q18_3  Q18_2  Q18_8  Q18_10  \\\n",
       "0    0    0      1       1    0       0       0      1      1      1       1   \n",
       "1    0    0      0       0    0       0       0      0      0      0       0   \n",
       "2    0    0      1       0    0       0       0      0      1      0       0   \n",
       "3    0    0      0       0    0       1       1      0      0      0       0   \n",
       "4    0    0      0       0    0       0       0      0      0      0       0   \n",
       "\n",
       "   Q18_17  Q18_9  Q18_21  Q18_13  Q18_20  Q18_19  Q18_7  Q18_5  Q18_15  \\\n",
       "0       1      1       1       1       1       1      1      1       1   \n",
       "1       0      0       0       0       0       0      0      0       0   \n",
       "2       0      0       0       0       0       0      0      0       0   \n",
       "3       0      0       0       0       0       0      0      0       0   \n",
       "4       0      0       0       0       0       0      0      0       0   \n",
       "\n",
       "   Q18_23  Q18_6  Q13_2  Q18_4  Q18_16  Q18_11  Q18_12  Q18_22  Q18_18  Q12_4  \\\n",
       "0       1      1      0      1       1       1       1       1       1      1   \n",
       "1       0      0      0      0       0       0       0       0       0      1   \n",
       "2       0      0      1      0       0       0       0       0       0      1   \n",
       "3       0      0      0      0       0       0       0       0       0      0   \n",
       "4       0      0      0      0       0       0       0       0       0      1   \n",
       "\n",
       "   Q13_Dont_Know  Q12_10  Q11_5  Q20  Q15  Q13_7  Q11_Dont_Know  Q13_5  Q13_3  \\\n",
       "0              0       0      1    0    1      0              0      1      1   \n",
       "1              0       1      0    0    1      0              0      1      0   \n",
       "2              0       1      0    0    1      0              0      1      0   \n",
       "3              0       0      0    0    1      0              1      0      0   \n",
       "4              0       0      0    0    1      0              0      0      0   \n",
       "\n",
       "   Q12_5  Q13_6  Q12_Dont_Know  Q12_2  Q12_3  Q13_1  Q11_7  Q13_14  Q12_1  \\\n",
       "0      0      0              0      0      1      0      0       1      0   \n",
       "1      0      1              0      0      1      0      1       0      0   \n",
       "2      0      1              0      0      1      1      1       1      1   \n",
       "3      0      0              0      0      0      0      0       0      0   \n",
       "4      0      0              0      0      0      0      1       1      0   \n",
       "\n",
       "   Q11_8  Q13_11  Q13_8  Q12_7  Q13_13  Q11_4  Q13_9  Q11_12  Q11_6  Q12_12  \\\n",
       "0      1       0      0      0       1      1      1       0      0       0   \n",
       "1      0       1      0      0       0      1      1       0      0       0   \n",
       "2      1       0      0      0       0      1      1       0      0       0   \n",
       "3      0       0      0      0       0      0      0       0      0       0   \n",
       "4      1       0      0      0       0      1      0       0      0       0   \n",
       "\n",
       "   Q11_2  Q11_13  Q11_3  Q11_11  Q13_10  Q13_12  Q13_4  Q12_8  Q12_11  Q13_15  \\\n",
       "0      0       0      0       1       0       0      0      1       1       0   \n",
       "1      0       0      0       0       0       0      0      0       0       0   \n",
       "2      1       0      0       0       0       0      0      1       0       0   \n",
       "3      0       0      0       0       0       0      0      0       0       0   \n",
       "4      1       0      0       1       0       0      0      0       0       0   \n",
       "\n",
       "  Q16  \n",
       "0   A  \n",
       "1   D  \n",
       "2   A  \n",
       "3   C  \n",
       "4   D  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_df.head()\n",
    "#control amaclı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "08d41669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed data shape: (6108, 75)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "exclude_column_name = 'Q16'  # Column to exclude from imputation\n",
    "\n",
    "# Save the excluded column\n",
    "column_to_exclude = df[exclude_column_name]\n",
    "\n",
    "# Drop the column you want to exclude for imputation\n",
    "columns_to_impute = df.drop(columns=[exclude_column_name])\n",
    "\n",
    "# Impute missing values with median\n",
    "imputed_data = columns_to_impute.fillna(columns_to_impute.median())\n",
    "\n",
    "# Create a DataFrame with imputed values\n",
    "imputed_df = pd.concat([imputed_data, column_to_exclude], axis=1)\n",
    "\n",
    "# Check the shape of the imputed data\n",
    "print(f\"Imputed data shape: {imputed_df.shape}\")\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'Q16' is the column with values A, B, C, D\n",
    "mapping = {'A': 0, 'B': 1, 'C': 1, 'D': 1}\n",
    "imputed_df['Q16'] = imputed_df['Q16'].replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7e768cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q11_1</th>\n",
       "      <th>Q11_2</th>\n",
       "      <th>Q11_3</th>\n",
       "      <th>Q11_4</th>\n",
       "      <th>Q11_5</th>\n",
       "      <th>Q11_6</th>\n",
       "      <th>Q11_7</th>\n",
       "      <th>Q11_8</th>\n",
       "      <th>Q11_9</th>\n",
       "      <th>Q11_10</th>\n",
       "      <th>Q11_11</th>\n",
       "      <th>Q11_12</th>\n",
       "      <th>Q11_13</th>\n",
       "      <th>Q11_Dont_Know</th>\n",
       "      <th>Q12_1</th>\n",
       "      <th>Q12_2</th>\n",
       "      <th>Q12_3</th>\n",
       "      <th>Q12_4</th>\n",
       "      <th>Q12_5</th>\n",
       "      <th>Q12_6</th>\n",
       "      <th>Q12_7</th>\n",
       "      <th>Q12_8</th>\n",
       "      <th>Q12_9</th>\n",
       "      <th>Q12_10</th>\n",
       "      <th>Q12_11</th>\n",
       "      <th>Q12_12</th>\n",
       "      <th>Q12_13</th>\n",
       "      <th>Q12_14</th>\n",
       "      <th>Q12_Dont_Know</th>\n",
       "      <th>Q13_1</th>\n",
       "      <th>Q13_2</th>\n",
       "      <th>Q13_3</th>\n",
       "      <th>Q13_4</th>\n",
       "      <th>Q13_5</th>\n",
       "      <th>Q13_6</th>\n",
       "      <th>Q13_7</th>\n",
       "      <th>Q13_8</th>\n",
       "      <th>Q13_9</th>\n",
       "      <th>Q13_10</th>\n",
       "      <th>Q13_11</th>\n",
       "      <th>Q13_12</th>\n",
       "      <th>Q13_13</th>\n",
       "      <th>Q13_14</th>\n",
       "      <th>Q13_15</th>\n",
       "      <th>Q13_16</th>\n",
       "      <th>Q13_Dont_Know</th>\n",
       "      <th>Q14</th>\n",
       "      <th>Q15</th>\n",
       "      <th>Q17</th>\n",
       "      <th>Q18_1</th>\n",
       "      <th>Q18_2</th>\n",
       "      <th>Q18_3</th>\n",
       "      <th>Q18_4</th>\n",
       "      <th>Q18_5</th>\n",
       "      <th>Q18_6</th>\n",
       "      <th>Q18_7</th>\n",
       "      <th>Q18_8</th>\n",
       "      <th>Q18_9</th>\n",
       "      <th>Q18_10</th>\n",
       "      <th>Q18_11</th>\n",
       "      <th>Q18_12</th>\n",
       "      <th>Q18_13</th>\n",
       "      <th>Q18_14</th>\n",
       "      <th>Q18_15</th>\n",
       "      <th>Q18_16</th>\n",
       "      <th>Q18_17</th>\n",
       "      <th>Q18_18</th>\n",
       "      <th>Q18_19</th>\n",
       "      <th>Q18_20</th>\n",
       "      <th>Q18_21</th>\n",
       "      <th>Q18_22</th>\n",
       "      <th>Q18_23</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q11_1  Q11_2  Q11_3  Q11_4  Q11_5  Q11_6  Q11_7  Q11_8  Q11_9  Q11_10  \\\n",
       "0      0      0      0      1      1      0      0      1      0       0   \n",
       "1      1      0      0      1      0      0      1      0      0       1   \n",
       "2      1      1      0      1      0      0      1      1      0       1   \n",
       "3      0      0      0      0      0      0      0      0      0       0   \n",
       "4      1      1      0      1      0      0      1      1      0       1   \n",
       "\n",
       "   Q11_11  Q11_12  Q11_13  Q11_Dont_Know  Q12_1  Q12_2  Q12_3  Q12_4  Q12_5  \\\n",
       "0       1       0       0              0      0      0      1      1      0   \n",
       "1       0       0       0              0      0      0      1      1      0   \n",
       "2       0       0       0              0      1      0      1      1      0   \n",
       "3       0       0       0              1      0      0      0      0      0   \n",
       "4       1       0       0              0      0      0      0      1      0   \n",
       "\n",
       "   Q12_6  Q12_7  Q12_8  Q12_9  Q12_10  Q12_11  Q12_12  Q12_13  Q12_14  \\\n",
       "0      0      0      1      0       0       1       0       0       0   \n",
       "1      0      0      0      0       1       0       0       0       0   \n",
       "2      0      0      1      0       1       0       0       0       0   \n",
       "3      0      0      0      0       0       0       0       0       1   \n",
       "4      0      0      0      0       0       0       0       0       0   \n",
       "\n",
       "   Q12_Dont_Know  Q13_1  Q13_2  Q13_3  Q13_4  Q13_5  Q13_6  Q13_7  Q13_8  \\\n",
       "0              0      0      0      1      0      1      0      0      0   \n",
       "1              0      0      0      0      0      1      1      0      0   \n",
       "2              0      1      1      0      0      1      1      0      0   \n",
       "3              0      0      0      0      0      0      0      0      0   \n",
       "4              0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "   Q13_9  Q13_10  Q13_11  Q13_12  Q13_13  Q13_14  Q13_15  Q13_16  \\\n",
       "0      1       0       0       0       1       1       0       0   \n",
       "1      1       0       1       0       0       0       0       0   \n",
       "2      1       0       0       0       0       1       0       0   \n",
       "3      0       0       0       0       0       0       0       1   \n",
       "4      0       0       0       0       0       1       0       0   \n",
       "\n",
       "   Q13_Dont_Know  Q14  Q15  Q17  Q18_1  Q18_2  Q18_3  Q18_4  Q18_5  Q18_6  \\\n",
       "0              0  1.0  2.0  3.0    5.0    5.0    5.0    5.0    5.0    5.0   \n",
       "1              0  3.0  2.0  3.0    4.0    3.0    2.0    4.0    3.0    2.0   \n",
       "2              0  1.0  2.0  1.0    5.0    4.0    4.0    3.0    4.0    4.0   \n",
       "3              0  2.0  2.0  2.0    4.0    4.0    3.0    3.0    3.0    3.0   \n",
       "4              0  2.0  2.0  2.0    4.0    4.0    3.0    3.0    2.0    3.0   \n",
       "\n",
       "   Q18_7  Q18_8  Q18_9  Q18_10  Q18_11  Q18_12  Q18_13  Q18_14  Q18_15  \\\n",
       "0    5.0    5.0    5.0     5.0     5.0     5.0     5.0     5.0     5.0   \n",
       "1    2.0    3.0    3.0     3.0     2.0     1.0     2.0     4.0     2.0   \n",
       "2    4.0    4.0    4.0     4.0     2.0     4.0     2.0     4.0     2.0   \n",
       "3    3.0    3.0    4.0     3.0     2.0     3.0     2.0     3.0     2.0   \n",
       "4    3.0    3.0    4.0     3.0     2.0     3.0     2.0     3.0     2.0   \n",
       "\n",
       "   Q18_16  Q18_17  Q18_18  Q18_19  Q18_20  Q18_21  Q18_22  Q18_23  Q20  Q21  \\\n",
       "0     5.0     5.0     5.0     5.0     5.0     5.0     5.0     5.0    3    3   \n",
       "1     2.0     4.0     2.0     4.0     2.0     2.0     2.0     2.0    3    3   \n",
       "2     2.0     4.0     4.0     3.0     2.0     4.0     2.0     4.0    4    1   \n",
       "3     2.0     3.0     2.0     3.0     2.0     3.0     2.0     2.0    3    3   \n",
       "4     2.0     3.0     2.0     1.0     1.0     3.0     2.0     2.0    3    3   \n",
       "\n",
       "   Q16  \n",
       "0    0  \n",
       "1    1  \n",
       "2    0  \n",
       "3    1  \n",
       "4    1  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5642e72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked Features:\n",
      "Q17       0.105585\n",
      "Q14       0.081853\n",
      "Q21       0.077972\n",
      "Q18_14    0.074776\n",
      "Q18_1     0.045890\n",
      "            ...   \n",
      "Q11_11    0.000000\n",
      "Q12_9     0.000000\n",
      "Q11_13    0.000000\n",
      "Q13_10    0.000000\n",
      "Q13_8     0.000000\n",
      "Length: 74, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "target_column = 'Q16'\n",
    "threshold = 0.2  # Set your desired correlation threshold\n",
    "\n",
    "# Copy the DataFrame to avoid modifying the original\n",
    "imputed_df_copy = imputed_df.copy()\n",
    "\n",
    "# Use mutual_info_classif for feature selection with categorical target\n",
    "X = imputed_df_copy.drop(columns=[target_column])\n",
    "y = imputed_df_copy[target_column]\n",
    "\n",
    "# Calculate mutual information between features and target\n",
    "mutual_info_values = mutual_info_classif(X, y)\n",
    "\n",
    "# Create a Series with feature names and their mutual information scores\n",
    "feature_mutual_info = pd.Series(mutual_info_values, index=X.columns)\n",
    "\n",
    "# Select features based on the mutual information threshold\n",
    "selected_features = feature_mutual_info[feature_mutual_info > threshold].index.tolist()\n",
    "\n",
    "# Rank features by mutual information scores\n",
    "ranked_features = feature_mutual_info.sort_values(ascending=False)\n",
    "\n",
    "# Display the ranked features\n",
    "print(\"Ranked Features:\")\n",
    "print(ranked_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "85131950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-zero Mutual Information Scores for Features:\n",
      "Q17              0.105585\n",
      "Q14              0.081853\n",
      "Q21              0.077972\n",
      "Q18_14           0.074776\n",
      "Q18_1            0.045890\n",
      "Q13_16           0.042508\n",
      "Q18_8            0.041466\n",
      "Q12_14           0.040738\n",
      "Q13_2            0.040673\n",
      "Q18_2            0.038494\n",
      "Q18_3            0.030530\n",
      "Q18_17           0.023491\n",
      "Q12_4            0.023077\n",
      "Q11_Dont_Know    0.022334\n",
      "Q18_10           0.021842\n",
      "Q18_11           0.021453\n",
      "Q18_13           0.020764\n",
      "Q13_Dont_Know    0.019272\n",
      "Q20              0.019026\n",
      "Q18_15           0.018819\n",
      "Q13_3            0.017842\n",
      "Q12_5            0.017215\n",
      "Q18_6            0.017212\n",
      "Q13_7            0.015912\n",
      "Q18_19           0.015503\n",
      "Q18_4            0.015196\n",
      "Q13_6            0.015155\n",
      "Q12_1            0.014982\n",
      "Q18_5            0.014965\n",
      "Q12_2            0.014235\n",
      "Q18_20           0.013248\n",
      "Q11_2            0.012794\n",
      "Q13_14           0.011445\n",
      "Q11_5            0.010761\n",
      "Q12_10           0.010419\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "non_zero_features = ranked_features[ranked_features >0.01]\n",
    "\n",
    "# Display non-zero features and their mutual information scores\n",
    "print(\"Non-zero Mutual Information Scores for Features:\")\n",
    "print(non_zero_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8b0ae69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Q17  Q14  Q21  Q18_14  Q18_1  Q13_16  Q18_8  Q12_14  Q13_2  Q18_2  Q18_3  \\\n",
      "0  3.0  1.0    3     5.0    5.0       0    5.0       0      0    5.0    5.0   \n",
      "1  3.0  3.0    3     4.0    4.0       0    3.0       0      0    3.0    2.0   \n",
      "2  1.0  1.0    1     4.0    5.0       0    4.0       0      1    4.0    4.0   \n",
      "3  2.0  2.0    3     3.0    4.0       1    3.0       1      0    4.0    3.0   \n",
      "4  2.0  2.0    3     3.0    4.0       0    3.0       0      0    4.0    3.0   \n",
      "\n",
      "   Q18_17  Q12_4  Q11_Dont_Know  Q18_10  Q18_11  Q18_13  Q13_Dont_Know  Q20  \\\n",
      "0     5.0      1              0     5.0     5.0     5.0              0    3   \n",
      "1     4.0      1              0     3.0     2.0     2.0              0    3   \n",
      "2     4.0      1              0     4.0     2.0     2.0              0    4   \n",
      "3     3.0      0              1     3.0     2.0     2.0              0    3   \n",
      "4     3.0      1              0     3.0     2.0     2.0              0    3   \n",
      "\n",
      "   Q18_15  Q13_3  Q12_5  Q18_6  Q13_7  Q18_19  Q18_4  Q13_6  Q12_1  Q18_5  \\\n",
      "0     5.0      1      0    5.0      0     5.0    5.0      0      0    5.0   \n",
      "1     2.0      0      0    2.0      0     4.0    4.0      1      0    3.0   \n",
      "2     2.0      0      0    4.0      0     3.0    3.0      1      1    4.0   \n",
      "3     2.0      0      0    3.0      0     3.0    3.0      0      0    3.0   \n",
      "4     2.0      0      0    3.0      0     1.0    3.0      0      0    2.0   \n",
      "\n",
      "   Q12_2  Q18_20  Q11_2  Q13_14  Q11_5  Q12_10  \n",
      "0      0     5.0      0       1      1       0  \n",
      "1      0     2.0      0       0      0       1  \n",
      "2      0     2.0      1       1      0       1  \n",
      "3      0     2.0      0       0      0       0  \n",
      "4      0     1.0      1       1      0       0  \n"
     ]
    }
   ],
   "source": [
    "non_zero_columns = non_zero_features.index.tolist()\n",
    "\n",
    "# Create a new DataFrame with only the non-zero columns\n",
    "new_df = imputed_df[non_zero_columns].copy()\n",
    "\n",
    "# Verify the new DataFrame\n",
    "print(new_df.head())  # Check the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a9542192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.7725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, RobustScaler\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = new_df  # Feature matrix\n",
    "y = imputed_df['Q16'] \n",
    "\n",
    "\n",
    "\n",
    "# Genişletilmiş özellik setini oluştur\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Özellikleri RobustScaler ile ölçeklendirme\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X_poly)\n",
    "\n",
    "# Veriyi train ve test setlerine ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest sınıflandırıcı oluşturun\n",
    "\n",
    "rf_classifier = RandomForestClassifier( n_estimators=50, max_depth=10, min_samples_split=5, min_samples_leaf=2)\n",
    "\n",
    "\n",
    "# Modeli eğitin\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "088d6b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Farklı n_estimators ve max_depth değerleri için model karmaşıklığı grafiği çiz\n",
    "n_estimators_values = [10, 50, 100, 200]\n",
    "max_depth_values = [1, 5, 10, 20]\n",
    "\n",
    "train_errors = []\n",
    "val_errors = []\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for n_estimators in n_estimators_values:\n",
    "    for max_depth in max_depth_values:\n",
    "        # RandomForestClassifier modelini oluştur\n",
    "        rf_clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "        \n",
    "        # Modeli eğit\n",
    "        rf_clf.fit(X_train, y_train)\n",
    "        \n",
    "        # Eğitim setindeki hata\n",
    "        y_train_pred = rf_clf.predict(X_train)\n",
    "        train_error = 1 - accuracy_score(y_train, y_train_pred)\n",
    "        \n",
    "        # Doğrulama setindeki hata\n",
    "        y_val_pred = rf_clf.predict(X_test)\n",
    "        val_error = 1 - accuracy_score(y_test, y_val_pred)\n",
    "        \n",
    "        train_errors.append((n_estimators, max_depth, train_error))\n",
    "        val_errors.append((n_estimators, max_depth, val_error))\n",
    "\n",
    "# Eğitim hatası ve doğrulama hatası grafiğini çiz\n",
    "for n_estimators in n_estimators_values:\n",
    "    train_errors_n = [error[2] for error in train_errors if error[0] == n_estimators]\n",
    "    val_errors_n = [error[2] for error in val_errors if error[0] == n_estimators]\n",
    "    \n",
    "    plt.plot(max_depth_values, train_errors_n, label=f'Training (n_estimators={n_estimators})', linestyle='dashed', marker='o')\n",
    "    plt.plot(max_depth_values, val_errors_n, label=f'Validation (n_estimators={n_estimators})', linestyle='dashed', marker='o')\n",
    "\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Error')\n",
    "plt.title('RandomForestClassifier Model Complexity')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "80416394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elifn\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\elifn\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.7660\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = new_df  # Feature matrix\n",
    "y = imputed_df['Q16'] \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# AdaBoostClassifier modeli\n",
    "\n",
    "\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100, learning_rate=1.0, base_estimator=RandomForestClassifier(n_estimators=50, max_depth=1))\n",
    "\n",
    "\n",
    "\n",
    "sfm = SelectFromModel(ada_clf, threshold=-np.inf, max_features=5)  # Örneğin, 5 özellik bırakmak istiyoruz\n",
    "X_train_sfm = sfm.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eğitin\n",
    "ada_clf.fit(X_train_sfm, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "X_test_sfm = sfm.transform(X_test)\n",
    "y_pred = ada_clf.predict(X_test_sfm)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dc9d9ab8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'base_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8172\\3044081131.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Random Forest sınıflandırıcı oluşturun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mrf_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'base_estimator'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = new_df  # Feature matrix\n",
    "y = imputed_df['Q16'] \n",
    "\n",
    "\n",
    "# Sabit özellikleri çıkar\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "# Önceden oluşturulmuş genişletilmiş özellik setini ve hedef değişkeni kullanarak veri setini oluşturun\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest sınıflandırıcı oluşturun\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, base_estimator=RandomForestClassifier(n_estimators=50, max_depth=1))\n",
    "\n",
    "\n",
    "# Modeli eğitin\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba27baac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Model oluşturma\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(units=128, activation='relu', input_shape=(X_train_balanced.shape[1],)))\n",
    "model.add(layers.Dense(units=256, activation='relu'))  # Increase units\n",
    "model.add(layers.Dense(units=128, activation='relu'))  # Add more layers\n",
    "model.add(layers.Dense(units=64, activation='relu'))\n",
    "model.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# Modeli derleme\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Modeli eğitme\n",
    "model.fit(X_train_balanced, y_train_balanced, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Test seti üzerinde modelin performansını değerlendirme\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4215fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86806638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1cb462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0758b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66854f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52215099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f2de3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2635c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173a0744",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, RobustScaler\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "# Aykırı değerleri ele //\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "\n",
    "# Check if there are samples remaining after removing outliers\n",
    "if X.shape[0] > 0:\n",
    "    # Genişletilmiş özellik setini oluştur\n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "\n",
    "    # Özellikleri RobustScaler ile ölçeklendirme\n",
    "    scaler = RobustScaler()\n",
    "    X_scaled = scaler.fit_transform(X_poly)\n",
    "\n",
    "    # Veriyi train ve test setlerine ayırma\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create RandomForestClassifier with the best parameters\n",
    "    rf_classifier = RandomForestClassifier(max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200)\n",
    "\n",
    "    # Modeli eğitin\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Test seti üzerinde tahminler yapın\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    # Doğruluk skorunu değerlendirin\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "else:\n",
    "    print(\"No samples remaining after removing outliers.\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c5cc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, RobustScaler\n",
    "from scipy import stats\n",
    "\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "\n",
    "\n",
    "# Genişletilmiş özellik setini oluştur\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Özellikleri RobustScaler ile ölçeklendirme\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X_poly)\n",
    "\n",
    "# Veriyi train ve test setlerine ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Create RandomForestClassifier with the best parameters\n",
    "rf_classifier = RandomForestClassifier(max_depth= 10, min_samples_leaf= 2, min_samples_split= 5, n_estimators= 200)\n",
    "\n",
    "# Modeli eğitin\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29008c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, RobustScaler\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "\n",
    "# Sabit özellikleri çıkar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "\n",
    "# Genişletilmiş özellik setini oluştur\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Özellikleri RobustScaler ile ölçeklendirme\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X_poly)\n",
    "\n",
    "# Veriyi train ve test setlerine ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest sınıflandırıcı oluşturun\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Modeli eğitin\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e552b27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X, new_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Kullanılacak sınıflandırıcı modelleri\n",
    "classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'SVM': SVC(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'Neural Network': MLPClassifier(max_iter=1000),\n",
    "    'QDA': QuadraticDiscriminantAnalysis(),\n",
    "    'AdaBoost': AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "# Her bir sınıflandırıcı modeli için RFE uygulayarak doğruluk skorlarını ölçün\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"Evaluating {clf_name} with RFE:\")\n",
    "    \n",
    "    # RFE'yi kullanarak özellik seçimi yapın\n",
    "    rfe = RFE(clf, n_features_to_select=5)  # Örneğin, 5 özellik bırakmak istiyoruz\n",
    "    X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "    \n",
    "    # Modeli eğitin\n",
    "    clf.fit(X_train_rfe, y_train)\n",
    "    \n",
    "    # Test seti üzerinde tahminler yapın\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    y_pred = clf.predict(X_test_rfe)\n",
    "    \n",
    "    # Doğruluk skorunu değerlendirin\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "    print(\"-------------------------------------------\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca32e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "# Örnek veri setini oluştur\n",
    "# imputed_df'yi veri setiniz olarak kullanın\n",
    "\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "\n",
    "\"\"\"z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "new_X = X[filtered_entries]\n",
    "new_y = y[filtered_entries]\"\"\"\n",
    "\n",
    "# Özellik seçimi: Pearson korelasyon katsayısı ile en iyi k özelliği seç\n",
    "k_best_features = 2\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "X_selected = feature_selector.fit_transform(X, y)\n",
    "\n",
    "# Veriyi standartlaştır\n",
    "scaler = StandardScaler()\n",
    "X_selected_standardized = scaler.fit_transform(X_selected)\n",
    "\n",
    "# Decision Tree modelini tanımla\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(dt_model, X_selected_standardized, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76723a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "# Özellik seçimi: Pearson korelasyon katsayısı ile en iyi k özelliği seç\n",
    "k_best_features = 5\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "X_selected = feature_selector.fit_transform(X, y)\n",
    "\n",
    "# Eğitim ve test setlerini oluştur\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Veriyi standartlaştır\n",
    "scaler = StandardScaler()\n",
    "X_selected_standardized = scaler.fit_transform(X_selected)\n",
    "\n",
    "# KNN modelini tanımla\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(knn_model, X_selected_standardized, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7982cbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "# Özellik seçimi: Pearson korelasyon katsayısı ile en iyi k özelliği seç\n",
    "k_best_features = 5\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "X_selected = feature_selector.fit_transform(X, y)\n",
    "\n",
    "# Eğitim ve test setlerini oluştur\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Veriyi standartlaştır\n",
    "scaler = StandardScaler()\n",
    "X_selected_standardized = scaler.fit_transform(X_selected)\n",
    "\n",
    "# Logistik Regresyon modelini tanımla\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(logreg_model, X_selected_standardized, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc78fc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "\n",
    "# Özellik seçimi: Pearson korelasyon katsayısı ile en iyi k özelliği seç\n",
    "k_best_features = 8\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "X_selected = feature_selector.fit_transform(X, y)\n",
    "\n",
    "# Eğitim ve test setlerini oluştur\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Veriyi standartlaştır\n",
    "scaler = StandardScaler()\n",
    "X_selected_standardized = scaler.fit_transform(X_selected)\n",
    "\n",
    "# Gradient Boosting modelini tanımla\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(gb_model, X_selected_standardized, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f9f70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "# Özellik seçimi: Pearson korelasyon katsayısı ile en iyi k özelliği seç\n",
    "k_best_features = 20\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "X_selected = feature_selector.fit_transform(X, y)\n",
    "\n",
    "# Eğitim ve test setlerini oluştur\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Veriyi standartlaştır\n",
    "scaler = StandardScaler()\n",
    "X_selected_standardized = scaler.fit_transform(X_selected)\n",
    "\n",
    "# Random Forest modelini tanımla\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(rf_model, X_selected_standardized, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db27a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "\n",
    "\n",
    "# Özellik seçimi: Pearson korelasyon katsayısı ile en iyi k özelliği seç\n",
    "k_best_features = 2\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "X_selected = feature_selector.fit_transform(X, y)\n",
    "\n",
    "# Eğitim ve test setlerini oluştur\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Veriyi standartlaştır\n",
    "scaler = StandardScaler()\n",
    "X_selected_standardized = scaler.fit_transform(X_selected)\n",
    "\n",
    "# SVM modelini tanımla\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(svm_model, X_selected_standardized, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f46ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PCA uygula\n",
    "pca = PCA(n_components=5)  # Örneğin, 5 bileşen kullanalım\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# SVM modelini tanımla\n",
    "svm_model = SVC()\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(svm_model, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31463e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PCA uygula\n",
    "pca = PCA(n_components=5)  # Örneğin, 5 bileşen kullanalım\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Neural Networks modelini tanımla\n",
    "nn_model = MLPClassifier(max_iter=1000)  # max_iter parametresi artırılabilir\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(nn_model, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3ec462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PCA uygula\n",
    "pca = PCA(n_components=5)  # Örneğin, 5 bileşen kullanalım\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Random Forest modelini tanımla\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(rf_model, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8aeb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PCA uygula\n",
    "pca = PCA(n_components=5)  # Örneğin, 5 bileşen kullanalım\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Decision Tree modelini tanımla\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(dt_model, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c206cfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PCA uygula\n",
    "pca = PCA(n_components=5)  # Örneğin, 5 bileşen kullanalım\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# K-Nearest Neighbors modelini tanımla\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(knn_model, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a28f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit özellikleri çıkar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PCA uygula\n",
    "pca = PCA(n_components=5)  # Örneğin, 5 bileşen kullanalım\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Naive Bayes modelini tanımla\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(nb_model, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eb3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "# Daha sonra k-means işlemlerine devam edebilirsiniz\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "y_kmeans = kmeans.fit_predict(X)\n",
    "\n",
    "# Elde edilen kümeleme sonuçlarını yeni bir özellik olarak ekleyin\n",
    "X_with_clusters = pd.concat([pd.DataFrame(X), pd.DataFrame({'Cluster': y_kmeans})], axis=1)\n",
    "\n",
    "# Veriyi eğitim ve test setlerine bölelim\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_with_clusters, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression modelini tanımla\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(logistic_regression, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = cv_scores.mean()\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5318cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Öncelikle veriyi standartlaştırın (PCA için önemlidir)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# PCA ile boyut azaltma\n",
    "pca = PCA(n_components=5)  # Örneğin, 5 bileşen kullanmak istiyoruz\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Linear SVM modelini tanımla\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(svm_classifier, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = cv_scores.mean()\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316a0cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Öncelikle veriyi standartlaştırın (PCA için önemlidir)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# PCA ile boyut azaltma\n",
    "pca = PCA(n_components=5)  # Örneğin, 5 bileşen kullanmak istiyoruz\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Logistic Regression modelini tanımla\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(logreg, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = cv_scores.mean()\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aeed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression modeli\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# RFECV'yi kullanarak özellik seçimi yapın\n",
    "rfecv = RFECV(estimator=logreg, step=1, cv=5, scoring='accuracy')  # cv=5, 5-fold cross-validation kullanıyoruz\n",
    "X_train_rfecv = rfecv.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eğitin\n",
    "logreg.fit(X_train_rfecv, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "X_test_rfecv = rfecv.transform(X_test)\n",
    "y_pred = logreg.predict(X_test_rfecv)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Model Accuracy with RFECV: {accuracy:.4f}\")\n",
    "\n",
    "# Modelin performansını 5 katlı çapraz doğrulama ile değerlendirin\n",
    "cv_scores = cross_val_score(logreg, X_train_rfecv, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = cv_scores.mean()\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f742edf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression modeli\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# RFECV'yi kullanarak özellik seçimi yapın\n",
    "rfecv = RFECV(estimator=logreg, step=1, cv=5, scoring='accuracy')  # cv=5, 5-fold cross-validation kullanıyoruz\n",
    "X_train_rfecv = rfecv.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eğitin\n",
    "logreg.fit(X_train_rfecv, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "X_test_rfecv = rfecv.transform(X_test)\n",
    "y_pred = logreg.predict(X_test_rfecv)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Model Accuracy with RFECV: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5e9374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit özellikleri çıkar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression modeli\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# RFE'yi kullanarak özellik seçimi yapın\n",
    "rfe = RFE(logreg, n_features_to_select=5)  # Örneğin, 5 özellik bırakmak istiyoruz\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eğitin\n",
    "logreg.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "y_pred = logreg.predict(X_test_rfe)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Modelin performansını 5 katlı çapraz doğrulama ile değerlendirin\n",
    "cv_scores = cross_val_score(logreg, X_train_rfe, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = cv_scores.mean()\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72398fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit özellikleri çıkar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression modeli\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# RFE'yi kullanarak özellik seçimi yapın\n",
    "rfe = RFE(logreg, n_features_to_select=5)  # Örneğin, 5 özellik bırakmak istiyoruz\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eğitin\n",
    "logreg.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "y_pred = logreg.predict(X_test_rfe)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Model Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176d67eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit özellikleri çıkar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# AdaBoostClassifier modeli\n",
    "ada_clf = AdaBoostClassifier()\n",
    "\n",
    "# SelectFromModel kullanarak özellik seçimi yapın\n",
    "sfm = SelectFromModel(ada_clf, threshold=-np.inf, max_features=5)  # Örneğin, 5 özellik bırakmak istiyoruz\n",
    "X_train_sfm = sfm.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eğitin\n",
    "ada_clf.fit(X_train_sfm, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "X_test_sfm = sfm.transform(X_test)\n",
    "y_pred = ada_clf.predict(X_test_sfm)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Modelin performansını 5 katlı çapraz doğrulama ile değerlendirin\n",
    "cv_scores = cross_val_score(ada_clf, X_train_sfm, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = cv_scores.mean()\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f693f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit özellikleri çıkar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# AdaBoostClassifier modeli\n",
    "ada_clf = AdaBoostClassifier()\n",
    "\n",
    "# SelectFromModel kullanarak özellik seçimi yapın\n",
    "sfm = SelectFromModel(ada_clf, threshold=-np.inf, max_features=5)  # Örneğin, 5 özellik bırakmak istiyoruz\n",
    "X_train_sfm = sfm.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eğitin\n",
    "ada_clf.fit(X_train_sfm, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "X_test_sfm = sfm.transform(X_test)\n",
    "y_pred = ada_clf.predict(X_test_sfm)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ab5794",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit özellikleri çıkar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Gradient Boosting modeli\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "# RFE'yi kullanarak özellik seçimi yapın\n",
    "rfe = RFE(clf, n_features_to_select=5)  # Örneğin, 5 özellik bırakmak istiyoruz\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eğitin\n",
    "clf.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "y_pred = clf.predict(X_test_rfe)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Modelin performansını 5 katlı çapraz doğrulama ile değerlendirin\n",
    "cv_scores = cross_val_score(clf, X_train_rfe, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc63929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "def kendall_tau(y_true, y_pred):\n",
    "    concordant_pairs = 0\n",
    "    discordant_pairs = 0\n",
    "\n",
    "    n = len(y_true)\n",
    "\n",
    "    for i, j in combinations(range(n), 2):\n",
    "        # İki çiftin sıralama durumunu kontrol et\n",
    "        pred_order_diff = np.sign(y_pred[i] - y_pred[j])\n",
    "        true_order_diff = np.sign(y_true[i] - y_true[j])\n",
    "\n",
    "        # Concordant veya discordant durumu kontrol et\n",
    "        if pred_order_diff == true_order_diff:\n",
    "            concordant_pairs += 1\n",
    "        else:\n",
    "            discordant_pairs += 1\n",
    "\n",
    "    # Paydan sıfır ise nan döndür\n",
    "    if (concordant_pairs + discordant_pairs) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    # Kendall Tau Korelasyonu hesapla\n",
    "    tau = (concordant_pairs - discordant_pairs) / np.sqrt((concordant_pairs + discordant_pairs) * n * (n - 1) / 2)\n",
    "\n",
    "    return tau\n",
    "\n",
    "\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "# StratifiedKFold ile 5-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Rank-SVM modelini tanımla\n",
    "rank_svm_model = SVC(kernel='linear')\n",
    "\n",
    "# Feature selection için SelectKBest ve f_classif kullan\n",
    "k_best_features = 5\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "\n",
    "# 5-fold cross-validation ile modelin performansını değerlendir\n",
    "cv_kendall_tau_scores = cross_val_score(rank_svm_model, X, y, cv=cv, scoring=make_scorer(kendall_tau, greater_is_better=True))\n",
    "cv_accuracy_scores = cross_val_score(rank_svm_model, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için skorları yazdır\n",
    "for i, (kendall_tau, accuracy) in enumerate(zip(cv_kendall_tau_scores, cv_accuracy_scores), start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Kendall Tau Korelasyonu = {kendall_tau:.4f}, Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "# Ortalama skorları hesapla\n",
    "mean_kendall_tau = np.mean(cv_kendall_tau_scores)\n",
    "mean_accuracy = np.mean(cv_accuracy_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Kendall Tau Korelasyonu:\", mean_kendall_tau)\n",
    "print(\"5 Katlı Çapraz Doğrulama İle Ortalama Accuracy:\", mean_accuracy)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94039217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Yeni_X ve yeni_y verilerini eğitim ve test setlerine bölelim\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X, new_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# RandomForestClassifier'ı sınıf ağırlıklarıyla oluşturun\n",
    "rf_classifier = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Modeli eğitin\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0dc903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Önceden belirlenmiş olan X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örnek olarak, new_X ve new_y'yi kullanalım\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X, new_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# SMOTE'u kullanarak oversampling\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# RandomForestClassifier'ı sınıf ağırlıklarıyla oluşturun\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Modeli eğitin\n",
    "rf_classifier.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391fc011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "# Z puanlarına dayalı olarak aykırı değerleri ele\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "\n",
    "# Sabit özellikleri çıkar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "\n",
    "# Genişletilmiş özellik setini oluştur\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Random Forest sınıflandırıcı oluşturun\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# 5-fold çapraz doğrulama için StratifiedKFold kullanın\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Genişletilmiş özellik seti ve hedef değişkeni ile bir pipeline oluşturun\n",
    "model = make_pipeline(PolynomialFeatures(degree=2), RandomForestClassifier())\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b36ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "# Aykırı değerleri ele\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "\n",
    "# Sabit özellikleri çıkar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "\n",
    "# Genişletilmiş özellik setini oluştur\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Random Forest sınıflandırıcı oluşturun\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Parametre aralığını belirle\n",
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [50, 100, 200],\n",
    "    'randomforestclassifier__max_depth': [None, 10, 20],\n",
    "    'randomforestclassifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Pipeline ve GridSearchCV kullanarak en iyi parametreleri bulun\n",
    "model = make_pipeline(PolynomialFeatures(degree=2), RandomForestClassifier())\n",
    "grid_search = GridSearchCV(model, param_grid, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring='accuracy')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# En iyi parametreleri görüntüleme\n",
    "print(\"En iyi parametreler:\", grid_search.best_params_)\n",
    "\n",
    "# En iyi modeli kullanma\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1f9f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, RobustScaler\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "# Aykırı değerleri ele\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "\n",
    "# Sabit özellikleri çıkar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "\n",
    "# Genişletilmiş özellik setini oluştur\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Özellikleri RobustScaler ile ölçeklendirme\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X_poly)\n",
    "\n",
    "# Veriyi train ve test setlerine ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest sınıflandırıcı oluşturun\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Modeli eğitin\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ff9a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "X = imputed_df.drop(target_column, axis=1)\n",
    "\n",
    "# Min-Max normalizasyonu uygulayın\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Normalizasyon sonrası veriyi yeni bir veri çerçevesine ekleyin (isteğe bağlı)\n",
    "normalized_df = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "\n",
    "# Normalizasyon sonrası veriyi yazdırın (isteğe bağlı)\n",
    "print(normalized_df)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751571d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Veriyi yükleyin veya oluşturun\n",
    "# Örneğin, imputed_df adlı bir veri çerçevesiniz olduğunu varsayalım\n",
    "\n",
    "# Hedef değişkeni (target attribute) ve özellikleri ayırın\n",
    "target_column = 'Q16'\n",
    "y = imputed_df[target_column]\n",
    "X = imputed_df.drop(target_column, axis=1)\n",
    "\n",
    "# Robust Scaler normalizasyonu uygulayın\n",
    "scaler = RobustScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Normalizasyon sonrası veriyi yeni bir veri çerçevesine ekleyin (isteğe bağlı)\n",
    "normalized_df = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "\n",
    "# Normalizasyon sonrası veriyi yazdırın (isteğe bağlı)\n",
    "print(normalized_df)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba1d5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50214f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.feature_selection import f_classif, SelectKBest\n",
    "\n",
    "\n",
    "\n",
    "# F-Score ile en iyi özellikleri seçme\n",
    "f_score_selector = SelectKBest(f_classif, k='all')\n",
    "X_f_score = f_score_selector.fit_transform(X, y)\n",
    "\n",
    "# F-Score değerleri\n",
    "f_scores = f_score_selector.scores_\n",
    "\n",
    "# Her bir sütun için F-Score değerlerini yazdırma\n",
    "for feature, score in zip(X.columns, f_scores):\n",
    "    print(f\"Sütun: {feature}, F-Score: {score}\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a4b604",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "target_column = 'Q16'\n",
    "\n",
    "# Assuming 'X' is your feature matrix and 'y' is your target variable\n",
    "X = imputed_df.drop(target_column, axis=1)  # Feature matrix\n",
    "y = imputed_df[target_column]  # Target variable\n",
    "\n",
    "# F-Score ile en iyi özellikleri seçme\n",
    "f_score_selector = SelectKBest(f_classif, k='all')\n",
    "X_f_score = f_score_selector.fit_transform(X, y)\n",
    "\n",
    "# F-Score değerleri\n",
    "f_scores = f_score_selector.scores_\n",
    "\n",
    "# Sütunları F-Score değerlerine göre sırala\n",
    "sorted_features = [feature for _, feature in sorted(zip(f_scores, X.columns), reverse=True)]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # Define your cross-validation strategy\n",
    "\n",
    "classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),  # Increase max_iter to 1000 or more\n",
    "    'SVM': SVC(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'Neural Network': MLPClassifier(max_iter=1000), \n",
    "    'QDA': QuadraticDiscriminantAnalysis(),\n",
    "    'AdaBoost': AdaBoostClassifier()\n",
    "    # Add more classifiers here\n",
    "}\n",
    "\n",
    "# Define the metric to be evaluated\n",
    "scoring = {\n",
    "    'Accuracy': 'accuracy',\n",
    "}\n",
    "\n",
    "# Perform 5-fold cross-validation with each classifier using selected features\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"Evaluating {clf_name} with F-Score Selected Features:\")\n",
    "    scores = cross_validate(clf, X[sorted_features], y, cv=skf, scoring=scoring)\n",
    "    \n",
    "    acc_mean = scores['test_Accuracy'].mean()\n",
    "    \n",
    "    print(f\"Accuracy: {acc_mean:.4f}\")\n",
    "    print(\"-------------------------------------------\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eac1441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405f0b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Her bir özelliği ve onun F-Score değerini içeren bir tuple listesi\n",
    "feature_score_pairs = list(zip(X.columns, f_scores))\n",
    "\n",
    "# F-Score değerlerine göre sıralama\n",
    "feature_score_pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# En fazla k özelliği seçme (k'i istediğiniz sayıya ayarlayabilirsiniz)\n",
    "max_k = 10\n",
    "for k in range(1, max_k + 1):\n",
    "    # En güçlü k özellikleri seçme\n",
    "    top_k_features = [feature for feature, _ in feature_score_pairs[:k]]\n",
    "    \n",
    "    # Seçilen en güçlü özelliklere sahip veri çerçevesini oluşturma\n",
    "    selected_df = imputed_df[top_k_features + ['Q16']]\n",
    "    \n",
    "    # Hedef değişkeni ve özellikleri ayırma\n",
    "    X_selected = selected_df.drop('Q16', axis=1)\n",
    "    y_selected = selected_df['Q16']\n",
    "    \n",
    "    # Veriyi eğitim ve test setlerine ayırma\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y_selected, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Sınıflandırıcı modelini oluşturma (Random Forest kullanıldı)\n",
    "    classifier = RandomForestClassifier(random_state=42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Test seti üzerinde tahmin yapma\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Doğruluk hesapla\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'k={k}, Doğruluk: {accuracy}')\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617eb0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"numeric_columns = imputed_df.select_dtypes(include=np.number).columns\n",
    "df_numeric = imputed_df[numeric_columns].apply(pd.to_numeric)\n",
    "# Veriyi standartlaştırın (PCA, verinin standartlaştırılmış olmasını ister)\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_numeric)\n",
    "\n",
    "# PCA modelini oluşturun ve uygulayın\n",
    "pca = PCA()\n",
    "pca_result = pca.fit_transform(df_scaled)\n",
    "\n",
    "# Elde edilen bileşenlerin varyans oranlarını ve kümülatif varyans oranlarını çizin\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, label='Explained Variance Ratio')\n",
    "plt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o', linestyle='--', color='orange', label='Cumulative Explained Variance')\n",
    "plt.title('PCA - Explained Variance')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Variance Ratio')\n",
    "plt.legend()\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5988f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"plt.figure(figsize=(16, 8))\n",
    "sns.boxplot(data=imputed_df, orient='h', palette='Set2')\n",
    "plt.title('Tüm Sayısal Değişkenlerin Box Plot\\'u')\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b738f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# IQR tabanlı aykırı değer tespiti\n",
    "Q1 = df_numeric.quantile(0.25)\n",
    "Q3 = df_numeric.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Aykırı değerleri içeren bir maske oluşturun\n",
    "outlier_mask_iqr = ((df_numeric < (Q1 - 1.5 * IQR)) | (df_numeric > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "# Aykırı değerlere sahip olan satırları göster\n",
    "outliers_iqr = df_best_imputed[outlier_mask_iqr]\n",
    "print(outliers_iqr)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62fe53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# IQR tabanlı outlier'ları tespit etme\n",
    "Q1 = df_numeric.quantile(0.25)\n",
    "Q3 = df_numeric.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Aykırı değerlere sahip olmayan satırları seçme\n",
    "df_no_outliers_iqr = df_numeric[~((df_numeric < (Q1 - 1.5 * IQR)) | (df_numeric > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a71702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#outlier çıkardıkran sonra PCA \n",
    "numeric_columns = df_no_outliers_iqr.select_dtypes(include=np.number).columns\n",
    "df_numeric = df_no_outliers_iqr[numeric_columns].apply(pd.to_numeric)\n",
    "# Veriyi standartlaştırın (PCA, verinin standartlaştırılmış olmasını ister)\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_numeric)\n",
    "\n",
    "# PCA modelini oluşturun ve uygulayın\n",
    "pca = PCA()\n",
    "pca_result = pca.fit_transform(df_scaled)\n",
    "\n",
    "# Elde edilen bileşenlerin varyans oranlarını ve kümülatif varyans oranlarını çizin\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, label='Explained Variance Ratio')\n",
    "plt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o', linestyle='--', color='orange', label='Cumulative Explained Variance')\n",
    "plt.title('PCA - Explained Variance')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Variance Ratio')\n",
    "plt.legend()\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a68d756",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#Outlier çıkardıkran sonra box plot\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.boxplot(data=df_no_outliers_iqr, orient='h', palette='Set2')\n",
    "plt.title('Tüm Sayısal Değişkenlerin Box Plot\\'u')\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce7726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#Normalizasyon\n",
    "# Min-Max normalizasyonu için ölçekleyiciyi oluşturun\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizasyon işlemini uygulayın ve NumPy dizisini DataFrame'e dönüştürün\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df_no_outliers_iqr), columns=df_no_outliers_iqr.columns)\n",
    "\n",
    "# Veri seti özet istatistikleri\n",
    "print(df_normalized.describe())\n",
    "\n",
    "# Histogramlar\n",
    "df_normalized.hist(figsize=(10, 8), bins=20)\n",
    "plt.show()\n",
    "\n",
    "# Kutu Grafikleri\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(data=df_normalized)\n",
    "plt.show()\n",
    "\n",
    "# Korelasyon Matrisi\n",
    "correlation_matrix = df_normalized.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\")\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440d2bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
