{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7db9985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2675bd3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q11_1</th>\n",
       "      <th>Q11_2</th>\n",
       "      <th>Q11_3</th>\n",
       "      <th>Q11_4</th>\n",
       "      <th>Q11_5</th>\n",
       "      <th>Q11_6</th>\n",
       "      <th>Q11_7</th>\n",
       "      <th>Q11_8</th>\n",
       "      <th>Q11_9</th>\n",
       "      <th>Q11_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q18_17</th>\n",
       "      <th>Q18_18</th>\n",
       "      <th>Q18_19</th>\n",
       "      <th>Q18_20</th>\n",
       "      <th>Q18_21</th>\n",
       "      <th>Q18_22</th>\n",
       "      <th>Q18_23</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q11_1  Q11_2  Q11_3  Q11_4  Q11_5  Q11_6  Q11_7  Q11_8  Q11_9  Q11_10  ...  \\\n",
       "0      0      0      0      1      1      0      0      1      0       0  ...   \n",
       "1      1      0      0      1      0      0      1      0      0       1  ...   \n",
       "2      1      1      0      1      0      0      1      1      0       1  ...   \n",
       "3      0      0      0      0      0      0      0      0      0       0  ...   \n",
       "4      1      1      0      1      0      0      1      1      0       1  ...   \n",
       "\n",
       "   Q18_17  Q18_18  Q18_19  Q18_20  Q18_21  Q18_22  Q18_23  Q20  Q21  Q16  \n",
       "0       5       5       5       5       5       5       5    3    3    A  \n",
       "1       4       2       4       2       2       2       2    3    3    D  \n",
       "2       4       4       ?       ?       4       2       4    4    1    A  \n",
       "3       ?       ?       ?       ?       ?       ?       ?    3    3    C  \n",
       "4       ?       ?       1       1       ?       ?       ?    3    3    D  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel('Course Project - Data for Classification - Electric Vehicles.xls')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7593525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q11_1      int64\n",
      "Q11_2      int64\n",
      "Q11_3      int64\n",
      "Q11_4      int64\n",
      "Q11_5      int64\n",
      "           ...  \n",
      "Q18_22    object\n",
      "Q18_23    object\n",
      "Q20        int64\n",
      "Q21        int64\n",
      "Q16       object\n",
      "Length: 75, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23070e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A' 'D' 'C' 'B']\n"
     ]
    }
   ],
   "source": [
    "print(df['Q16'].unique()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f0af2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    2883\n",
       "B    1526\n",
       "C     892\n",
       "D     807\n",
       "Name: Q16, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Q16'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5a39c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q11_1</th>\n",
       "      <th>Q11_2</th>\n",
       "      <th>Q11_3</th>\n",
       "      <th>Q11_4</th>\n",
       "      <th>Q11_5</th>\n",
       "      <th>Q11_6</th>\n",
       "      <th>Q11_7</th>\n",
       "      <th>Q11_8</th>\n",
       "      <th>Q11_9</th>\n",
       "      <th>Q11_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q18_17</th>\n",
       "      <th>Q18_18</th>\n",
       "      <th>Q18_19</th>\n",
       "      <th>Q18_20</th>\n",
       "      <th>Q18_21</th>\n",
       "      <th>Q18_22</th>\n",
       "      <th>Q18_23</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q11_1  Q11_2  Q11_3  Q11_4  Q11_5  Q11_6  Q11_7  Q11_8  Q11_9  Q11_10  ...  \\\n",
       "0      0      0      0      1      1      0      0      1      0       0  ...   \n",
       "1      1      0      0      1      0      0      1      0      0       1  ...   \n",
       "2      1      1      0      1      0      0      1      1      0       1  ...   \n",
       "3      0      0      0      0      0      0      0      0      0       0  ...   \n",
       "4      1      1      0      1      0      0      1      1      0       1  ...   \n",
       "\n",
       "   Q18_17  Q18_18  Q18_19  Q18_20  Q18_21  Q18_22  Q18_23  Q20  Q21  Q16  \n",
       "0       5       5       5       5       5       5       5    3    3    A  \n",
       "1       4       2       4       2       2       2       2    3    3    D  \n",
       "2       4       4       ?       ?       4       2       4    4    1    A  \n",
       "3       ?       ?       ?       ?       ?       ?       ?    3    3    C  \n",
       "4       ?       ?       1       1       ?       ?       ?    3    3    D  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd25157f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q11_1</th>\n",
       "      <th>Q11_2</th>\n",
       "      <th>Q11_3</th>\n",
       "      <th>Q11_4</th>\n",
       "      <th>Q11_5</th>\n",
       "      <th>Q11_6</th>\n",
       "      <th>Q11_7</th>\n",
       "      <th>Q11_8</th>\n",
       "      <th>Q11_9</th>\n",
       "      <th>Q11_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q18_17</th>\n",
       "      <th>Q18_18</th>\n",
       "      <th>Q18_19</th>\n",
       "      <th>Q18_20</th>\n",
       "      <th>Q18_21</th>\n",
       "      <th>Q18_22</th>\n",
       "      <th>Q18_23</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q11_1  Q11_2  Q11_3  Q11_4  Q11_5  Q11_6  Q11_7  Q11_8  Q11_9  Q11_10  ...  \\\n",
       "0      0      0      0      1      1      0      0      1      0       0  ...   \n",
       "1      1      0      0      1      0      0      1      0      0       1  ...   \n",
       "2      1      1      0      1      0      0      1      1      0       1  ...   \n",
       "3      0      0      0      0      0      0      0      0      0       0  ...   \n",
       "4      1      1      0      1      0      0      1      1      0       1  ...   \n",
       "\n",
       "   Q18_17  Q18_18  Q18_19  Q18_20  Q18_21  Q18_22  Q18_23  Q20  Q21  Q16  \n",
       "0     5.0     5.0     5.0     5.0     5.0     5.0     5.0    3    3    A  \n",
       "1     4.0     2.0     4.0     2.0     2.0     2.0     2.0    3    3    D  \n",
       "2     4.0     4.0     NaN     NaN     4.0     2.0     4.0    4    1    A  \n",
       "3     NaN     NaN     NaN     NaN     NaN     NaN     NaN    3    3    C  \n",
       "4     NaN     NaN     1.0     1.0     NaN     NaN     NaN    3    3    D  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'df' is your DataFrame\n",
    "import numpy as np\n",
    "\n",
    "# Replace non-numeric values with NaN\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36ed904e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed data shape for k=1: (6108, 74)\n",
      "Imputed data shape for k=3: (6108, 74)\n",
      "Imputed data shape for k=5: (6108, 74)\n",
      "Imputed data shape for k=7: (6108, 74)\n",
      "Imputed data shape for k=9: (6108, 74)\n",
      "Imputed data shape for k=11: (6108, 74)\n",
      "Imputed data shape for k=15: (6108, 74)\n",
      "Imputed data shape for k=19: (6108, 74)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'exclude_column_name' is the column to exclude\n",
    "exclude_column_name = 'Q16'\n",
    "column_to_exclude = df[exclude_column_name]\n",
    "\n",
    "# Create a list of k values\n",
    "k_values = [1, 3, 5, 7, 9,11,15,19]\n",
    "\n",
    "# Loop through each k value\n",
    "for k in k_values:\n",
    "    # Drop the column you want to exclude\n",
    "    columns_to_impute = df.drop(columns=[exclude_column_name])\n",
    "    \n",
    "    # Apply KNN imputation for the current k value\n",
    "    imputer = KNNImputer(n_neighbors=k)\n",
    "    imputed_data = imputer.fit_transform(columns_to_impute)\n",
    "    \n",
    "    # Use the imputed data for further processing or modeling\n",
    "    # ...\n",
    "    imputed_df = pd.DataFrame(imputed_data, columns=columns_to_impute.columns)\n",
    "    imputed_df[exclude_column_name] = column_to_exclude\n",
    "\n",
    "    # Example: Print imputed data shape\n",
    "    print(f\"Imputed data shape for k={k}: {imputed_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0ca55a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q11_1: float64\n",
      "Q11_2: float64\n",
      "Q11_3: float64\n",
      "Q11_4: float64\n",
      "Q11_5: float64\n",
      "Q11_6: float64\n",
      "Q11_7: float64\n",
      "Q11_8: float64\n",
      "Q11_9: float64\n",
      "Q11_10: float64\n",
      "Q11_11: float64\n",
      "Q11_12: float64\n",
      "Q11_13: float64\n",
      "Q11_Dont_Know: float64\n",
      "Q12_1: float64\n",
      "Q12_2: float64\n",
      "Q12_3: float64\n",
      "Q12_4: float64\n",
      "Q12_5: float64\n",
      "Q12_6: float64\n",
      "Q12_7: float64\n",
      "Q12_8: float64\n",
      "Q12_9: float64\n",
      "Q12_10: float64\n",
      "Q12_11: float64\n",
      "Q12_12: float64\n",
      "Q12_13: float64\n",
      "Q12_14: float64\n",
      "Q12_Dont_Know: float64\n",
      "Q13_1: float64\n",
      "Q13_2: float64\n",
      "Q13_3: float64\n",
      "Q13_4: float64\n",
      "Q13_5: float64\n",
      "Q13_6: float64\n",
      "Q13_7: float64\n",
      "Q13_8: float64\n",
      "Q13_9: float64\n",
      "Q13_10: float64\n",
      "Q13_11: float64\n",
      "Q13_12: float64\n",
      "Q13_13: float64\n",
      "Q13_14: float64\n",
      "Q13_15: float64\n",
      "Q13_16: float64\n",
      "Q13_Dont_Know: float64\n",
      "Q14: float64\n",
      "Q15: float64\n",
      "Q17: float64\n",
      "Q18_1: float64\n",
      "Q18_2: float64\n",
      "Q18_3: float64\n",
      "Q18_4: float64\n",
      "Q18_5: float64\n",
      "Q18_6: float64\n",
      "Q18_7: float64\n",
      "Q18_8: float64\n",
      "Q18_9: float64\n",
      "Q18_10: float64\n",
      "Q18_11: float64\n",
      "Q18_12: float64\n",
      "Q18_13: float64\n",
      "Q18_14: float64\n",
      "Q18_15: float64\n",
      "Q18_16: float64\n",
      "Q18_17: float64\n",
      "Q18_18: float64\n",
      "Q18_19: float64\n",
      "Q18_20: float64\n",
      "Q18_21: float64\n",
      "Q18_22: float64\n",
      "Q18_23: float64\n",
      "Q20: float64\n",
      "Q21: float64\n",
      "Q16: object\n"
     ]
    }
   ],
   "source": [
    "for column, dtype in imputed_df.dtypes.items():\n",
    "    print(f\"{column}: {dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca5caf35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q11_1     float64\n",
      "Q11_2     float64\n",
      "Q11_3     float64\n",
      "Q11_4     float64\n",
      "Q11_5     float64\n",
      "           ...   \n",
      "Q18_22    float64\n",
      "Q18_23    float64\n",
      "Q20       float64\n",
      "Q21       float64\n",
      "Q16        object\n",
      "Length: 75, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(imputed_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6da470d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q11_1</th>\n",
       "      <th>Q11_2</th>\n",
       "      <th>Q11_3</th>\n",
       "      <th>Q11_4</th>\n",
       "      <th>Q11_5</th>\n",
       "      <th>Q11_6</th>\n",
       "      <th>Q11_7</th>\n",
       "      <th>Q11_8</th>\n",
       "      <th>Q11_9</th>\n",
       "      <th>Q11_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q18_17</th>\n",
       "      <th>Q18_18</th>\n",
       "      <th>Q18_19</th>\n",
       "      <th>Q18_20</th>\n",
       "      <th>Q18_21</th>\n",
       "      <th>Q18_22</th>\n",
       "      <th>Q18_23</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.736842</td>\n",
       "      <td>2.368421</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.894737</td>\n",
       "      <td>2.842105</td>\n",
       "      <td>3.105263</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.105263</td>\n",
       "      <td>2.789474</td>\n",
       "      <td>2.684211</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.315789</td>\n",
       "      <td>1.842105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.052632</td>\n",
       "      <td>1.473684</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q11_1  Q11_2  Q11_3  Q11_4  Q11_5  Q11_6  Q11_7  Q11_8  Q11_9  Q11_10  ...  \\\n",
       "0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    1.0    0.0     0.0  ...   \n",
       "1    1.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0     1.0  ...   \n",
       "2    1.0    1.0    0.0    1.0    0.0    0.0    1.0    1.0    0.0     1.0  ...   \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0  ...   \n",
       "4    1.0    1.0    0.0    1.0    0.0    0.0    1.0    1.0    0.0     1.0  ...   \n",
       "\n",
       "     Q18_17    Q18_18    Q18_19    Q18_20    Q18_21    Q18_22    Q18_23  Q20  \\\n",
       "0  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000  3.0   \n",
       "1  4.000000  2.000000  4.000000  2.000000  2.000000  2.000000  2.000000  3.0   \n",
       "2  4.000000  4.000000  3.736842  2.368421  4.000000  2.000000  4.000000  4.0   \n",
       "3  2.894737  2.842105  3.105263  3.000000  3.105263  2.789474  2.684211  3.0   \n",
       "4  2.315789  1.842105  1.000000  1.000000  2.052632  1.473684  2.000000  3.0   \n",
       "\n",
       "   Q21  Q16  \n",
       "0  3.0    A  \n",
       "1  3.0    D  \n",
       "2  1.0    A  \n",
       "3  3.0    C  \n",
       "4  3.0    D  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_df.head()\n",
    "# missing values KNN kullanılarak en iyi k ddeğeri seçmeye çalışılarak dolduruldu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9339b831",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q11_1     0\n",
      "Q11_2     0\n",
      "Q11_3     0\n",
      "Q11_4     0\n",
      "Q11_5     0\n",
      "         ..\n",
      "Q18_22    0\n",
      "Q18_23    0\n",
      "Q20       0\n",
      "Q21       0\n",
      "Q16       0\n",
      "Length: 75, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(imputed_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a357f7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q11_1</th>\n",
       "      <th>Q11_2</th>\n",
       "      <th>Q11_3</th>\n",
       "      <th>Q11_4</th>\n",
       "      <th>Q11_5</th>\n",
       "      <th>Q11_6</th>\n",
       "      <th>Q11_7</th>\n",
       "      <th>Q11_8</th>\n",
       "      <th>Q11_9</th>\n",
       "      <th>Q11_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q18_17</th>\n",
       "      <th>Q18_18</th>\n",
       "      <th>Q18_19</th>\n",
       "      <th>Q18_20</th>\n",
       "      <th>Q18_21</th>\n",
       "      <th>Q18_22</th>\n",
       "      <th>Q18_23</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.736842</td>\n",
       "      <td>2.368421</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.894737</td>\n",
       "      <td>2.842105</td>\n",
       "      <td>3.105263</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.105263</td>\n",
       "      <td>2.789474</td>\n",
       "      <td>2.684211</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.315789</td>\n",
       "      <td>1.842105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.052632</td>\n",
       "      <td>1.473684</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q11_1  Q11_2  Q11_3  Q11_4  Q11_5  Q11_6  Q11_7  Q11_8  Q11_9  Q11_10  ...  \\\n",
       "0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    1.0    0.0     0.0  ...   \n",
       "1    1.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0     1.0  ...   \n",
       "2    1.0    1.0    0.0    1.0    0.0    0.0    1.0    1.0    0.0     1.0  ...   \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0  ...   \n",
       "4    1.0    1.0    0.0    1.0    0.0    0.0    1.0    1.0    0.0     1.0  ...   \n",
       "\n",
       "     Q18_17    Q18_18    Q18_19    Q18_20    Q18_21    Q18_22    Q18_23  Q20  \\\n",
       "0  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000  3.0   \n",
       "1  4.000000  2.000000  4.000000  2.000000  2.000000  2.000000  2.000000  3.0   \n",
       "2  4.000000  4.000000  3.736842  2.368421  4.000000  2.000000  4.000000  4.0   \n",
       "3  2.894737  2.842105  3.105263  3.000000  3.105263  2.789474  2.684211  3.0   \n",
       "4  2.315789  1.842105  1.000000  1.000000  2.052632  1.473684  2.000000  3.0   \n",
       "\n",
       "   Q21  Q16  \n",
       "0  3.0    A  \n",
       "1  3.0    D  \n",
       "2  1.0    A  \n",
       "3  3.0    C  \n",
       "4  3.0    D  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_df.head()\n",
    "#control amaclı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80961be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.feature_selection import RFE\\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.svm import SVC\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\n\\n# Önceden belirlenmiş X ve y\\'yi kullanalım\\n# X: Özellik matrisi, y: Hedef değişken\\n# Örneğin, new_X ve new_y\\'yi kullanalım\\nX = imputed_df.drop(\\'Q16\\', axis=1)\\ny = imputed_df[\\'Q16\\']\\nX_train, X_test, y_train, y_test = train_test_split(new_X, new_y, test_size=0.2, random_state=42)\\n\\n# Kullanılacak sınıflandırıcı modelleri\\nclassifiers = {\\n    \\'Random Forest\\': RandomForestClassifier(),\\n    \\'Gradient Boosting\\': GradientBoostingClassifier(),\\n    \\'Logistic Regression\\': LogisticRegression(max_iter=1000),\\n    \\'SVM\\': SVC(),\\n    \\'K-Nearest Neighbors\\': KNeighborsClassifier(),\\n    \\'Decision Tree\\': DecisionTreeClassifier(),\\n    \\'Gaussian Naive Bayes\\': GaussianNB(),\\n    \\'Neural Network\\': MLPClassifier(max_iter=1000),\\n    \\'QDA\\': QuadraticDiscriminantAnalysis(),\\n    \\'AdaBoost\\': AdaBoostClassifier()\\n}\\n\\n# Her bir sınıflandırıcı modeli için RFE uygulayarak doğruluk skorlarını ölçün\\nfor clf_name, clf in classifiers.items():\\n    print(f\"Evaluating {clf_name} with RFE:\")\\n    \\n    # RFE\\'yi kullanarak özellik seçimi yapın\\n    rfe = RFE(clf, n_features_to_select=5)  # Örneğin, 5 özellik bırakmak istiyoruz\\n    X_train_rfe = rfe.fit_transform(X_train, y_train)\\n    \\n    # Modeli eğitin\\n    clf.fit(X_train_rfe, y_train)\\n    \\n    # Test seti üzerinde tahminler yapın\\n    X_test_rfe = rfe.transform(X_test)\\n    y_pred = clf.predict(X_test_rfe)\\n    \\n    # Doğruluk skorunu değerlendirin\\n    accuracy = accuracy_score(y_test, y_pred)\\n    print(f\"Model Accuracy: {accuracy:.4f}\")\\n    print(\"-------------------------------------------\")\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X, new_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Kullanılacak sınıflandırıcı modelleri\n",
    "classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'SVM': SVC(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'Neural Network': MLPClassifier(max_iter=1000),\n",
    "    'QDA': QuadraticDiscriminantAnalysis(),\n",
    "    'AdaBoost': AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "# Her bir sınıflandırıcı modeli için RFE uygulayarak doğruluk skorlarını ölçün\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"Evaluating {clf_name} with RFE:\")\n",
    "    \n",
    "    # RFE'yi kullanarak özellik seçimi yapın\n",
    "    rfe = RFE(clf, n_features_to_select=5)  # Örneğin, 5 özellik bırakmak istiyoruz\n",
    "    X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "    \n",
    "    # Modeli eğitin\n",
    "    clf.fit(X_train_rfe, y_train)\n",
    "    \n",
    "    # Test seti üzerinde tahminler yapın\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    y_pred = clf.predict(X_test_rfe)\n",
    "    \n",
    "    # Doğruluk skorunu değerlendirin\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "    print(\"-------------------------------------------\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "83c3c674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çapraz Doğrulama Seti 1: Doğruluk = 0.5671031096563012\n",
      "Çapraz Doğrulama Seti 2: Doğruluk = 0.6145662847790507\n",
      "Çapraz Doğrulama Seti 3: Doğruluk = 0.6072013093289689\n",
      "Çapraz Doğrulama Seti 4: Doğruluk = 0.592956592956593\n",
      "Çapraz Doğrulama Seti 5: Doğruluk = 0.6003276003276004\n",
      "\n",
      "5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk: 0.5964309794097028\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "# Örnek veri setini oluştur\n",
    "# imputed_df'yi veri setiniz olarak kullanın\n",
    "\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "new_X = X[filtered_entries]\n",
    "new_y = y[filtered_entries]\n",
    "\n",
    "# Özellik seçimi: Pearson korelasyon katsayısı ile en iyi k özelliği seç\n",
    "k_best_features = 2\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "X_selected = feature_selector.fit_transform(X, y)\n",
    "\n",
    "# Veriyi standartlaştır\n",
    "scaler = StandardScaler()\n",
    "X_selected_standardized = scaler.fit_transform(X_selected)\n",
    "\n",
    "# Decision Tree modelini tanımla\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(dt_model, X_selected_standardized, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ef797745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çapraz Doğrulama Seti 1: Doğruluk = 0.5945945945945946\n",
      "Çapraz Doğrulama Seti 2: Doğruluk = 0.6136724960254372\n",
      "Çapraz Doğrulama Seti 3: Doğruluk = 0.6391096979332274\n",
      "Çapraz Doğrulama Seti 4: Doğruluk = 0.6194267515923567\n",
      "Çapraz Doğrulama Seti 5: Doğruluk = 0.6273885350318471\n",
      "\n",
      "5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk: 0.6188384150354926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "# Özellik seçimi: Pearson korelasyon katsayısı ile en iyi k özelliği seç\n",
    "k_best_features = 5\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "X_selected = feature_selector.fit_transform(X, y)\n",
    "\n",
    "# Eğitim ve test setlerini oluştur\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Veriyi standartlaştır\n",
    "scaler = StandardScaler()\n",
    "X_selected_standardized = scaler.fit_transform(X_selected)\n",
    "\n",
    "# KNN modelini tanımla\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(knn_model, X_selected_standardized, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bad4de46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çapraz Doğrulama Seti 1: Doğruluk = 0.6073131955484896\n",
      "Çapraz Doğrulama Seti 2: Doğruluk = 0.6200317965023847\n",
      "Çapraz Doğrulama Seti 3: Doğruluk = 0.6375198728139905\n",
      "Çapraz Doğrulama Seti 4: Doğruluk = 0.6337579617834395\n",
      "Çapraz Doğrulama Seti 5: Doğruluk = 0.6560509554140127\n",
      "\n",
      "5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk: 0.6309347564124634\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "# Özellik seçimi: Pearson korelasyon katsayısı ile en iyi k özelliği seç\n",
    "k_best_features = 5\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "X_selected = feature_selector.fit_transform(X, y)\n",
    "\n",
    "# Eğitim ve test setlerini oluştur\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Veriyi standartlaştır\n",
    "scaler = StandardScaler()\n",
    "X_selected_standardized = scaler.fit_transform(X_selected)\n",
    "\n",
    "# Logistik Regresyon modelini tanımla\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(logreg_model, X_selected_standardized, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "50559126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çapraz Doğrulama Seti 1: Doğruluk = 0.6232114467408585\n",
      "Çapraz Doğrulama Seti 2: Doğruluk = 0.6422893481717011\n",
      "Çapraz Doğrulama Seti 3: Doğruluk = 0.6422893481717011\n",
      "Çapraz Doğrulama Seti 4: Doğruluk = 0.6305732484076433\n",
      "Çapraz Doğrulama Seti 5: Doğruluk = 0.6480891719745223\n",
      "\n",
      "5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk: 0.6372905126932853\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "\n",
    "# Özellik seçimi: Pearson korelasyon katsayısı ile en iyi k özelliği seç\n",
    "k_best_features = 8\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "X_selected = feature_selector.fit_transform(X, y)\n",
    "\n",
    "# Eğitim ve test setlerini oluştur\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Veriyi standartlaştır\n",
    "scaler = StandardScaler()\n",
    "X_selected_standardized = scaler.fit_transform(X_selected)\n",
    "\n",
    "# Gradient Boosting modelini tanımla\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(gb_model, X_selected_standardized, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ef923cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çapraz Doğrulama Seti 1: Doğruluk = 0.6136724960254372\n",
      "Çapraz Doğrulama Seti 2: Doğruluk = 0.6454689984101749\n",
      "Çapraz Doğrulama Seti 3: Doğruluk = 0.6343402225755167\n",
      "Çapraz Doğrulama Seti 4: Doğruluk = 0.6528662420382165\n",
      "Çapraz Doğrulama Seti 5: Doğruluk = 0.6401273885350318\n",
      "\n",
      "5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk: 0.6372950695168754\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit özellikleri çıkar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "# Özellik seçimi: Pearson korelasyon katsayısı ile en iyi k özelliği seç\n",
    "k_best_features = 20\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "X_selected = feature_selector.fit_transform(X, y)\n",
    "\n",
    "# Eğitim ve test setlerini oluştur\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Veriyi standartlaştır\n",
    "scaler = StandardScaler()\n",
    "X_selected_standardized = scaler.fit_transform(X_selected)\n",
    "\n",
    "# Random Forest modelini tanımla\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(rf_model, X_selected_standardized, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7e568f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çapraz Doğrulama Seti 1: Doğruluk = 0.5659777424483307\n",
      "Çapraz Doğrulama Seti 2: Doğruluk = 0.5691573926868044\n",
      "Çapraz Doğrulama Seti 3: Doğruluk = 0.5691573926868044\n",
      "Çapraz Doğrulama Seti 4: Doğruluk = 0.589171974522293\n",
      "Çapraz Doğrulama Seti 5: Doğruluk = 0.5684713375796179\n",
      "\n",
      "5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk: 0.5723871679847701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit özellikleri çıkar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "\n",
    "# Özellik seçimi: Pearson korelasyon katsayısı ile en iyi k özelliği seç\n",
    "k_best_features = 2\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "X_selected = feature_selector.fit_transform(X, y)\n",
    "\n",
    "# Eğitim ve test setlerini oluştur\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Veriyi standartlaştır\n",
    "scaler = StandardScaler()\n",
    "X_selected_standardized = scaler.fit_transform(X_selected)\n",
    "\n",
    "# SVM modelini tanımla\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(svm_model, X_selected_standardized, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "078e9aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çapraz Doğrulama Seti 1: Doğruluk = 0.6094069529652352\n",
      "Çapraz Doğrulama Seti 2: Doğruluk = 0.6264073694984647\n",
      "Çapraz Doğrulama Seti 3: Doğruluk = 0.593654042988741\n",
      "Çapraz Doğrulama Seti 4: Doğruluk = 0.6131013306038895\n",
      "Çapraz Doğrulama Seti 5: Doğruluk = 0.6069600818833163\n",
      "\n",
      "5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk: 0.6099059555879294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PCA uygula\n",
    "pca = PCA(n_components=5)  # Örneğin, 5 bileşen kullanalım\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# SVM modelini tanımla\n",
    "svm_model = SVC()\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(svm_model, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7d930622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çapraz Doğrulama Seti 1: Doğruluk = 0.6202783300198808\n",
      "Çapraz Doğrulama Seti 2: Doğruluk = 0.6163021868787276\n",
      "Çapraz Doğrulama Seti 3: Doğruluk = 0.5825049701789264\n",
      "Çapraz Doğrulama Seti 4: Doğruluk = 0.5924453280318092\n",
      "Çapraz Doğrulama Seti 5: Doğruluk = 0.6055776892430279\n",
      "\n",
      "5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk: 0.6034217008704743\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PCA uygula\n",
    "pca = PCA(n_components=5)  # Örneğin, 5 bileşen kullanalım\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Neural Networks modelini tanımla\n",
    "nn_model = MLPClassifier(max_iter=1000)  # max_iter parametresi artırılabilir\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(nn_model, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5c481bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çapraz Doğrulama Seti 1: Doğruluk = 0.5838445807770961\n",
      "Çapraz Doğrulama Seti 2: Doğruluk = 0.6069600818833163\n",
      "Çapraz Doğrulama Seti 3: Doğruluk = 0.5762538382804504\n",
      "Çapraz Doğrulama Seti 4: Doğruluk = 0.6049129989764586\n",
      "Çapraz Doğrulama Seti 5: Doğruluk = 0.6100307062436029\n",
      "\n",
      "5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk: 0.5964004412321848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PCA uygula\n",
    "pca = PCA(n_components=5)  # Örneğin, 5 bileşen kullanalım\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Random Forest modelini tanımla\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(rf_model, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ed9b2b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çapraz Doğrulama Seti 1: Doğruluk = 0.4990059642147117\n",
      "Çapraz Doğrulama Seti 2: Doğruluk = 0.5069582504970179\n",
      "Çapraz Doğrulama Seti 3: Doğruluk = 0.4970178926441352\n",
      "Çapraz Doğrulama Seti 4: Doğruluk = 0.510934393638171\n",
      "Çapraz Doğrulama Seti 5: Doğruluk = 0.5059760956175299\n",
      "\n",
      "5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk: 0.5039785193223131\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PCA uygula\n",
    "pca = PCA(n_components=5)  # Örneğin, 5 bileşen kullanalım\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Decision Tree modelini tanımla\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(dt_model, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ba4ec93b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çapraz Doğrulama Seti 1: Doğruluk = 0.5705521472392638\n",
      "Çapraz Doğrulama Seti 2: Doğruluk = 0.5967246673490276\n",
      "Çapraz Doğrulama Seti 3: Doğruluk = 0.5598771750255885\n",
      "Çapraz Doğrulama Seti 4: Doğruluk = 0.5619242579324463\n",
      "Çapraz Doğrulama Seti 5: Doğruluk = 0.586489252814739\n",
      "\n",
      "5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk: 0.5751135000722132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PCA uygula\n",
    "pca = PCA(n_components=5)  # Örneğin, 5 bileşen kullanalım\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# K-Nearest Neighbors modelini tanımla\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(knn_model, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "84ce113d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çapraz Doğrulama Seti 1: Doğruluk = 0.6023856858846919\n",
      "Çapraz Doğrulama Seti 2: Doğruluk = 0.610337972166998\n",
      "Çapraz Doğrulama Seti 3: Doğruluk = 0.5924453280318092\n",
      "Çapraz Doğrulama Seti 4: Doğruluk = 0.6341948310139165\n",
      "Çapraz Doğrulama Seti 5: Doğruluk = 0.6055776892430279\n",
      "\n",
      "5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk: 0.6089883012680887\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit özellikleri çıkar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PCA uygula\n",
    "pca = PCA(n_components=5)  # Örneğin, 5 bileşen kullanalım\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Naive Bayes modelini tanımla\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(nb_model, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "995e6142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elifn\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\elifn\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elifn\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elifn\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elifn\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çapraz Doğrulama Seti 1: Doğruluk = 0.6339468302658486\n",
      "Çapraz Doğrulama Seti 2: Doğruluk = 0.6438075742067554\n",
      "Çapraz Doğrulama Seti 3: Doğruluk = 0.638689866939611\n",
      "Çapraz Doğrulama Seti 4: Doğruluk = 0.638689866939611\n",
      "Çapraz Doğrulama Seti 5: Doğruluk = 0.6345957011258956\n",
      "\n",
      "5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk: 0.6379459678955444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elifn\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "# Daha sonra k-means işlemlerine devam edebilirsiniz\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "y_kmeans = kmeans.fit_predict(X)\n",
    "\n",
    "# Elde edilen kümeleme sonuçlarını yeni bir özellik olarak ekleyin\n",
    "X_with_clusters = pd.concat([pd.DataFrame(X), pd.DataFrame({'Cluster': y_kmeans})], axis=1)\n",
    "\n",
    "# Veriyi eğitim ve test setlerine bölelim\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_with_clusters, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression modelini tanımla\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(logistic_regression, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = cv_scores.mean()\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "248903af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çapraz Doğrulama Seti 1: Doğruluk = 0.5869120654396728\n",
      "Çapraz Doğrulama Seti 2: Doğruluk = 0.5752302968270215\n",
      "Çapraz Doğrulama Seti 3: Doğruluk = 0.5916069600818833\n",
      "Çapraz Doğrulama Seti 4: Doğruluk = 0.5916069600818833\n",
      "Çapraz Doğrulama Seti 5: Doğruluk = 0.5875127942681678\n",
      "\n",
      "5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk: 0.5865738153397257\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Öncelikle veriyi standartlaştırın (PCA için önemlidir)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# PCA ile boyut azaltma\n",
    "pca = PCA(n_components=5)  # Örneğin, 5 bileşen kullanmak istiyoruz\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Linear SVM modelini tanımla\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(svm_classifier, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = cv_scores.mean()\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cbfeb092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çapraz Doğrulama Seti 1: Doğruluk = 0.6124744376278118\n",
      "Çapraz Doğrulama Seti 2: Doğruluk = 0.6059365404298874\n",
      "Çapraz Doğrulama Seti 3: Doğruluk = 0.6038894575230297\n",
      "Çapraz Doğrulama Seti 4: Doğruluk = 0.5987717502558854\n",
      "Çapraz Doğrulama Seti 5: Doğruluk = 0.5916069600818833\n",
      "\n",
      "5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk: 0.6025358291836995\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Öncelikle veriyi standartlaştırın (PCA için önemlidir)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# PCA ile boyut azaltma\n",
    "pca = PCA(n_components=5)  # Örneğin, 5 bileşen kullanmak istiyoruz\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Logistic Regression modelini tanımla\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(logreg, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = cv_scores.mean()\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a3a9a43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Accuracy with RFECV: 0.6489\n",
      "Çapraz Doğrulama Seti 1: Doğruluk = 0.6482617586912065\n",
      "Çapraz Doğrulama Seti 2: Doğruluk = 0.6519959058341863\n",
      "Çapraz Doğrulama Seti 3: Doğruluk = 0.6417604912998977\n",
      "Çapraz Doğrulama Seti 4: Doğruluk = 0.6417604912998977\n",
      "Çapraz Doğrulama Seti 5: Doğruluk = 0.6407369498464688\n",
      "\n",
      "5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk: 0.6449031193943314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression modeli\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# RFECV'yi kullanarak özellik seçimi yapın\n",
    "rfecv = RFECV(estimator=logreg, step=1, cv=5, scoring='accuracy')  # cv=5, 5-fold cross-validation kullanıyoruz\n",
    "X_train_rfecv = rfecv.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eğitin\n",
    "logreg.fit(X_train_rfecv, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "X_test_rfecv = rfecv.transform(X_test)\n",
    "y_pred = logreg.predict(X_test_rfecv)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Model Accuracy with RFECV: {accuracy:.4f}\")\n",
    "\n",
    "# Modelin performansını 5 katlı çapraz doğrulama ile değerlendirin\n",
    "cv_scores = cross_val_score(logreg, X_train_rfecv, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = cv_scores.mean()\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcb434b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Accuracy with RFECV: 0.6489\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression modeli\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# RFECV'yi kullanarak özellik seçimi yapın\n",
    "rfecv = RFECV(estimator=logreg, step=1, cv=5, scoring='accuracy')  # cv=5, 5-fold cross-validation kullanıyoruz\n",
    "X_train_rfecv = rfecv.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eğitin\n",
    "logreg.fit(X_train_rfecv, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "X_test_rfecv = rfecv.transform(X_test)\n",
    "y_pred = logreg.predict(X_test_rfecv)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Model Accuracy with RFECV: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5717a93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Accuracy: 0.6534\n",
      "Çapraz Doğrulama Seti 1: Doğruluk = 0.5864811133200796\n",
      "Çapraz Doğrulama Seti 2: Doğruluk = 0.6063618290258449\n",
      "Çapraz Doğrulama Seti 3: Doğruluk = 0.588469184890656\n",
      "Çapraz Doğrulama Seti 4: Doğruluk = 0.5984095427435387\n",
      "Çapraz Doğrulama Seti 5: Doğruluk = 0.5916334661354582\n",
      "\n",
      "5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk: 0.5942710272231155\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit özellikleri çıkar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression modeli\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# RFE'yi kullanarak özellik seçimi yapın\n",
    "rfe = RFE(logreg, n_features_to_select=5)  # Örneğin, 5 özellik bırakmak istiyoruz\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eğitin\n",
    "logreg.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "y_pred = logreg.predict(X_test_rfe)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Modelin performansını 5 katlı çapraz doğrulama ile değerlendirin\n",
    "cv_scores = cross_val_score(logreg, X_train_rfe, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = cv_scores.mean()\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "13997113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Accuracy: 0.6534\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit özellikleri çıkar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression modeli\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# RFE'yi kullanarak özellik seçimi yapın\n",
    "rfe = RFE(logreg, n_features_to_select=5)  # Örneğin, 5 özellik bırakmak istiyoruz\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eğitin\n",
    "logreg.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "y_pred = logreg.predict(X_test_rfe)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Model Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4ba2f183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.6709\n",
      "Çapraz Doğrulama Seti 1: Doğruluk = 0.6163021868787276\n",
      "Çapraz Doğrulama Seti 2: Doğruluk = 0.6222664015904572\n",
      "Çapraz Doğrulama Seti 3: Doğruluk = 0.5944333996023857\n",
      "Çapraz Doğrulama Seti 4: Doğruluk = 0.6202783300198808\n",
      "Çapraz Doğrulama Seti 5: Doğruluk = 0.6294820717131474\n",
      "\n",
      "5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk: 0.6165524779609197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit özellikleri çıkar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# AdaBoostClassifier modeli\n",
    "ada_clf = AdaBoostClassifier()\n",
    "\n",
    "# SelectFromModel kullanarak özellik seçimi yapın\n",
    "sfm = SelectFromModel(ada_clf, threshold=-np.inf, max_features=5)  # Örneğin, 5 özellik bırakmak istiyoruz\n",
    "X_train_sfm = sfm.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eğitin\n",
    "ada_clf.fit(X_train_sfm, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "X_test_sfm = sfm.transform(X_test)\n",
    "y_pred = ada_clf.predict(X_test_sfm)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Modelin performansını 5 katlı çapraz doğrulama ile değerlendirin\n",
    "cv_scores = cross_val_score(ada_clf, X_train_sfm, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = cv_scores.mean()\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b3f5d796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.6709\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit özellikleri çıkar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# AdaBoostClassifier modeli\n",
    "ada_clf = AdaBoostClassifier()\n",
    "\n",
    "# SelectFromModel kullanarak özellik seçimi yapın\n",
    "sfm = SelectFromModel(ada_clf, threshold=-np.inf, max_features=5)  # Örneğin, 5 özellik bırakmak istiyoruz\n",
    "X_train_sfm = sfm.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eğitin\n",
    "ada_clf.fit(X_train_sfm, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "X_test_sfm = sfm.transform(X_test)\n",
    "y_pred = ada_clf.predict(X_test_sfm)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7d897be4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.6884\n",
      "Çapraz Doğrulama Seti 1: Doğruluk = 0.6202783300198808\n",
      "Çapraz Doğrulama Seti 2: Doğruluk = 0.6381709741550696\n",
      "Çapraz Doğrulama Seti 3: Doğruluk = 0.6023856858846919\n",
      "Çapraz Doğrulama Seti 4: Doğruluk = 0.6023856858846919\n",
      "Çapraz Doğrulama Seti 5: Doğruluk = 0.6553784860557769\n",
      "\n",
      "5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk: 0.6237198324000222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örneğin, new_X ve new_y'yi kullanalım\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit özellikleri çıkar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Gradient Boosting modeli\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "# RFE'yi kullanarak özellik seçimi yapın\n",
    "rfe = RFE(clf, n_features_to_select=5)  # Örneğin, 5 özellik bırakmak istiyoruz\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eğitin\n",
    "clf.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "y_pred = clf.predict(X_test_rfe)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Modelin performansını 5 katlı çapraz doğrulama ile değerlendirin\n",
    "cv_scores = cross_val_score(clf, X_train_rfe, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "879c8fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.model_selection import cross_val_score, StratifiedKFold\\nfrom sklearn.metrics import make_scorer, accuracy_score\\nfrom sklearn.svm import SVC\\nfrom sklearn.feature_selection import SelectKBest, f_classif\\nimport numpy as np\\nfrom itertools import combinations\\n\\ndef kendall_tau(y_true, y_pred):\\n    concordant_pairs = 0\\n    discordant_pairs = 0\\n\\n    n = len(y_true)\\n\\n    for i, j in combinations(range(n), 2):\\n        # İki çiftin sıralama durumunu kontrol et\\n        pred_order_diff = np.sign(y_pred[i] - y_pred[j])\\n        true_order_diff = np.sign(y_true[i] - y_true[j])\\n\\n        # Concordant veya discordant durumu kontrol et\\n        if pred_order_diff == true_order_diff:\\n            concordant_pairs += 1\\n        else:\\n            discordant_pairs += 1\\n\\n    # Paydan sıfır ise nan döndür\\n    if (concordant_pairs + discordant_pairs) == 0:\\n        return np.nan\\n\\n    # Kendall Tau Korelasyonu hesapla\\n    tau = (concordant_pairs - discordant_pairs) / np.sqrt((concordant_pairs + discordant_pairs) * n * (n - 1) / 2)\\n\\n    return tau\\n\\n\\n\\n# Önceden belirlenmiş X ve y\\'yi kullanalım\\n# X: Özellik matrisi, y: Hedef değişken\\nX = imputed_df.drop(\\'Q16\\', axis=1)\\ny = imputed_df[\\'Q16\\']\\n\\n# StratifiedKFold ile 5-fold cross-validation\\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\\n\\n# Rank-SVM modelini tanımla\\nrank_svm_model = SVC(kernel=\\'linear\\')\\n\\n# Feature selection için SelectKBest ve f_classif kullan\\nk_best_features = 5\\nfeature_selector = SelectKBest(score_func=f_classif, k=k_best_features)\\n\\n# 5-fold cross-validation ile modelin performansını değerlendir\\ncv_kendall_tau_scores = cross_val_score(rank_svm_model, X, y, cv=cv, scoring=make_scorer(kendall_tau, greater_is_better=True))\\ncv_accuracy_scores = cross_val_score(rank_svm_model, X, y, cv=cv, scoring=\\'accuracy\\')\\n\\n# Her bir çapraz doğrulama seti için skorları yazdır\\nfor i, (kendall_tau, accuracy) in enumerate(zip(cv_kendall_tau_scores, cv_accuracy_scores), start=1):\\n    print(f\"Çapraz Doğrulama Seti {i}: Kendall Tau Korelasyonu = {kendall_tau:.4f}, Accuracy = {accuracy:.4f}\")\\n\\n# Ortalama skorları hesapla\\nmean_kendall_tau = np.mean(cv_kendall_tau_scores)\\nmean_accuracy = np.mean(cv_accuracy_scores)\\n\\nprint(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Kendall Tau Korelasyonu:\", mean_kendall_tau)\\nprint(\"5 Katlı Çapraz Doğrulama İle Ortalama Accuracy:\", mean_accuracy)'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "def kendall_tau(y_true, y_pred):\n",
    "    concordant_pairs = 0\n",
    "    discordant_pairs = 0\n",
    "\n",
    "    n = len(y_true)\n",
    "\n",
    "    for i, j in combinations(range(n), 2):\n",
    "        # İki çiftin sıralama durumunu kontrol et\n",
    "        pred_order_diff = np.sign(y_pred[i] - y_pred[j])\n",
    "        true_order_diff = np.sign(y_true[i] - y_true[j])\n",
    "\n",
    "        # Concordant veya discordant durumu kontrol et\n",
    "        if pred_order_diff == true_order_diff:\n",
    "            concordant_pairs += 1\n",
    "        else:\n",
    "            discordant_pairs += 1\n",
    "\n",
    "    # Paydan sıfır ise nan döndür\n",
    "    if (concordant_pairs + discordant_pairs) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    # Kendall Tau Korelasyonu hesapla\n",
    "    tau = (concordant_pairs - discordant_pairs) / np.sqrt((concordant_pairs + discordant_pairs) * n * (n - 1) / 2)\n",
    "\n",
    "    return tau\n",
    "\n",
    "\n",
    "\n",
    "# Önceden belirlenmiş X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "# StratifiedKFold ile 5-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Rank-SVM modelini tanımla\n",
    "rank_svm_model = SVC(kernel='linear')\n",
    "\n",
    "# Feature selection için SelectKBest ve f_classif kullan\n",
    "k_best_features = 5\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "\n",
    "# 5-fold cross-validation ile modelin performansını değerlendir\n",
    "cv_kendall_tau_scores = cross_val_score(rank_svm_model, X, y, cv=cv, scoring=make_scorer(kendall_tau, greater_is_better=True))\n",
    "cv_accuracy_scores = cross_val_score(rank_svm_model, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için skorları yazdır\n",
    "for i, (kendall_tau, accuracy) in enumerate(zip(cv_kendall_tau_scores, cv_accuracy_scores), start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Kendall Tau Korelasyonu = {kendall_tau:.4f}, Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "# Ortalama skorları hesapla\n",
    "mean_kendall_tau = np.mean(cv_kendall_tau_scores)\n",
    "mean_accuracy = np.mean(cv_accuracy_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Kendall Tau Korelasyonu:\", mean_kendall_tau)\n",
    "print(\"5 Katlı Çapraz Doğrulama İle Ortalama Accuracy:\", mean_accuracy)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "327fc506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.6836\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Yeni_X ve yeni_y verilerini eğitim ve test setlerine bölelim\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X, new_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# RandomForestClassifier'ı sınıf ağırlıklarıyla oluşturun\n",
    "rf_classifier = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Modeli eğitin\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e1dfee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from imblearn.over_sampling import SMOTE\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.metrics import accuracy_score\\n\\n# Önceden belirlenmiş olan X ve y\\'yi kullanalım\\n# X: Özellik matrisi, y: Hedef değişken\\n# Örnek olarak, new_X ve new_y\\'yi kullanalım\\nX_train, X_test, y_train, y_test = train_test_split(new_X, new_y, test_size=0.2, random_state=42)\\n\\n# SMOTE\\'u kullanarak oversampling\\nsmote = SMOTE(random_state=42)\\nX_resampled, y_resampled = smote.fit_resample(X_train, y_train)\\n\\n# RandomForestClassifier\\'ı sınıf ağırlıklarıyla oluşturun\\nrf_classifier = RandomForestClassifier(random_state=42)\\n\\n# Modeli eğitin\\nrf_classifier.fit(X_resampled, y_resampled)\\n\\n# Test seti üzerinde tahminler yapın\\ny_pred = rf_classifier.predict(X_test)\\n\\n# Doğruluk skorunu değerlendirin\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(f\"Model Accuracy: {accuracy:.4f}\")'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Önceden belirlenmiş olan X ve y'yi kullanalım\n",
    "# X: Özellik matrisi, y: Hedef değişken\n",
    "# Örnek olarak, new_X ve new_y'yi kullanalım\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X, new_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# SMOTE'u kullanarak oversampling\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# RandomForestClassifier'ı sınıf ağırlıklarıyla oluşturun\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Modeli eğitin\n",
    "rf_classifier.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "66cc5ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çapraz Doğrulama Seti 1: Doğruluk = 0.6406995230524642\n",
      "Çapraz Doğrulama Seti 2: Doğruluk = 0.6454689984101749\n",
      "Çapraz Doğrulama Seti 3: Doğruluk = 0.6677265500794912\n",
      "Çapraz Doğrulama Seti 4: Doğruluk = 0.64171974522293\n",
      "Çapraz Doğrulama Seti 5: Doğruluk = 0.6257961783439491\n",
      "\n",
      "5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk: 0.644282199021802\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "# Z puanlarına dayalı olarak aykırı değerleri ele\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "\n",
    "# Sabit özellikleri çıkar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "\n",
    "# Genişletilmiş özellik setini oluştur\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Random Forest sınıflandırıcı oluşturun\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# 5-fold çapraz doğrulama için StratifiedKFold kullanın\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Genişletilmiş özellik seti ve hedef değişkeni ile bir pipeline oluşturun\n",
    "model = make_pipeline(PolynomialFeatures(degree=2), RandomForestClassifier())\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5156c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "# Aykırı değerleri ele\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "\n",
    "# Sabit özellikleri çıkar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "\n",
    "# Genişletilmiş özellik setini oluştur\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Random Forest sınıflandırıcı oluşturun\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Parametre aralığını belirle\n",
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [50, 100, 200],\n",
    "    'randomforestclassifier__max_depth': [None, 10, 20],\n",
    "    'randomforestclassifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Pipeline ve GridSearchCV kullanarak en iyi parametreleri bulun\n",
    "model = make_pipeline(PolynomialFeatures(degree=2), RandomForestClassifier())\n",
    "grid_search = GridSearchCV(model, param_grid, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring='accuracy')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# En iyi parametreleri görüntüleme\n",
    "print(\"En iyi parametreler:\", grid_search.best_params_)\n",
    "\n",
    "# En iyi modeli kullanma\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 5 katlı çapraz doğrulama ile doğruluk skorlarını al\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring='accuracy')\n",
    "\n",
    "# Her bir çapraz doğrulama seti için doğruluk skorlarını yazdır\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Çapraz Doğrulama Seti {i}: Doğruluk = {score}\")\n",
    "\n",
    "# Ortalama doğruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 Katlı Çapraz Doğrulama İle Ortalama Doğruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "95ed71c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.6963\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from scipy import stats\n",
    "# Özellik ve hedef değişkeni seç\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit özellikleri çıkar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "# Önceden oluşturulmuş genişletilmiş özellik setini ve hedef değişkeni kullanarak veri setini oluşturun\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest sınıflandırıcı oluşturun\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Modeli eğitin\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Doğruluk skorunu değerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d027631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import pandas as pd\\nfrom sklearn.preprocessing import MinMaxScaler\\n\\n\\nX = imputed_df.drop(target_column, axis=1)\\n\\n# Min-Max normalizasyonu uygulayın\\nscaler = MinMaxScaler()\\nX_normalized = scaler.fit_transform(X)\\n\\n# Normalizasyon sonrası veriyi yeni bir veri çerçevesine ekleyin (isteğe bağlı)\\nnormalized_df = pd.DataFrame(X_normalized, columns=X.columns)\\n\\n# Normalizasyon sonrası veriyi yazdırın (isteğe bağlı)\\nprint(normalized_df)'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "X = imputed_df.drop(target_column, axis=1)\n",
    "\n",
    "# Min-Max normalizasyonu uygulayın\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Normalizasyon sonrası veriyi yeni bir veri çerçevesine ekleyin (isteğe bağlı)\n",
    "normalized_df = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "\n",
    "# Normalizasyon sonrası veriyi yazdırın (isteğe bağlı)\n",
    "print(normalized_df)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5bcd8792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import pandas as pd\\nfrom sklearn.preprocessing import RobustScaler\\n\\n# Veriyi yükleyin veya oluşturun\\n# Örneğin, imputed_df adlı bir veri çerçevesiniz olduğunu varsayalım\\n\\n# Hedef değişkeni (target attribute) ve özellikleri ayırın\\ntarget_column = 'Q16'\\ny = imputed_df[target_column]\\nX = imputed_df.drop(target_column, axis=1)\\n\\n# Robust Scaler normalizasyonu uygulayın\\nscaler = RobustScaler()\\nX_normalized = scaler.fit_transform(X)\\n\\n# Normalizasyon sonrası veriyi yeni bir veri çerçevesine ekleyin (isteğe bağlı)\\nnormalized_df = pd.DataFrame(X_normalized, columns=X.columns)\\n\\n# Normalizasyon sonrası veriyi yazdırın (isteğe bağlı)\\nprint(normalized_df)\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Veriyi yükleyin veya oluşturun\n",
    "# Örneğin, imputed_df adlı bir veri çerçevesiniz olduğunu varsayalım\n",
    "\n",
    "# Hedef değişkeni (target attribute) ve özellikleri ayırın\n",
    "target_column = 'Q16'\n",
    "y = imputed_df[target_column]\n",
    "X = imputed_df.drop(target_column, axis=1)\n",
    "\n",
    "# Robust Scaler normalizasyonu uygulayın\n",
    "scaler = RobustScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Normalizasyon sonrası veriyi yeni bir veri çerçevesine ekleyin (isteğe bağlı)\n",
    "normalized_df = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "\n",
    "# Normalizasyon sonrası veriyi yazdırın (isteğe bağlı)\n",
    "print(normalized_df)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9f73e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.feature_selection import f_classif, SelectKBest\\n\\n\\n\\n# F-Score ile en iyi özellikleri seçme\\nf_score_selector = SelectKBest(f_classif, k=\\'all\\')\\nX_f_score = f_score_selector.fit_transform(X, y)\\n\\n# F-Score değerleri\\nf_scores = f_score_selector.scores_\\n\\n# Her bir sütun için F-Score değerlerini yazdırma\\nfor feature, score in zip(X.columns, f_scores):\\n    print(f\"Sütun: {feature}, F-Score: {score}\")'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from sklearn.feature_selection import f_classif, SelectKBest\n",
    "\n",
    "\n",
    "\n",
    "# F-Score ile en iyi özellikleri seçme\n",
    "f_score_selector = SelectKBest(f_classif, k='all')\n",
    "X_f_score = f_score_selector.fit_transform(X, y)\n",
    "\n",
    "# F-Score değerleri\n",
    "f_scores = f_score_selector.scores_\n",
    "\n",
    "# Her bir sütun için F-Score değerlerini yazdırma\n",
    "for feature, score in zip(X.columns, f_scores):\n",
    "    print(f\"Sütun: {feature}, F-Score: {score}\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d8d8649",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.model_selection import cross_validate\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.svm import SVC\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\\nfrom sklearn.ensemble import AdaBoostClassifier\\nfrom sklearn.model_selection import StratifiedKFold\\nfrom sklearn.feature_selection import f_classif, SelectKBest\\n\\n# Assuming df is your DataFrame\\ntarget_column = \\'Q16\\'\\n\\n# Assuming \\'X\\' is your feature matrix and \\'y\\' is your target variable\\nX = imputed_df.drop(target_column, axis=1)  # Feature matrix\\ny = imputed_df[target_column]  # Target variable\\n\\n# F-Score ile en iyi özellikleri seçme\\nf_score_selector = SelectKBest(f_classif, k=\\'all\\')\\nX_f_score = f_score_selector.fit_transform(X, y)\\n\\n# F-Score değerleri\\nf_scores = f_score_selector.scores_\\n\\n# Sütunları F-Score değerlerine göre sırala\\nsorted_features = [feature for _, feature in sorted(zip(f_scores, X.columns), reverse=True)]\\n\\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # Define your cross-validation strategy\\n\\nclassifiers = {\\n    \\'Random Forest\\': RandomForestClassifier(),\\n    \\'Gradient Boosting\\': GradientBoostingClassifier(),\\n    \\'Logistic Regression\\': LogisticRegression(max_iter=1000),  # Increase max_iter to 1000 or more\\n    \\'SVM\\': SVC(),\\n    \\'K-Nearest Neighbors\\': KNeighborsClassifier(),\\n    \\'Decision Tree\\': DecisionTreeClassifier(),\\n    \\'Gaussian Naive Bayes\\': GaussianNB(),\\n    \\'Neural Network\\': MLPClassifier(max_iter=1000), \\n    \\'QDA\\': QuadraticDiscriminantAnalysis(),\\n    \\'AdaBoost\\': AdaBoostClassifier()\\n    # Add more classifiers here\\n}\\n\\n# Define the metric to be evaluated\\nscoring = {\\n    \\'Accuracy\\': \\'accuracy\\',\\n}\\n\\n# Perform 5-fold cross-validation with each classifier using selected features\\nfor clf_name, clf in classifiers.items():\\n    print(f\"Evaluating {clf_name} with F-Score Selected Features:\")\\n    scores = cross_validate(clf, X[sorted_features], y, cv=skf, scoring=scoring)\\n    \\n    acc_mean = scores[\\'test_Accuracy\\'].mean()\\n    \\n    print(f\"Accuracy: {acc_mean:.4f}\")\\n    print(\"-------------------------------------------\")'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "target_column = 'Q16'\n",
    "\n",
    "# Assuming 'X' is your feature matrix and 'y' is your target variable\n",
    "X = imputed_df.drop(target_column, axis=1)  # Feature matrix\n",
    "y = imputed_df[target_column]  # Target variable\n",
    "\n",
    "# F-Score ile en iyi özellikleri seçme\n",
    "f_score_selector = SelectKBest(f_classif, k='all')\n",
    "X_f_score = f_score_selector.fit_transform(X, y)\n",
    "\n",
    "# F-Score değerleri\n",
    "f_scores = f_score_selector.scores_\n",
    "\n",
    "# Sütunları F-Score değerlerine göre sırala\n",
    "sorted_features = [feature for _, feature in sorted(zip(f_scores, X.columns), reverse=True)]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # Define your cross-validation strategy\n",
    "\n",
    "classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),  # Increase max_iter to 1000 or more\n",
    "    'SVM': SVC(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'Neural Network': MLPClassifier(max_iter=1000), \n",
    "    'QDA': QuadraticDiscriminantAnalysis(),\n",
    "    'AdaBoost': AdaBoostClassifier()\n",
    "    # Add more classifiers here\n",
    "}\n",
    "\n",
    "# Define the metric to be evaluated\n",
    "scoring = {\n",
    "    'Accuracy': 'accuracy',\n",
    "}\n",
    "\n",
    "# Perform 5-fold cross-validation with each classifier using selected features\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"Evaluating {clf_name} with F-Score Selected Features:\")\n",
    "    scores = cross_validate(clf, X[sorted_features], y, cv=skf, scoring=scoring)\n",
    "    \n",
    "    acc_mean = scores['test_Accuracy'].mean()\n",
    "    \n",
    "    print(f\"Accuracy: {acc_mean:.4f}\")\n",
    "    print(\"-------------------------------------------\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091fead4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5554f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\n\\n# Her bir özelliği ve onun F-Score değerini içeren bir tuple listesi\\nfeature_score_pairs = list(zip(X.columns, f_scores))\\n\\n# F-Score değerlerine göre sıralama\\nfeature_score_pairs.sort(key=lambda x: x[1], reverse=True)\\n\\n# En fazla k özelliği seçme (k'i istediğiniz sayıya ayarlayabilirsiniz)\\nmax_k = 10\\nfor k in range(1, max_k + 1):\\n    # En güçlü k özellikleri seçme\\n    top_k_features = [feature for feature, _ in feature_score_pairs[:k]]\\n    \\n    # Seçilen en güçlü özelliklere sahip veri çerçevesini oluşturma\\n    selected_df = imputed_df[top_k_features + ['Q16']]\\n    \\n    # Hedef değişkeni ve özellikleri ayırma\\n    X_selected = selected_df.drop('Q16', axis=1)\\n    y_selected = selected_df['Q16']\\n    \\n    # Veriyi eğitim ve test setlerine ayırma\\n    X_train, X_test, y_train, y_test = train_test_split(X_selected, y_selected, test_size=0.2, random_state=42)\\n    \\n    # Sınıflandırıcı modelini oluşturma (Random Forest kullanıldı)\\n    classifier = RandomForestClassifier(random_state=42)\\n    classifier.fit(X_train, y_train)\\n    \\n    # Test seti üzerinde tahmin yapma\\n    y_pred = classifier.predict(X_test)\\n    \\n    # Doğruluk hesapla\\n    accuracy = accuracy_score(y_test, y_pred)\\n    print(f'k={k}, Doğruluk: {accuracy}')\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Her bir özelliği ve onun F-Score değerini içeren bir tuple listesi\n",
    "feature_score_pairs = list(zip(X.columns, f_scores))\n",
    "\n",
    "# F-Score değerlerine göre sıralama\n",
    "feature_score_pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# En fazla k özelliği seçme (k'i istediğiniz sayıya ayarlayabilirsiniz)\n",
    "max_k = 10\n",
    "for k in range(1, max_k + 1):\n",
    "    # En güçlü k özellikleri seçme\n",
    "    top_k_features = [feature for feature, _ in feature_score_pairs[:k]]\n",
    "    \n",
    "    # Seçilen en güçlü özelliklere sahip veri çerçevesini oluşturma\n",
    "    selected_df = imputed_df[top_k_features + ['Q16']]\n",
    "    \n",
    "    # Hedef değişkeni ve özellikleri ayırma\n",
    "    X_selected = selected_df.drop('Q16', axis=1)\n",
    "    y_selected = selected_df['Q16']\n",
    "    \n",
    "    # Veriyi eğitim ve test setlerine ayırma\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y_selected, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Sınıflandırıcı modelini oluşturma (Random Forest kullanıldı)\n",
    "    classifier = RandomForestClassifier(random_state=42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Test seti üzerinde tahmin yapma\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Doğruluk hesapla\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'k={k}, Doğruluk: {accuracy}')\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "617eb0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"numeric_columns = imputed_df.select_dtypes(include=np.number).columns\\ndf_numeric = imputed_df[numeric_columns].apply(pd.to_numeric)\\n# Veriyi standartlaştırın (PCA, verinin standartlaştırılmış olmasını ister)\\nscaler = StandardScaler()\\ndf_scaled = scaler.fit_transform(df_numeric)\\n\\n# PCA modelini oluşturun ve uygulayın\\npca = PCA()\\npca_result = pca.fit_transform(df_scaled)\\n\\n# Elde edilen bileşenlerin varyans oranlarını ve kümülatif varyans oranlarını çizin\\nexplained_variance_ratio = pca.explained_variance_ratio_\\ncumulative_explained_variance = np.cumsum(explained_variance_ratio)\\n\\nplt.figure(figsize=(12, 6))\\nplt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, label='Explained Variance Ratio')\\nplt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o', linestyle='--', color='orange', label='Cumulative Explained Variance')\\nplt.title('PCA - Explained Variance')\\nplt.xlabel('Principal Components')\\nplt.ylabel('Variance Ratio')\\nplt.legend()\\nplt.show()\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"numeric_columns = imputed_df.select_dtypes(include=np.number).columns\n",
    "df_numeric = imputed_df[numeric_columns].apply(pd.to_numeric)\n",
    "# Veriyi standartlaştırın (PCA, verinin standartlaştırılmış olmasını ister)\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_numeric)\n",
    "\n",
    "# PCA modelini oluşturun ve uygulayın\n",
    "pca = PCA()\n",
    "pca_result = pca.fit_transform(df_scaled)\n",
    "\n",
    "# Elde edilen bileşenlerin varyans oranlarını ve kümülatif varyans oranlarını çizin\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, label='Explained Variance Ratio')\n",
    "plt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o', linestyle='--', color='orange', label='Cumulative Explained Variance')\n",
    "plt.title('PCA - Explained Variance')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Variance Ratio')\n",
    "plt.legend()\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac5988f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"plt.figure(figsize=(16, 8))\\nsns.boxplot(data=imputed_df, orient='h', palette='Set2')\\nplt.title('Tüm Sayısal Değişkenlerin Box Plot'u')\\nplt.show()\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"plt.figure(figsize=(16, 8))\n",
    "sns.boxplot(data=imputed_df, orient='h', palette='Set2')\n",
    "plt.title('Tüm Sayısal Değişkenlerin Box Plot\\'u')\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b738f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# IQR tabanlı aykırı değer tespiti\\nQ1 = df_numeric.quantile(0.25)\\nQ3 = df_numeric.quantile(0.75)\\nIQR = Q3 - Q1\\n\\n# Aykırı değerleri içeren bir maske oluşturun\\noutlier_mask_iqr = ((df_numeric < (Q1 - 1.5 * IQR)) | (df_numeric > (Q3 + 1.5 * IQR))).any(axis=1)\\n\\n# Aykırı değerlere sahip olan satırları göster\\noutliers_iqr = df_best_imputed[outlier_mask_iqr]\\nprint(outliers_iqr)\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# IQR tabanlı aykırı değer tespiti\n",
    "Q1 = df_numeric.quantile(0.25)\n",
    "Q3 = df_numeric.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Aykırı değerleri içeren bir maske oluşturun\n",
    "outlier_mask_iqr = ((df_numeric < (Q1 - 1.5 * IQR)) | (df_numeric > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "# Aykırı değerlere sahip olan satırları göster\n",
    "outliers_iqr = df_best_imputed[outlier_mask_iqr]\n",
    "print(outliers_iqr)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a62fe53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# IQR tabanlı outlier'ları tespit etme\\nQ1 = df_numeric.quantile(0.25)\\nQ3 = df_numeric.quantile(0.75)\\nIQR = Q3 - Q1\\n\\n# Aykırı değerlere sahip olmayan satırları seçme\\ndf_no_outliers_iqr = df_numeric[~((df_numeric < (Q1 - 1.5 * IQR)) | (df_numeric > (Q3 + 1.5 * IQR))).any(axis=1)]\\n\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# IQR tabanlı outlier'ları tespit etme\n",
    "Q1 = df_numeric.quantile(0.25)\n",
    "Q3 = df_numeric.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Aykırı değerlere sahip olmayan satırları seçme\n",
    "df_no_outliers_iqr = df_numeric[~((df_numeric < (Q1 - 1.5 * IQR)) | (df_numeric > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a71702b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#outlier çıkardıkran sonra PCA \\nnumeric_columns = df_no_outliers_iqr.select_dtypes(include=np.number).columns\\ndf_numeric = df_no_outliers_iqr[numeric_columns].apply(pd.to_numeric)\\n# Veriyi standartlaştırın (PCA, verinin standartlaştırılmış olmasını ister)\\nscaler = StandardScaler()\\ndf_scaled = scaler.fit_transform(df_numeric)\\n\\n# PCA modelini oluşturun ve uygulayın\\npca = PCA()\\npca_result = pca.fit_transform(df_scaled)\\n\\n# Elde edilen bileşenlerin varyans oranlarını ve kümülatif varyans oranlarını çizin\\nexplained_variance_ratio = pca.explained_variance_ratio_\\ncumulative_explained_variance = np.cumsum(explained_variance_ratio)\\n\\nplt.figure(figsize=(12, 6))\\nplt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, label='Explained Variance Ratio')\\nplt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o', linestyle='--', color='orange', label='Cumulative Explained Variance')\\nplt.title('PCA - Explained Variance')\\nplt.xlabel('Principal Components')\\nplt.ylabel('Variance Ratio')\\nplt.legend()\\nplt.show()\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#outlier çıkardıkran sonra PCA \n",
    "numeric_columns = df_no_outliers_iqr.select_dtypes(include=np.number).columns\n",
    "df_numeric = df_no_outliers_iqr[numeric_columns].apply(pd.to_numeric)\n",
    "# Veriyi standartlaştırın (PCA, verinin standartlaştırılmış olmasını ister)\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_numeric)\n",
    "\n",
    "# PCA modelini oluşturun ve uygulayın\n",
    "pca = PCA()\n",
    "pca_result = pca.fit_transform(df_scaled)\n",
    "\n",
    "# Elde edilen bileşenlerin varyans oranlarını ve kümülatif varyans oranlarını çizin\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, label='Explained Variance Ratio')\n",
    "plt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o', linestyle='--', color='orange', label='Cumulative Explained Variance')\n",
    "plt.title('PCA - Explained Variance')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Variance Ratio')\n",
    "plt.legend()\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8a68d756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#Outlier çıkardıkran sonra box plot\\nplt.figure(figsize=(16, 8))\\nsns.boxplot(data=df_no_outliers_iqr, orient='h', palette='Set2')\\nplt.title('Tüm Sayısal Değişkenlerin Box Plot'u')\\nplt.show()\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Outlier çıkardıkran sonra box plot\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.boxplot(data=df_no_outliers_iqr, orient='h', palette='Set2')\n",
    "plt.title('Tüm Sayısal Değişkenlerin Box Plot\\'u')\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8ce7726f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Normalizasyon\\n# Min-Max normalizasyonu için ölçekleyiciyi oluşturun\\nscaler = MinMaxScaler()\\n\\n# Normalizasyon işlemini uygulayın ve NumPy dizisini DataFrame\\'e dönüştürün\\ndf_normalized = pd.DataFrame(scaler.fit_transform(df_no_outliers_iqr), columns=df_no_outliers_iqr.columns)\\n\\n# Veri seti özet istatistikleri\\nprint(df_normalized.describe())\\n\\n# Histogramlar\\ndf_normalized.hist(figsize=(10, 8), bins=20)\\nplt.show()\\n\\n# Kutu Grafikleri\\nplt.figure(figsize=(12, 8))\\nsns.boxplot(data=df_normalized)\\nplt.show()\\n\\n# Korelasyon Matrisi\\ncorrelation_matrix = df_normalized.corr()\\nsns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\")\\nplt.show()'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Normalizasyon\n",
    "# Min-Max normalizasyonu için ölçekleyiciyi oluşturun\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizasyon işlemini uygulayın ve NumPy dizisini DataFrame'e dönüştürün\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df_no_outliers_iqr), columns=df_no_outliers_iqr.columns)\n",
    "\n",
    "# Veri seti özet istatistikleri\n",
    "print(df_normalized.describe())\n",
    "\n",
    "# Histogramlar\n",
    "df_normalized.hist(figsize=(10, 8), bins=20)\n",
    "plt.show()\n",
    "\n",
    "# Kutu Grafikleri\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(data=df_normalized)\n",
    "plt.show()\n",
    "\n",
    "# Korelasyon Matrisi\n",
    "correlation_matrix = df_normalized.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\")\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440d2bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
