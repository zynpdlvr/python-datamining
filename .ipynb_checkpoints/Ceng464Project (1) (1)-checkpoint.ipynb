{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7db9985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2675bd3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q11_1</th>\n",
       "      <th>Q11_2</th>\n",
       "      <th>Q11_3</th>\n",
       "      <th>Q11_4</th>\n",
       "      <th>Q11_5</th>\n",
       "      <th>Q11_6</th>\n",
       "      <th>Q11_7</th>\n",
       "      <th>Q11_8</th>\n",
       "      <th>Q11_9</th>\n",
       "      <th>Q11_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q18_17</th>\n",
       "      <th>Q18_18</th>\n",
       "      <th>Q18_19</th>\n",
       "      <th>Q18_20</th>\n",
       "      <th>Q18_21</th>\n",
       "      <th>Q18_22</th>\n",
       "      <th>Q18_23</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q11_1  Q11_2  Q11_3  Q11_4  Q11_5  Q11_6  Q11_7  Q11_8  Q11_9  Q11_10  ...  \\\n",
       "0      0      0      0      1      1      0      0      1      0       0  ...   \n",
       "1      1      0      0      1      0      0      1      0      0       1  ...   \n",
       "2      1      1      0      1      0      0      1      1      0       1  ...   \n",
       "3      0      0      0      0      0      0      0      0      0       0  ...   \n",
       "4      1      1      0      1      0      0      1      1      0       1  ...   \n",
       "\n",
       "   Q18_17  Q18_18  Q18_19  Q18_20  Q18_21  Q18_22  Q18_23  Q20  Q21  Q16  \n",
       "0       5       5       5       5       5       5       5    3    3    A  \n",
       "1       4       2       4       2       2       2       2    3    3    D  \n",
       "2       4       4       ?       ?       4       2       4    4    1    A  \n",
       "3       ?       ?       ?       ?       ?       ?       ?    3    3    C  \n",
       "4       ?       ?       1       1       ?       ?       ?    3    3    D  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel('Course Project - Data for Classification - Electric Vehicles.xls')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7593525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q11_1      int64\n",
      "Q11_2      int64\n",
      "Q11_3      int64\n",
      "Q11_4      int64\n",
      "Q11_5      int64\n",
      "           ...  \n",
      "Q18_22    object\n",
      "Q18_23    object\n",
      "Q20        int64\n",
      "Q21        int64\n",
      "Q16       object\n",
      "Length: 75, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23070e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A' 'D' 'C' 'B']\n"
     ]
    }
   ],
   "source": [
    "print(df['Q16'].unique()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f0af2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    2883\n",
       "B    1526\n",
       "C     892\n",
       "D     807\n",
       "Name: Q16, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Q16'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5a39c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q11_1</th>\n",
       "      <th>Q11_2</th>\n",
       "      <th>Q11_3</th>\n",
       "      <th>Q11_4</th>\n",
       "      <th>Q11_5</th>\n",
       "      <th>Q11_6</th>\n",
       "      <th>Q11_7</th>\n",
       "      <th>Q11_8</th>\n",
       "      <th>Q11_9</th>\n",
       "      <th>Q11_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q18_17</th>\n",
       "      <th>Q18_18</th>\n",
       "      <th>Q18_19</th>\n",
       "      <th>Q18_20</th>\n",
       "      <th>Q18_21</th>\n",
       "      <th>Q18_22</th>\n",
       "      <th>Q18_23</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q11_1  Q11_2  Q11_3  Q11_4  Q11_5  Q11_6  Q11_7  Q11_8  Q11_9  Q11_10  ...  \\\n",
       "0      0      0      0      1      1      0      0      1      0       0  ...   \n",
       "1      1      0      0      1      0      0      1      0      0       1  ...   \n",
       "2      1      1      0      1      0      0      1      1      0       1  ...   \n",
       "3      0      0      0      0      0      0      0      0      0       0  ...   \n",
       "4      1      1      0      1      0      0      1      1      0       1  ...   \n",
       "\n",
       "   Q18_17  Q18_18  Q18_19  Q18_20  Q18_21  Q18_22  Q18_23  Q20  Q21  Q16  \n",
       "0       5       5       5       5       5       5       5    3    3    A  \n",
       "1       4       2       4       2       2       2       2    3    3    D  \n",
       "2       4       4       ?       ?       4       2       4    4    1    A  \n",
       "3       ?       ?       ?       ?       ?       ?       ?    3    3    C  \n",
       "4       ?       ?       1       1       ?       ?       ?    3    3    D  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd25157f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q11_1</th>\n",
       "      <th>Q11_2</th>\n",
       "      <th>Q11_3</th>\n",
       "      <th>Q11_4</th>\n",
       "      <th>Q11_5</th>\n",
       "      <th>Q11_6</th>\n",
       "      <th>Q11_7</th>\n",
       "      <th>Q11_8</th>\n",
       "      <th>Q11_9</th>\n",
       "      <th>Q11_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q18_17</th>\n",
       "      <th>Q18_18</th>\n",
       "      <th>Q18_19</th>\n",
       "      <th>Q18_20</th>\n",
       "      <th>Q18_21</th>\n",
       "      <th>Q18_22</th>\n",
       "      <th>Q18_23</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q11_1  Q11_2  Q11_3  Q11_4  Q11_5  Q11_6  Q11_7  Q11_8  Q11_9  Q11_10  ...  \\\n",
       "0      0      0      0      1      1      0      0      1      0       0  ...   \n",
       "1      1      0      0      1      0      0      1      0      0       1  ...   \n",
       "2      1      1      0      1      0      0      1      1      0       1  ...   \n",
       "3      0      0      0      0      0      0      0      0      0       0  ...   \n",
       "4      1      1      0      1      0      0      1      1      0       1  ...   \n",
       "\n",
       "   Q18_17  Q18_18  Q18_19  Q18_20  Q18_21  Q18_22  Q18_23  Q20  Q21  Q16  \n",
       "0     5.0     5.0     5.0     5.0     5.0     5.0     5.0    3    3    A  \n",
       "1     4.0     2.0     4.0     2.0     2.0     2.0     2.0    3    3    D  \n",
       "2     4.0     4.0     NaN     NaN     4.0     2.0     4.0    4    1    A  \n",
       "3     NaN     NaN     NaN     NaN     NaN     NaN     NaN    3    3    C  \n",
       "4     NaN     NaN     1.0     1.0     NaN     NaN     NaN    3    3    D  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'df' is your DataFrame\n",
    "import numpy as np\n",
    "\n",
    "# Replace non-numeric values with NaN\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36ed904e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed data shape for k=1: (6108, 74)\n",
      "Imputed data shape for k=3: (6108, 74)\n",
      "Imputed data shape for k=5: (6108, 74)\n",
      "Imputed data shape for k=7: (6108, 74)\n",
      "Imputed data shape for k=9: (6108, 74)\n",
      "Imputed data shape for k=11: (6108, 74)\n",
      "Imputed data shape for k=15: (6108, 74)\n",
      "Imputed data shape for k=19: (6108, 74)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'exclude_column_name' is the column to exclude\n",
    "exclude_column_name = 'Q16'\n",
    "column_to_exclude = df[exclude_column_name]\n",
    "\n",
    "# Create a list of k values\n",
    "k_values = [1, 3, 5, 7, 9,11,15,19]\n",
    "\n",
    "# Loop through each k value\n",
    "for k in k_values:\n",
    "    # Drop the column you want to exclude\n",
    "    columns_to_impute = df.drop(columns=[exclude_column_name])\n",
    "    \n",
    "    # Apply KNN imputation for the current k value\n",
    "    imputer = KNNImputer(n_neighbors=k)\n",
    "    imputed_data = imputer.fit_transform(columns_to_impute)\n",
    "    \n",
    "    # Use the imputed data for further processing or modeling\n",
    "    # ...\n",
    "    imputed_df = pd.DataFrame(imputed_data, columns=columns_to_impute.columns)\n",
    "    imputed_df[exclude_column_name] = column_to_exclude\n",
    "\n",
    "    # Example: Print imputed data shape\n",
    "    print(f\"Imputed data shape for k={k}: {imputed_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0ca55a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q11_1: float64\n",
      "Q11_2: float64\n",
      "Q11_3: float64\n",
      "Q11_4: float64\n",
      "Q11_5: float64\n",
      "Q11_6: float64\n",
      "Q11_7: float64\n",
      "Q11_8: float64\n",
      "Q11_9: float64\n",
      "Q11_10: float64\n",
      "Q11_11: float64\n",
      "Q11_12: float64\n",
      "Q11_13: float64\n",
      "Q11_Dont_Know: float64\n",
      "Q12_1: float64\n",
      "Q12_2: float64\n",
      "Q12_3: float64\n",
      "Q12_4: float64\n",
      "Q12_5: float64\n",
      "Q12_6: float64\n",
      "Q12_7: float64\n",
      "Q12_8: float64\n",
      "Q12_9: float64\n",
      "Q12_10: float64\n",
      "Q12_11: float64\n",
      "Q12_12: float64\n",
      "Q12_13: float64\n",
      "Q12_14: float64\n",
      "Q12_Dont_Know: float64\n",
      "Q13_1: float64\n",
      "Q13_2: float64\n",
      "Q13_3: float64\n",
      "Q13_4: float64\n",
      "Q13_5: float64\n",
      "Q13_6: float64\n",
      "Q13_7: float64\n",
      "Q13_8: float64\n",
      "Q13_9: float64\n",
      "Q13_10: float64\n",
      "Q13_11: float64\n",
      "Q13_12: float64\n",
      "Q13_13: float64\n",
      "Q13_14: float64\n",
      "Q13_15: float64\n",
      "Q13_16: float64\n",
      "Q13_Dont_Know: float64\n",
      "Q14: float64\n",
      "Q15: float64\n",
      "Q17: float64\n",
      "Q18_1: float64\n",
      "Q18_2: float64\n",
      "Q18_3: float64\n",
      "Q18_4: float64\n",
      "Q18_5: float64\n",
      "Q18_6: float64\n",
      "Q18_7: float64\n",
      "Q18_8: float64\n",
      "Q18_9: float64\n",
      "Q18_10: float64\n",
      "Q18_11: float64\n",
      "Q18_12: float64\n",
      "Q18_13: float64\n",
      "Q18_14: float64\n",
      "Q18_15: float64\n",
      "Q18_16: float64\n",
      "Q18_17: float64\n",
      "Q18_18: float64\n",
      "Q18_19: float64\n",
      "Q18_20: float64\n",
      "Q18_21: float64\n",
      "Q18_22: float64\n",
      "Q18_23: float64\n",
      "Q20: float64\n",
      "Q21: float64\n",
      "Q16: object\n"
     ]
    }
   ],
   "source": [
    "for column, dtype in imputed_df.dtypes.items():\n",
    "    print(f\"{column}: {dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca5caf35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q11_1     float64\n",
      "Q11_2     float64\n",
      "Q11_3     float64\n",
      "Q11_4     float64\n",
      "Q11_5     float64\n",
      "           ...   \n",
      "Q18_22    float64\n",
      "Q18_23    float64\n",
      "Q20       float64\n",
      "Q21       float64\n",
      "Q16        object\n",
      "Length: 75, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(imputed_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6da470d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q11_1</th>\n",
       "      <th>Q11_2</th>\n",
       "      <th>Q11_3</th>\n",
       "      <th>Q11_4</th>\n",
       "      <th>Q11_5</th>\n",
       "      <th>Q11_6</th>\n",
       "      <th>Q11_7</th>\n",
       "      <th>Q11_8</th>\n",
       "      <th>Q11_9</th>\n",
       "      <th>Q11_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q18_17</th>\n",
       "      <th>Q18_18</th>\n",
       "      <th>Q18_19</th>\n",
       "      <th>Q18_20</th>\n",
       "      <th>Q18_21</th>\n",
       "      <th>Q18_22</th>\n",
       "      <th>Q18_23</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.736842</td>\n",
       "      <td>2.368421</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.894737</td>\n",
       "      <td>2.842105</td>\n",
       "      <td>3.105263</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.105263</td>\n",
       "      <td>2.789474</td>\n",
       "      <td>2.684211</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.315789</td>\n",
       "      <td>1.842105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.052632</td>\n",
       "      <td>1.473684</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q11_1  Q11_2  Q11_3  Q11_4  Q11_5  Q11_6  Q11_7  Q11_8  Q11_9  Q11_10  ...  \\\n",
       "0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    1.0    0.0     0.0  ...   \n",
       "1    1.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0     1.0  ...   \n",
       "2    1.0    1.0    0.0    1.0    0.0    0.0    1.0    1.0    0.0     1.0  ...   \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0  ...   \n",
       "4    1.0    1.0    0.0    1.0    0.0    0.0    1.0    1.0    0.0     1.0  ...   \n",
       "\n",
       "     Q18_17    Q18_18    Q18_19    Q18_20    Q18_21    Q18_22    Q18_23  Q20  \\\n",
       "0  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000  3.0   \n",
       "1  4.000000  2.000000  4.000000  2.000000  2.000000  2.000000  2.000000  3.0   \n",
       "2  4.000000  4.000000  3.736842  2.368421  4.000000  2.000000  4.000000  4.0   \n",
       "3  2.894737  2.842105  3.105263  3.000000  3.105263  2.789474  2.684211  3.0   \n",
       "4  2.315789  1.842105  1.000000  1.000000  2.052632  1.473684  2.000000  3.0   \n",
       "\n",
       "   Q21  Q16  \n",
       "0  3.0    A  \n",
       "1  3.0    D  \n",
       "2  1.0    A  \n",
       "3  3.0    C  \n",
       "4  3.0    D  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_df.head()\n",
    "# missing values KNN kullanÄ±larak en iyi k ddeÄŸeri seÃ§meye Ã§alÄ±ÅŸÄ±larak dolduruldu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9339b831",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q11_1     0\n",
      "Q11_2     0\n",
      "Q11_3     0\n",
      "Q11_4     0\n",
      "Q11_5     0\n",
      "         ..\n",
      "Q18_22    0\n",
      "Q18_23    0\n",
      "Q20       0\n",
      "Q21       0\n",
      "Q16       0\n",
      "Length: 75, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(imputed_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a357f7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q11_1</th>\n",
       "      <th>Q11_2</th>\n",
       "      <th>Q11_3</th>\n",
       "      <th>Q11_4</th>\n",
       "      <th>Q11_5</th>\n",
       "      <th>Q11_6</th>\n",
       "      <th>Q11_7</th>\n",
       "      <th>Q11_8</th>\n",
       "      <th>Q11_9</th>\n",
       "      <th>Q11_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q18_17</th>\n",
       "      <th>Q18_18</th>\n",
       "      <th>Q18_19</th>\n",
       "      <th>Q18_20</th>\n",
       "      <th>Q18_21</th>\n",
       "      <th>Q18_22</th>\n",
       "      <th>Q18_23</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.736842</td>\n",
       "      <td>2.368421</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.894737</td>\n",
       "      <td>2.842105</td>\n",
       "      <td>3.105263</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.105263</td>\n",
       "      <td>2.789474</td>\n",
       "      <td>2.684211</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.315789</td>\n",
       "      <td>1.842105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.052632</td>\n",
       "      <td>1.473684</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q11_1  Q11_2  Q11_3  Q11_4  Q11_5  Q11_6  Q11_7  Q11_8  Q11_9  Q11_10  ...  \\\n",
       "0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    1.0    0.0     0.0  ...   \n",
       "1    1.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0     1.0  ...   \n",
       "2    1.0    1.0    0.0    1.0    0.0    0.0    1.0    1.0    0.0     1.0  ...   \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0  ...   \n",
       "4    1.0    1.0    0.0    1.0    0.0    0.0    1.0    1.0    0.0     1.0  ...   \n",
       "\n",
       "     Q18_17    Q18_18    Q18_19    Q18_20    Q18_21    Q18_22    Q18_23  Q20  \\\n",
       "0  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000  3.0   \n",
       "1  4.000000  2.000000  4.000000  2.000000  2.000000  2.000000  2.000000  3.0   \n",
       "2  4.000000  4.000000  3.736842  2.368421  4.000000  2.000000  4.000000  4.0   \n",
       "3  2.894737  2.842105  3.105263  3.000000  3.105263  2.789474  2.684211  3.0   \n",
       "4  2.315789  1.842105  1.000000  1.000000  2.052632  1.473684  2.000000  3.0   \n",
       "\n",
       "   Q21  Q16  \n",
       "0  3.0    A  \n",
       "1  3.0    D  \n",
       "2  1.0    A  \n",
       "3  3.0    C  \n",
       "4  3.0    D  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_df.head()\n",
    "#control amaclÄ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80961be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.feature_selection import RFE\\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.svm import SVC\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\n\\n# Ã–nceden belirlenmiÅŸ X ve y\\'yi kullanalÄ±m\\n# X: Ã–zellik matrisi, y: Hedef deÄŸiÅŸken\\n# Ã–rneÄŸin, new_X ve new_y\\'yi kullanalÄ±m\\nX = imputed_df.drop(\\'Q16\\', axis=1)\\ny = imputed_df[\\'Q16\\']\\nX_train, X_test, y_train, y_test = train_test_split(new_X, new_y, test_size=0.2, random_state=42)\\n\\n# KullanÄ±lacak sÄ±nÄ±flandÄ±rÄ±cÄ± modelleri\\nclassifiers = {\\n    \\'Random Forest\\': RandomForestClassifier(),\\n    \\'Gradient Boosting\\': GradientBoostingClassifier(),\\n    \\'Logistic Regression\\': LogisticRegression(max_iter=1000),\\n    \\'SVM\\': SVC(),\\n    \\'K-Nearest Neighbors\\': KNeighborsClassifier(),\\n    \\'Decision Tree\\': DecisionTreeClassifier(),\\n    \\'Gaussian Naive Bayes\\': GaussianNB(),\\n    \\'Neural Network\\': MLPClassifier(max_iter=1000),\\n    \\'QDA\\': QuadraticDiscriminantAnalysis(),\\n    \\'AdaBoost\\': AdaBoostClassifier()\\n}\\n\\n# Her bir sÄ±nÄ±flandÄ±rÄ±cÄ± modeli iÃ§in RFE uygulayarak doÄŸruluk skorlarÄ±nÄ± Ã¶lÃ§Ã¼n\\nfor clf_name, clf in classifiers.items():\\n    print(f\"Evaluating {clf_name} with RFE:\")\\n    \\n    # RFE\\'yi kullanarak Ã¶zellik seÃ§imi yapÄ±n\\n    rfe = RFE(clf, n_features_to_select=5)  # Ã–rneÄŸin, 5 Ã¶zellik bÄ±rakmak istiyoruz\\n    X_train_rfe = rfe.fit_transform(X_train, y_train)\\n    \\n    # Modeli eÄŸitin\\n    clf.fit(X_train_rfe, y_train)\\n    \\n    # Test seti Ã¼zerinde tahminler yapÄ±n\\n    X_test_rfe = rfe.transform(X_test)\\n    y_pred = clf.predict(X_test_rfe)\\n    \\n    # DoÄŸruluk skorunu deÄŸerlendirin\\n    accuracy = accuracy_score(y_test, y_pred)\\n    print(f\"Model Accuracy: {accuracy:.4f}\")\\n    print(\"-------------------------------------------\")\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Ã–nceden belirlenmiÅŸ X ve y'yi kullanalÄ±m\n",
    "# X: Ã–zellik matrisi, y: Hedef deÄŸiÅŸken\n",
    "# Ã–rneÄŸin, new_X ve new_y'yi kullanalÄ±m\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X, new_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# KullanÄ±lacak sÄ±nÄ±flandÄ±rÄ±cÄ± modelleri\n",
    "classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'SVM': SVC(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'Neural Network': MLPClassifier(max_iter=1000),\n",
    "    'QDA': QuadraticDiscriminantAnalysis(),\n",
    "    'AdaBoost': AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "# Her bir sÄ±nÄ±flandÄ±rÄ±cÄ± modeli iÃ§in RFE uygulayarak doÄŸruluk skorlarÄ±nÄ± Ã¶lÃ§Ã¼n\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"Evaluating {clf_name} with RFE:\")\n",
    "    \n",
    "    # RFE'yi kullanarak Ã¶zellik seÃ§imi yapÄ±n\n",
    "    rfe = RFE(clf, n_features_to_select=5)  # Ã–rneÄŸin, 5 Ã¶zellik bÄ±rakmak istiyoruz\n",
    "    X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "    \n",
    "    # Modeli eÄŸitin\n",
    "    clf.fit(X_train_rfe, y_train)\n",
    "    \n",
    "    # Test seti Ã¼zerinde tahminler yapÄ±n\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    y_pred = clf.predict(X_test_rfe)\n",
    "    \n",
    "    # DoÄŸruluk skorunu deÄŸerlendirin\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "    print(\"-------------------------------------------\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "83c3c674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã‡apraz DoÄŸrulama Seti 1: DoÄŸruluk = 0.5671031096563012\n",
      "Ã‡apraz DoÄŸrulama Seti 2: DoÄŸruluk = 0.6145662847790507\n",
      "Ã‡apraz DoÄŸrulama Seti 3: DoÄŸruluk = 0.6072013093289689\n",
      "Ã‡apraz DoÄŸrulama Seti 4: DoÄŸruluk = 0.592956592956593\n",
      "Ã‡apraz DoÄŸrulama Seti 5: DoÄŸruluk = 0.6003276003276004\n",
      "\n",
      "5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk: 0.5964309794097028\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "# Ã–rnek veri setini oluÅŸtur\n",
    "# imputed_df'yi veri setiniz olarak kullanÄ±n\n",
    "\n",
    "# Ã–zellik ve hedef deÄŸiÅŸkeni seÃ§\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "new_X = X[filtered_entries]\n",
    "new_y = y[filtered_entries]\n",
    "\n",
    "# Ã–zellik seÃ§imi: Pearson korelasyon katsayÄ±sÄ± ile en iyi k Ã¶zelliÄŸi seÃ§\n",
    "k_best_features = 2\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "X_selected = feature_selector.fit_transform(X, y)\n",
    "\n",
    "# Veriyi standartlaÅŸtÄ±r\n",
    "scaler = StandardScaler()\n",
    "X_selected_standardized = scaler.fit_transform(X_selected)\n",
    "\n",
    "# Decision Tree modelini tanÄ±mla\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 5 katlÄ± Ã§apraz doÄŸrulama ile doÄŸruluk skorlarÄ±nÄ± al\n",
    "cv_scores = cross_val_score(dt_model, X_selected_standardized, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir Ã§apraz doÄŸrulama seti iÃ§in doÄŸruluk skorlarÄ±nÄ± yazdÄ±r\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: DoÄŸruluk = {score}\")\n",
    "\n",
    "# Ortalama doÄŸruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ef797745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã‡apraz DoÄŸrulama Seti 1: DoÄŸruluk = 0.5945945945945946\n",
      "Ã‡apraz DoÄŸrulama Seti 2: DoÄŸruluk = 0.6136724960254372\n",
      "Ã‡apraz DoÄŸrulama Seti 3: DoÄŸruluk = 0.6391096979332274\n",
      "Ã‡apraz DoÄŸrulama Seti 4: DoÄŸruluk = 0.6194267515923567\n",
      "Ã‡apraz DoÄŸrulama Seti 5: DoÄŸruluk = 0.6273885350318471\n",
      "\n",
      "5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk: 0.6188384150354926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "# Ã–zellik ve hedef deÄŸiÅŸkeni seÃ§\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "# Ã–zellik seÃ§imi: Pearson korelasyon katsayÄ±sÄ± ile en iyi k Ã¶zelliÄŸi seÃ§\n",
    "k_best_features = 5\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "X_selected = feature_selector.fit_transform(X, y)\n",
    "\n",
    "# EÄŸitim ve test setlerini oluÅŸtur\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Veriyi standartlaÅŸtÄ±r\n",
    "scaler = StandardScaler()\n",
    "X_selected_standardized = scaler.fit_transform(X_selected)\n",
    "\n",
    "# KNN modelini tanÄ±mla\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# 5 katlÄ± Ã§apraz doÄŸrulama ile doÄŸruluk skorlarÄ±nÄ± al\n",
    "cv_scores = cross_val_score(knn_model, X_selected_standardized, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir Ã§apraz doÄŸrulama seti iÃ§in doÄŸruluk skorlarÄ±nÄ± yazdÄ±r\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: DoÄŸruluk = {score}\")\n",
    "\n",
    "# Ortalama doÄŸruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bad4de46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã‡apraz DoÄŸrulama Seti 1: DoÄŸruluk = 0.6073131955484896\n",
      "Ã‡apraz DoÄŸrulama Seti 2: DoÄŸruluk = 0.6200317965023847\n",
      "Ã‡apraz DoÄŸrulama Seti 3: DoÄŸruluk = 0.6375198728139905\n",
      "Ã‡apraz DoÄŸrulama Seti 4: DoÄŸruluk = 0.6337579617834395\n",
      "Ã‡apraz DoÄŸrulama Seti 5: DoÄŸruluk = 0.6560509554140127\n",
      "\n",
      "5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk: 0.6309347564124634\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "# Ã–zellik ve hedef deÄŸiÅŸkeni seÃ§\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "# Ã–zellik seÃ§imi: Pearson korelasyon katsayÄ±sÄ± ile en iyi k Ã¶zelliÄŸi seÃ§\n",
    "k_best_features = 5\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "X_selected = feature_selector.fit_transform(X, y)\n",
    "\n",
    "# EÄŸitim ve test setlerini oluÅŸtur\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Veriyi standartlaÅŸtÄ±r\n",
    "scaler = StandardScaler()\n",
    "X_selected_standardized = scaler.fit_transform(X_selected)\n",
    "\n",
    "# Logistik Regresyon modelini tanÄ±mla\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# 5 katlÄ± Ã§apraz doÄŸrulama ile doÄŸruluk skorlarÄ±nÄ± al\n",
    "cv_scores = cross_val_score(logreg_model, X_selected_standardized, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir Ã§apraz doÄŸrulama seti iÃ§in doÄŸruluk skorlarÄ±nÄ± yazdÄ±r\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: DoÄŸruluk = {score}\")\n",
    "\n",
    "# Ortalama doÄŸruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "50559126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã‡apraz DoÄŸrulama Seti 1: DoÄŸruluk = 0.6232114467408585\n",
      "Ã‡apraz DoÄŸrulama Seti 2: DoÄŸruluk = 0.6422893481717011\n",
      "Ã‡apraz DoÄŸrulama Seti 3: DoÄŸruluk = 0.6422893481717011\n",
      "Ã‡apraz DoÄŸrulama Seti 4: DoÄŸruluk = 0.6305732484076433\n",
      "Ã‡apraz DoÄŸrulama Seti 5: DoÄŸruluk = 0.6480891719745223\n",
      "\n",
      "5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk: 0.6372905126932853\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "# Ã–zellik ve hedef deÄŸiÅŸkeni seÃ§\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "\n",
    "# Ã–zellik seÃ§imi: Pearson korelasyon katsayÄ±sÄ± ile en iyi k Ã¶zelliÄŸi seÃ§\n",
    "k_best_features = 8\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "X_selected = feature_selector.fit_transform(X, y)\n",
    "\n",
    "# EÄŸitim ve test setlerini oluÅŸtur\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Veriyi standartlaÅŸtÄ±r\n",
    "scaler = StandardScaler()\n",
    "X_selected_standardized = scaler.fit_transform(X_selected)\n",
    "\n",
    "# Gradient Boosting modelini tanÄ±mla\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# 5 katlÄ± Ã§apraz doÄŸrulama ile doÄŸruluk skorlarÄ±nÄ± al\n",
    "cv_scores = cross_val_score(gb_model, X_selected_standardized, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir Ã§apraz doÄŸrulama seti iÃ§in doÄŸruluk skorlarÄ±nÄ± yazdÄ±r\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: DoÄŸruluk = {score}\")\n",
    "\n",
    "# Ortalama doÄŸruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ef923cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã‡apraz DoÄŸrulama Seti 1: DoÄŸruluk = 0.6136724960254372\n",
      "Ã‡apraz DoÄŸrulama Seti 2: DoÄŸruluk = 0.6454689984101749\n",
      "Ã‡apraz DoÄŸrulama Seti 3: DoÄŸruluk = 0.6343402225755167\n",
      "Ã‡apraz DoÄŸrulama Seti 4: DoÄŸruluk = 0.6528662420382165\n",
      "Ã‡apraz DoÄŸrulama Seti 5: DoÄŸruluk = 0.6401273885350318\n",
      "\n",
      "5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk: 0.6372950695168754\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "# Ã–zellik ve hedef deÄŸiÅŸkeni seÃ§\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit Ã¶zellikleri Ã§Ä±kar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "# Ã–zellik seÃ§imi: Pearson korelasyon katsayÄ±sÄ± ile en iyi k Ã¶zelliÄŸi seÃ§\n",
    "k_best_features = 20\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "X_selected = feature_selector.fit_transform(X, y)\n",
    "\n",
    "# EÄŸitim ve test setlerini oluÅŸtur\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Veriyi standartlaÅŸtÄ±r\n",
    "scaler = StandardScaler()\n",
    "X_selected_standardized = scaler.fit_transform(X_selected)\n",
    "\n",
    "# Random Forest modelini tanÄ±mla\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 5 katlÄ± Ã§apraz doÄŸrulama ile doÄŸruluk skorlarÄ±nÄ± al\n",
    "cv_scores = cross_val_score(rf_model, X_selected_standardized, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir Ã§apraz doÄŸrulama seti iÃ§in doÄŸruluk skorlarÄ±nÄ± yazdÄ±r\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: DoÄŸruluk = {score}\")\n",
    "\n",
    "# Ortalama doÄŸruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7e568f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã‡apraz DoÄŸrulama Seti 1: DoÄŸruluk = 0.5659777424483307\n",
      "Ã‡apraz DoÄŸrulama Seti 2: DoÄŸruluk = 0.5691573926868044\n",
      "Ã‡apraz DoÄŸrulama Seti 3: DoÄŸruluk = 0.5691573926868044\n",
      "Ã‡apraz DoÄŸrulama Seti 4: DoÄŸruluk = 0.589171974522293\n",
      "Ã‡apraz DoÄŸrulama Seti 5: DoÄŸruluk = 0.5684713375796179\n",
      "\n",
      "5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk: 0.5723871679847701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "# Ã–zellik ve hedef deÄŸiÅŸkeni seÃ§\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit Ã¶zellikleri Ã§Ä±kar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "\n",
    "# Ã–zellik seÃ§imi: Pearson korelasyon katsayÄ±sÄ± ile en iyi k Ã¶zelliÄŸi seÃ§\n",
    "k_best_features = 2\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "X_selected = feature_selector.fit_transform(X, y)\n",
    "\n",
    "# EÄŸitim ve test setlerini oluÅŸtur\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Veriyi standartlaÅŸtÄ±r\n",
    "scaler = StandardScaler()\n",
    "X_selected_standardized = scaler.fit_transform(X_selected)\n",
    "\n",
    "# SVM modelini tanÄ±mla\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "\n",
    "# 5 katlÄ± Ã§apraz doÄŸrulama ile doÄŸruluk skorlarÄ±nÄ± al\n",
    "cv_scores = cross_val_score(svm_model, X_selected_standardized, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir Ã§apraz doÄŸrulama seti iÃ§in doÄŸruluk skorlarÄ±nÄ± yazdÄ±r\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: DoÄŸruluk = {score}\")\n",
    "\n",
    "# Ortalama doÄŸruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "078e9aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã‡apraz DoÄŸrulama Seti 1: DoÄŸruluk = 0.6094069529652352\n",
      "Ã‡apraz DoÄŸrulama Seti 2: DoÄŸruluk = 0.6264073694984647\n",
      "Ã‡apraz DoÄŸrulama Seti 3: DoÄŸruluk = 0.593654042988741\n",
      "Ã‡apraz DoÄŸrulama Seti 4: DoÄŸruluk = 0.6131013306038895\n",
      "Ã‡apraz DoÄŸrulama Seti 5: DoÄŸruluk = 0.6069600818833163\n",
      "\n",
      "5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk: 0.6099059555879294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PCA uygula\n",
    "pca = PCA(n_components=5)  # Ã–rneÄŸin, 5 bileÅŸen kullanalÄ±m\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# SVM modelini tanÄ±mla\n",
    "svm_model = SVC()\n",
    "\n",
    "# 5 katlÄ± Ã§apraz doÄŸrulama ile doÄŸruluk skorlarÄ±nÄ± al\n",
    "cv_scores = cross_val_score(svm_model, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir Ã§apraz doÄŸrulama seti iÃ§in doÄŸruluk skorlarÄ±nÄ± yazdÄ±r\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: DoÄŸruluk = {score}\")\n",
    "\n",
    "# Ortalama doÄŸruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7d930622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã‡apraz DoÄŸrulama Seti 1: DoÄŸruluk = 0.6202783300198808\n",
      "Ã‡apraz DoÄŸrulama Seti 2: DoÄŸruluk = 0.6163021868787276\n",
      "Ã‡apraz DoÄŸrulama Seti 3: DoÄŸruluk = 0.5825049701789264\n",
      "Ã‡apraz DoÄŸrulama Seti 4: DoÄŸruluk = 0.5924453280318092\n",
      "Ã‡apraz DoÄŸrulama Seti 5: DoÄŸruluk = 0.6055776892430279\n",
      "\n",
      "5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk: 0.6034217008704743\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PCA uygula\n",
    "pca = PCA(n_components=5)  # Ã–rneÄŸin, 5 bileÅŸen kullanalÄ±m\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Neural Networks modelini tanÄ±mla\n",
    "nn_model = MLPClassifier(max_iter=1000)  # max_iter parametresi artÄ±rÄ±labilir\n",
    "\n",
    "# 5 katlÄ± Ã§apraz doÄŸrulama ile doÄŸruluk skorlarÄ±nÄ± al\n",
    "cv_scores = cross_val_score(nn_model, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir Ã§apraz doÄŸrulama seti iÃ§in doÄŸruluk skorlarÄ±nÄ± yazdÄ±r\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: DoÄŸruluk = {score}\")\n",
    "\n",
    "# Ortalama doÄŸruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5c481bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã‡apraz DoÄŸrulama Seti 1: DoÄŸruluk = 0.5838445807770961\n",
      "Ã‡apraz DoÄŸrulama Seti 2: DoÄŸruluk = 0.6069600818833163\n",
      "Ã‡apraz DoÄŸrulama Seti 3: DoÄŸruluk = 0.5762538382804504\n",
      "Ã‡apraz DoÄŸrulama Seti 4: DoÄŸruluk = 0.6049129989764586\n",
      "Ã‡apraz DoÄŸrulama Seti 5: DoÄŸruluk = 0.6100307062436029\n",
      "\n",
      "5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk: 0.5964004412321848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Ã–nceden belirlenmiÅŸ X ve y'yi kullanalÄ±m\n",
    "# X: Ã–zellik matrisi, y: Hedef deÄŸiÅŸken\n",
    "# Ã–rneÄŸin, new_X ve new_y'yi kullanalÄ±m\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PCA uygula\n",
    "pca = PCA(n_components=5)  # Ã–rneÄŸin, 5 bileÅŸen kullanalÄ±m\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Random Forest modelini tanÄ±mla\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# 5 katlÄ± Ã§apraz doÄŸrulama ile doÄŸruluk skorlarÄ±nÄ± al\n",
    "cv_scores = cross_val_score(rf_model, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir Ã§apraz doÄŸrulama seti iÃ§in doÄŸruluk skorlarÄ±nÄ± yazdÄ±r\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: DoÄŸruluk = {score}\")\n",
    "\n",
    "# Ortalama doÄŸruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ed9b2b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã‡apraz DoÄŸrulama Seti 1: DoÄŸruluk = 0.4990059642147117\n",
      "Ã‡apraz DoÄŸrulama Seti 2: DoÄŸruluk = 0.5069582504970179\n",
      "Ã‡apraz DoÄŸrulama Seti 3: DoÄŸruluk = 0.4970178926441352\n",
      "Ã‡apraz DoÄŸrulama Seti 4: DoÄŸruluk = 0.510934393638171\n",
      "Ã‡apraz DoÄŸrulama Seti 5: DoÄŸruluk = 0.5059760956175299\n",
      "\n",
      "5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk: 0.5039785193223131\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Ã–nceden belirlenmiÅŸ X ve y'yi kullanalÄ±m\n",
    "# X: Ã–zellik matrisi, y: Hedef deÄŸiÅŸken\n",
    "# Ã–rneÄŸin, new_X ve new_y'yi kullanalÄ±m\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PCA uygula\n",
    "pca = PCA(n_components=5)  # Ã–rneÄŸin, 5 bileÅŸen kullanalÄ±m\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Decision Tree modelini tanÄ±mla\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# 5 katlÄ± Ã§apraz doÄŸrulama ile doÄŸruluk skorlarÄ±nÄ± al\n",
    "cv_scores = cross_val_score(dt_model, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir Ã§apraz doÄŸrulama seti iÃ§in doÄŸruluk skorlarÄ±nÄ± yazdÄ±r\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: DoÄŸruluk = {score}\")\n",
    "\n",
    "# Ortalama doÄŸruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ba4ec93b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã‡apraz DoÄŸrulama Seti 1: DoÄŸruluk = 0.5705521472392638\n",
      "Ã‡apraz DoÄŸrulama Seti 2: DoÄŸruluk = 0.5967246673490276\n",
      "Ã‡apraz DoÄŸrulama Seti 3: DoÄŸruluk = 0.5598771750255885\n",
      "Ã‡apraz DoÄŸrulama Seti 4: DoÄŸruluk = 0.5619242579324463\n",
      "Ã‡apraz DoÄŸrulama Seti 5: DoÄŸruluk = 0.586489252814739\n",
      "\n",
      "5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk: 0.5751135000722132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Ã–nceden belirlenmiÅŸ X ve y'yi kullanalÄ±m\n",
    "# X: Ã–zellik matrisi, y: Hedef deÄŸiÅŸken\n",
    "# Ã–rneÄŸin, new_X ve new_y'yi kullanalÄ±m\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PCA uygula\n",
    "pca = PCA(n_components=5)  # Ã–rneÄŸin, 5 bileÅŸen kullanalÄ±m\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# K-Nearest Neighbors modelini tanÄ±mla\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# 5 katlÄ± Ã§apraz doÄŸrulama ile doÄŸruluk skorlarÄ±nÄ± al\n",
    "cv_scores = cross_val_score(knn_model, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir Ã§apraz doÄŸrulama seti iÃ§in doÄŸruluk skorlarÄ±nÄ± yazdÄ±r\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: DoÄŸruluk = {score}\")\n",
    "\n",
    "# Ortalama doÄŸruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "84ce113d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã‡apraz DoÄŸrulama Seti 1: DoÄŸruluk = 0.6023856858846919\n",
      "Ã‡apraz DoÄŸrulama Seti 2: DoÄŸruluk = 0.610337972166998\n",
      "Ã‡apraz DoÄŸrulama Seti 3: DoÄŸruluk = 0.5924453280318092\n",
      "Ã‡apraz DoÄŸrulama Seti 4: DoÄŸruluk = 0.6341948310139165\n",
      "Ã‡apraz DoÄŸrulama Seti 5: DoÄŸruluk = 0.6055776892430279\n",
      "\n",
      "5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk: 0.6089883012680887\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Ã–nceden belirlenmiÅŸ X ve y'yi kullanalÄ±m\n",
    "# X: Ã–zellik matrisi, y: Hedef deÄŸiÅŸken\n",
    "# Ã–rneÄŸin, new_X ve new_y'yi kullanalÄ±m\n",
    "from scipy import stats\n",
    "# Ã–zellik ve hedef deÄŸiÅŸkeni seÃ§\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit Ã¶zellikleri Ã§Ä±kar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PCA uygula\n",
    "pca = PCA(n_components=5)  # Ã–rneÄŸin, 5 bileÅŸen kullanalÄ±m\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Naive Bayes modelini tanÄ±mla\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# 5 katlÄ± Ã§apraz doÄŸrulama ile doÄŸruluk skorlarÄ±nÄ± al\n",
    "cv_scores = cross_val_score(nb_model, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir Ã§apraz doÄŸrulama seti iÃ§in doÄŸruluk skorlarÄ±nÄ± yazdÄ±r\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: DoÄŸruluk = {score}\")\n",
    "\n",
    "# Ortalama doÄŸruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "995e6142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elifn\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\elifn\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elifn\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elifn\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\elifn\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã‡apraz DoÄŸrulama Seti 1: DoÄŸruluk = 0.6339468302658486\n",
      "Ã‡apraz DoÄŸrulama Seti 2: DoÄŸruluk = 0.6438075742067554\n",
      "Ã‡apraz DoÄŸrulama Seti 3: DoÄŸruluk = 0.638689866939611\n",
      "Ã‡apraz DoÄŸrulama Seti 4: DoÄŸruluk = 0.638689866939611\n",
      "Ã‡apraz DoÄŸrulama Seti 5: DoÄŸruluk = 0.6345957011258956\n",
      "\n",
      "5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk: 0.6379459678955444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elifn\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "# Daha sonra k-means iÅŸlemlerine devam edebilirsiniz\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "y_kmeans = kmeans.fit_predict(X)\n",
    "\n",
    "# Elde edilen kÃ¼meleme sonuÃ§larÄ±nÄ± yeni bir Ã¶zellik olarak ekleyin\n",
    "X_with_clusters = pd.concat([pd.DataFrame(X), pd.DataFrame({'Cluster': y_kmeans})], axis=1)\n",
    "\n",
    "# Veriyi eÄŸitim ve test setlerine bÃ¶lelim\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_with_clusters, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression modelini tanÄ±mla\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "# 5 katlÄ± Ã§apraz doÄŸrulama ile doÄŸruluk skorlarÄ±nÄ± al\n",
    "cv_scores = cross_val_score(logistic_regression, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir Ã§apraz doÄŸrulama seti iÃ§in doÄŸruluk skorlarÄ±nÄ± yazdÄ±r\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: DoÄŸruluk = {score}\")\n",
    "\n",
    "# Ortalama doÄŸruluk skorunu hesapla\n",
    "mean_accuracy = cv_scores.mean()\n",
    "\n",
    "print(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "248903af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã‡apraz DoÄŸrulama Seti 1: DoÄŸruluk = 0.5869120654396728\n",
      "Ã‡apraz DoÄŸrulama Seti 2: DoÄŸruluk = 0.5752302968270215\n",
      "Ã‡apraz DoÄŸrulama Seti 3: DoÄŸruluk = 0.5916069600818833\n",
      "Ã‡apraz DoÄŸrulama Seti 4: DoÄŸruluk = 0.5916069600818833\n",
      "Ã‡apraz DoÄŸrulama Seti 5: DoÄŸruluk = 0.5875127942681678\n",
      "\n",
      "5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk: 0.5865738153397257\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Ã–nceden belirlenmiÅŸ X ve y'yi kullanalÄ±m\n",
    "# X: Ã–zellik matrisi, y: Hedef deÄŸiÅŸken\n",
    "# Ã–rneÄŸin, new_X ve new_y'yi kullanalÄ±m\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ã–ncelikle veriyi standartlaÅŸtÄ±rÄ±n (PCA iÃ§in Ã¶nemlidir)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# PCA ile boyut azaltma\n",
    "pca = PCA(n_components=5)  # Ã–rneÄŸin, 5 bileÅŸen kullanmak istiyoruz\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Linear SVM modelini tanÄ±mla\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "# 5 katlÄ± Ã§apraz doÄŸrulama ile doÄŸruluk skorlarÄ±nÄ± al\n",
    "cv_scores = cross_val_score(svm_classifier, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir Ã§apraz doÄŸrulama seti iÃ§in doÄŸruluk skorlarÄ±nÄ± yazdÄ±r\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: DoÄŸruluk = {score}\")\n",
    "\n",
    "# Ortalama doÄŸruluk skorunu hesapla\n",
    "mean_accuracy = cv_scores.mean()\n",
    "\n",
    "print(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cbfeb092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã‡apraz DoÄŸrulama Seti 1: DoÄŸruluk = 0.6124744376278118\n",
      "Ã‡apraz DoÄŸrulama Seti 2: DoÄŸruluk = 0.6059365404298874\n",
      "Ã‡apraz DoÄŸrulama Seti 3: DoÄŸruluk = 0.6038894575230297\n",
      "Ã‡apraz DoÄŸrulama Seti 4: DoÄŸruluk = 0.5987717502558854\n",
      "Ã‡apraz DoÄŸrulama Seti 5: DoÄŸruluk = 0.5916069600818833\n",
      "\n",
      "5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk: 0.6025358291836995\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Ã–nceden belirlenmiÅŸ X ve y'yi kullanalÄ±m\n",
    "# X: Ã–zellik matrisi, y: Hedef deÄŸiÅŸken\n",
    "# Ã–rneÄŸin, new_X ve new_y'yi kullanalÄ±m\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ã–ncelikle veriyi standartlaÅŸtÄ±rÄ±n (PCA iÃ§in Ã¶nemlidir)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# PCA ile boyut azaltma\n",
    "pca = PCA(n_components=5)  # Ã–rneÄŸin, 5 bileÅŸen kullanmak istiyoruz\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Logistic Regression modelini tanÄ±mla\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# 5 katlÄ± Ã§apraz doÄŸrulama ile doÄŸruluk skorlarÄ±nÄ± al\n",
    "cv_scores = cross_val_score(logreg, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir Ã§apraz doÄŸrulama seti iÃ§in doÄŸruluk skorlarÄ±nÄ± yazdÄ±r\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: DoÄŸruluk = {score}\")\n",
    "\n",
    "# Ortalama doÄŸruluk skorunu hesapla\n",
    "mean_accuracy = cv_scores.mean()\n",
    "\n",
    "print(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a3a9a43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Accuracy with RFECV: 0.6489\n",
      "Ã‡apraz DoÄŸrulama Seti 1: DoÄŸruluk = 0.6482617586912065\n",
      "Ã‡apraz DoÄŸrulama Seti 2: DoÄŸruluk = 0.6519959058341863\n",
      "Ã‡apraz DoÄŸrulama Seti 3: DoÄŸruluk = 0.6417604912998977\n",
      "Ã‡apraz DoÄŸrulama Seti 4: DoÄŸruluk = 0.6417604912998977\n",
      "Ã‡apraz DoÄŸrulama Seti 5: DoÄŸruluk = 0.6407369498464688\n",
      "\n",
      "5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk: 0.6449031193943314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Ã–nceden belirlenmiÅŸ X ve y'yi kullanalÄ±m\n",
    "# X: Ã–zellik matrisi, y: Hedef deÄŸiÅŸken\n",
    "# Ã–rneÄŸin, new_X ve new_y'yi kullanalÄ±m\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression modeli\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# RFECV'yi kullanarak Ã¶zellik seÃ§imi yapÄ±n\n",
    "rfecv = RFECV(estimator=logreg, step=1, cv=5, scoring='accuracy')  # cv=5, 5-fold cross-validation kullanÄ±yoruz\n",
    "X_train_rfecv = rfecv.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eÄŸitin\n",
    "logreg.fit(X_train_rfecv, y_train)\n",
    "\n",
    "# Test seti Ã¼zerinde tahminler yapÄ±n\n",
    "X_test_rfecv = rfecv.transform(X_test)\n",
    "y_pred = logreg.predict(X_test_rfecv)\n",
    "\n",
    "# DoÄŸruluk skorunu deÄŸerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Model Accuracy with RFECV: {accuracy:.4f}\")\n",
    "\n",
    "# Modelin performansÄ±nÄ± 5 katlÄ± Ã§apraz doÄŸrulama ile deÄŸerlendirin\n",
    "cv_scores = cross_val_score(logreg, X_train_rfecv, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir Ã§apraz doÄŸrulama seti iÃ§in doÄŸruluk skorlarÄ±nÄ± yazdÄ±r\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: DoÄŸruluk = {score}\")\n",
    "\n",
    "# Ortalama doÄŸruluk skorunu hesapla\n",
    "mean_accuracy = cv_scores.mean()\n",
    "\n",
    "print(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcb434b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Accuracy with RFECV: 0.6489\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Ã–nceden belirlenmiÅŸ X ve y'yi kullanalÄ±m\n",
    "# X: Ã–zellik matrisi, y: Hedef deÄŸiÅŸken\n",
    "# Ã–rneÄŸin, new_X ve new_y'yi kullanalÄ±m\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression modeli\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# RFECV'yi kullanarak Ã¶zellik seÃ§imi yapÄ±n\n",
    "rfecv = RFECV(estimator=logreg, step=1, cv=5, scoring='accuracy')  # cv=5, 5-fold cross-validation kullanÄ±yoruz\n",
    "X_train_rfecv = rfecv.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eÄŸitin\n",
    "logreg.fit(X_train_rfecv, y_train)\n",
    "\n",
    "# Test seti Ã¼zerinde tahminler yapÄ±n\n",
    "X_test_rfecv = rfecv.transform(X_test)\n",
    "y_pred = logreg.predict(X_test_rfecv)\n",
    "\n",
    "# DoÄŸruluk skorunu deÄŸerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Model Accuracy with RFECV: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5717a93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Accuracy: 0.6534\n",
      "Ã‡apraz DoÄŸrulama Seti 1: DoÄŸruluk = 0.5864811133200796\n",
      "Ã‡apraz DoÄŸrulama Seti 2: DoÄŸruluk = 0.6063618290258449\n",
      "Ã‡apraz DoÄŸrulama Seti 3: DoÄŸruluk = 0.588469184890656\n",
      "Ã‡apraz DoÄŸrulama Seti 4: DoÄŸruluk = 0.5984095427435387\n",
      "Ã‡apraz DoÄŸrulama Seti 5: DoÄŸruluk = 0.5916334661354582\n",
      "\n",
      "5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk: 0.5942710272231155\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Ã–nceden belirlenmiÅŸ X ve y'yi kullanalÄ±m\n",
    "# X: Ã–zellik matrisi, y: Hedef deÄŸiÅŸken\n",
    "# Ã–rneÄŸin, new_X ve new_y'yi kullanalÄ±m\n",
    "from scipy import stats\n",
    "# Ã–zellik ve hedef deÄŸiÅŸkeni seÃ§\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit Ã¶zellikleri Ã§Ä±kar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression modeli\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# RFE'yi kullanarak Ã¶zellik seÃ§imi yapÄ±n\n",
    "rfe = RFE(logreg, n_features_to_select=5)  # Ã–rneÄŸin, 5 Ã¶zellik bÄ±rakmak istiyoruz\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eÄŸitin\n",
    "logreg.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Test seti Ã¼zerinde tahminler yapÄ±n\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "y_pred = logreg.predict(X_test_rfe)\n",
    "\n",
    "# DoÄŸruluk skorunu deÄŸerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Modelin performansÄ±nÄ± 5 katlÄ± Ã§apraz doÄŸrulama ile deÄŸerlendirin\n",
    "cv_scores = cross_val_score(logreg, X_train_rfe, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir Ã§apraz doÄŸrulama seti iÃ§in doÄŸruluk skorlarÄ±nÄ± yazdÄ±r\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: DoÄŸruluk = {score}\")\n",
    "\n",
    "# Ortalama doÄŸruluk skorunu hesapla\n",
    "mean_accuracy = cv_scores.mean()\n",
    "\n",
    "print(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "13997113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Accuracy: 0.6534\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Ã–nceden belirlenmiÅŸ X ve y'yi kullanalÄ±m\n",
    "# X: Ã–zellik matrisi, y: Hedef deÄŸiÅŸken\n",
    "# Ã–rneÄŸin, new_X ve new_y'yi kullanalÄ±m\n",
    "from scipy import stats\n",
    "# Ã–zellik ve hedef deÄŸiÅŸkeni seÃ§\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit Ã¶zellikleri Ã§Ä±kar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression modeli\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# RFE'yi kullanarak Ã¶zellik seÃ§imi yapÄ±n\n",
    "rfe = RFE(logreg, n_features_to_select=5)  # Ã–rneÄŸin, 5 Ã¶zellik bÄ±rakmak istiyoruz\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eÄŸitin\n",
    "logreg.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Test seti Ã¼zerinde tahminler yapÄ±n\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "y_pred = logreg.predict(X_test_rfe)\n",
    "\n",
    "# DoÄŸruluk skorunu deÄŸerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Model Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4ba2f183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.6709\n",
      "Ã‡apraz DoÄŸrulama Seti 1: DoÄŸruluk = 0.6163021868787276\n",
      "Ã‡apraz DoÄŸrulama Seti 2: DoÄŸruluk = 0.6222664015904572\n",
      "Ã‡apraz DoÄŸrulama Seti 3: DoÄŸruluk = 0.5944333996023857\n",
      "Ã‡apraz DoÄŸrulama Seti 4: DoÄŸruluk = 0.6202783300198808\n",
      "Ã‡apraz DoÄŸrulama Seti 5: DoÄŸruluk = 0.6294820717131474\n",
      "\n",
      "5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk: 0.6165524779609197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Ã–nceden belirlenmiÅŸ X ve y'yi kullanalÄ±m\n",
    "# X: Ã–zellik matrisi, y: Hedef deÄŸiÅŸken\n",
    "# Ã–rneÄŸin, new_X ve new_y'yi kullanalÄ±m\n",
    "from scipy import stats\n",
    "# Ã–zellik ve hedef deÄŸiÅŸkeni seÃ§\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit Ã¶zellikleri Ã§Ä±kar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# AdaBoostClassifier modeli\n",
    "ada_clf = AdaBoostClassifier()\n",
    "\n",
    "# SelectFromModel kullanarak Ã¶zellik seÃ§imi yapÄ±n\n",
    "sfm = SelectFromModel(ada_clf, threshold=-np.inf, max_features=5)  # Ã–rneÄŸin, 5 Ã¶zellik bÄ±rakmak istiyoruz\n",
    "X_train_sfm = sfm.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eÄŸitin\n",
    "ada_clf.fit(X_train_sfm, y_train)\n",
    "\n",
    "# Test seti Ã¼zerinde tahminler yapÄ±n\n",
    "X_test_sfm = sfm.transform(X_test)\n",
    "y_pred = ada_clf.predict(X_test_sfm)\n",
    "\n",
    "# DoÄŸruluk skorunu deÄŸerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Modelin performansÄ±nÄ± 5 katlÄ± Ã§apraz doÄŸrulama ile deÄŸerlendirin\n",
    "cv_scores = cross_val_score(ada_clf, X_train_sfm, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir Ã§apraz doÄŸrulama seti iÃ§in doÄŸruluk skorlarÄ±nÄ± yazdÄ±r\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: DoÄŸruluk = {score}\")\n",
    "\n",
    "# Ortalama doÄŸruluk skorunu hesapla\n",
    "mean_accuracy = cv_scores.mean()\n",
    "\n",
    "print(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b3f5d796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.6709\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Ã–nceden belirlenmiÅŸ X ve y'yi kullanalÄ±m\n",
    "# X: Ã–zellik matrisi, y: Hedef deÄŸiÅŸken\n",
    "# Ã–rneÄŸin, new_X ve new_y'yi kullanalÄ±m\n",
    "from scipy import stats\n",
    "# Ã–zellik ve hedef deÄŸiÅŸkeni seÃ§\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit Ã¶zellikleri Ã§Ä±kar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# AdaBoostClassifier modeli\n",
    "ada_clf = AdaBoostClassifier()\n",
    "\n",
    "# SelectFromModel kullanarak Ã¶zellik seÃ§imi yapÄ±n\n",
    "sfm = SelectFromModel(ada_clf, threshold=-np.inf, max_features=5)  # Ã–rneÄŸin, 5 Ã¶zellik bÄ±rakmak istiyoruz\n",
    "X_train_sfm = sfm.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eÄŸitin\n",
    "ada_clf.fit(X_train_sfm, y_train)\n",
    "\n",
    "# Test seti Ã¼zerinde tahminler yapÄ±n\n",
    "X_test_sfm = sfm.transform(X_test)\n",
    "y_pred = ada_clf.predict(X_test_sfm)\n",
    "\n",
    "# DoÄŸruluk skorunu deÄŸerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7d897be4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.6884\n",
      "Ã‡apraz DoÄŸrulama Seti 1: DoÄŸruluk = 0.6202783300198808\n",
      "Ã‡apraz DoÄŸrulama Seti 2: DoÄŸruluk = 0.6381709741550696\n",
      "Ã‡apraz DoÄŸrulama Seti 3: DoÄŸruluk = 0.6023856858846919\n",
      "Ã‡apraz DoÄŸrulama Seti 4: DoÄŸruluk = 0.6023856858846919\n",
      "Ã‡apraz DoÄŸrulama Seti 5: DoÄŸruluk = 0.6553784860557769\n",
      "\n",
      "5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk: 0.6237198324000222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Ã–nceden belirlenmiÅŸ X ve y'yi kullanalÄ±m\n",
    "# X: Ã–zellik matrisi, y: Hedef deÄŸiÅŸken\n",
    "# Ã–rneÄŸin, new_X ve new_y'yi kullanalÄ±m\n",
    "from scipy import stats\n",
    "# Ã–zellik ve hedef deÄŸiÅŸkeni seÃ§\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit Ã¶zellikleri Ã§Ä±kar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Gradient Boosting modeli\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "# RFE'yi kullanarak Ã¶zellik seÃ§imi yapÄ±n\n",
    "rfe = RFE(clf, n_features_to_select=5)  # Ã–rneÄŸin, 5 Ã¶zellik bÄ±rakmak istiyoruz\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eÄŸitin\n",
    "clf.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Test seti Ã¼zerinde tahminler yapÄ±n\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "y_pred = clf.predict(X_test_rfe)\n",
    "\n",
    "# DoÄŸruluk skorunu deÄŸerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Modelin performansÄ±nÄ± 5 katlÄ± Ã§apraz doÄŸrulama ile deÄŸerlendirin\n",
    "cv_scores = cross_val_score(clf, X_train_rfe, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir Ã§apraz doÄŸrulama seti iÃ§in doÄŸruluk skorlarÄ±nÄ± yazdÄ±r\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: DoÄŸruluk = {score}\")\n",
    "\n",
    "# Ortalama doÄŸruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk:\", mean_accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "879c8fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.model_selection import cross_val_score, StratifiedKFold\\nfrom sklearn.metrics import make_scorer, accuracy_score\\nfrom sklearn.svm import SVC\\nfrom sklearn.feature_selection import SelectKBest, f_classif\\nimport numpy as np\\nfrom itertools import combinations\\n\\ndef kendall_tau(y_true, y_pred):\\n    concordant_pairs = 0\\n    discordant_pairs = 0\\n\\n    n = len(y_true)\\n\\n    for i, j in combinations(range(n), 2):\\n        # Ä°ki Ã§iftin sÄ±ralama durumunu kontrol et\\n        pred_order_diff = np.sign(y_pred[i] - y_pred[j])\\n        true_order_diff = np.sign(y_true[i] - y_true[j])\\n\\n        # Concordant veya discordant durumu kontrol et\\n        if pred_order_diff == true_order_diff:\\n            concordant_pairs += 1\\n        else:\\n            discordant_pairs += 1\\n\\n    # Paydan sÄ±fÄ±r ise nan dÃ¶ndÃ¼r\\n    if (concordant_pairs + discordant_pairs) == 0:\\n        return np.nan\\n\\n    # Kendall Tau Korelasyonu hesapla\\n    tau = (concordant_pairs - discordant_pairs) / np.sqrt((concordant_pairs + discordant_pairs) * n * (n - 1) / 2)\\n\\n    return tau\\n\\n\\n\\n# Ã–nceden belirlenmiÅŸ X ve y\\'yi kullanalÄ±m\\n# X: Ã–zellik matrisi, y: Hedef deÄŸiÅŸken\\nX = imputed_df.drop(\\'Q16\\', axis=1)\\ny = imputed_df[\\'Q16\\']\\n\\n# StratifiedKFold ile 5-fold cross-validation\\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\\n\\n# Rank-SVM modelini tanÄ±mla\\nrank_svm_model = SVC(kernel=\\'linear\\')\\n\\n# Feature selection iÃ§in SelectKBest ve f_classif kullan\\nk_best_features = 5\\nfeature_selector = SelectKBest(score_func=f_classif, k=k_best_features)\\n\\n# 5-fold cross-validation ile modelin performansÄ±nÄ± deÄŸerlendir\\ncv_kendall_tau_scores = cross_val_score(rank_svm_model, X, y, cv=cv, scoring=make_scorer(kendall_tau, greater_is_better=True))\\ncv_accuracy_scores = cross_val_score(rank_svm_model, X, y, cv=cv, scoring=\\'accuracy\\')\\n\\n# Her bir Ã§apraz doÄŸrulama seti iÃ§in skorlarÄ± yazdÄ±r\\nfor i, (kendall_tau, accuracy) in enumerate(zip(cv_kendall_tau_scores, cv_accuracy_scores), start=1):\\n    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: Kendall Tau Korelasyonu = {kendall_tau:.4f}, Accuracy = {accuracy:.4f}\")\\n\\n# Ortalama skorlarÄ± hesapla\\nmean_kendall_tau = np.mean(cv_kendall_tau_scores)\\nmean_accuracy = np.mean(cv_accuracy_scores)\\n\\nprint(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama Kendall Tau Korelasyonu:\", mean_kendall_tau)\\nprint(\"5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama Accuracy:\", mean_accuracy)'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "def kendall_tau(y_true, y_pred):\n",
    "    concordant_pairs = 0\n",
    "    discordant_pairs = 0\n",
    "\n",
    "    n = len(y_true)\n",
    "\n",
    "    for i, j in combinations(range(n), 2):\n",
    "        # Ä°ki Ã§iftin sÄ±ralama durumunu kontrol et\n",
    "        pred_order_diff = np.sign(y_pred[i] - y_pred[j])\n",
    "        true_order_diff = np.sign(y_true[i] - y_true[j])\n",
    "\n",
    "        # Concordant veya discordant durumu kontrol et\n",
    "        if pred_order_diff == true_order_diff:\n",
    "            concordant_pairs += 1\n",
    "        else:\n",
    "            discordant_pairs += 1\n",
    "\n",
    "    # Paydan sÄ±fÄ±r ise nan dÃ¶ndÃ¼r\n",
    "    if (concordant_pairs + discordant_pairs) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    # Kendall Tau Korelasyonu hesapla\n",
    "    tau = (concordant_pairs - discordant_pairs) / np.sqrt((concordant_pairs + discordant_pairs) * n * (n - 1) / 2)\n",
    "\n",
    "    return tau\n",
    "\n",
    "\n",
    "\n",
    "# Ã–nceden belirlenmiÅŸ X ve y'yi kullanalÄ±m\n",
    "# X: Ã–zellik matrisi, y: Hedef deÄŸiÅŸken\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "# StratifiedKFold ile 5-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Rank-SVM modelini tanÄ±mla\n",
    "rank_svm_model = SVC(kernel='linear')\n",
    "\n",
    "# Feature selection iÃ§in SelectKBest ve f_classif kullan\n",
    "k_best_features = 5\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "\n",
    "# 5-fold cross-validation ile modelin performansÄ±nÄ± deÄŸerlendir\n",
    "cv_kendall_tau_scores = cross_val_score(rank_svm_model, X, y, cv=cv, scoring=make_scorer(kendall_tau, greater_is_better=True))\n",
    "cv_accuracy_scores = cross_val_score(rank_svm_model, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Her bir Ã§apraz doÄŸrulama seti iÃ§in skorlarÄ± yazdÄ±r\n",
    "for i, (kendall_tau, accuracy) in enumerate(zip(cv_kendall_tau_scores, cv_accuracy_scores), start=1):\n",
    "    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: Kendall Tau Korelasyonu = {kendall_tau:.4f}, Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "# Ortalama skorlarÄ± hesapla\n",
    "mean_kendall_tau = np.mean(cv_kendall_tau_scores)\n",
    "mean_accuracy = np.mean(cv_accuracy_scores)\n",
    "\n",
    "print(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama Kendall Tau Korelasyonu:\", mean_kendall_tau)\n",
    "print(\"5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama Accuracy:\", mean_accuracy)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "327fc506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.6836\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Yeni_X ve yeni_y verilerini eÄŸitim ve test setlerine bÃ¶lelim\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X, new_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# RandomForestClassifier'Ä± sÄ±nÄ±f aÄŸÄ±rlÄ±klarÄ±yla oluÅŸturun\n",
    "rf_classifier = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Modeli eÄŸitin\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Test seti Ã¼zerinde tahminler yapÄ±n\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# DoÄŸruluk skorunu deÄŸerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e1dfee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from imblearn.over_sampling import SMOTE\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.metrics import accuracy_score\\n\\n# Ã–nceden belirlenmiÅŸ olan X ve y\\'yi kullanalÄ±m\\n# X: Ã–zellik matrisi, y: Hedef deÄŸiÅŸken\\n# Ã–rnek olarak, new_X ve new_y\\'yi kullanalÄ±m\\nX_train, X_test, y_train, y_test = train_test_split(new_X, new_y, test_size=0.2, random_state=42)\\n\\n# SMOTE\\'u kullanarak oversampling\\nsmote = SMOTE(random_state=42)\\nX_resampled, y_resampled = smote.fit_resample(X_train, y_train)\\n\\n# RandomForestClassifier\\'Ä± sÄ±nÄ±f aÄŸÄ±rlÄ±klarÄ±yla oluÅŸturun\\nrf_classifier = RandomForestClassifier(random_state=42)\\n\\n# Modeli eÄŸitin\\nrf_classifier.fit(X_resampled, y_resampled)\\n\\n# Test seti Ã¼zerinde tahminler yapÄ±n\\ny_pred = rf_classifier.predict(X_test)\\n\\n# DoÄŸruluk skorunu deÄŸerlendirin\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(f\"Model Accuracy: {accuracy:.4f}\")'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Ã–nceden belirlenmiÅŸ olan X ve y'yi kullanalÄ±m\n",
    "# X: Ã–zellik matrisi, y: Hedef deÄŸiÅŸken\n",
    "# Ã–rnek olarak, new_X ve new_y'yi kullanalÄ±m\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X, new_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# SMOTE'u kullanarak oversampling\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# RandomForestClassifier'Ä± sÄ±nÄ±f aÄŸÄ±rlÄ±klarÄ±yla oluÅŸturun\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Modeli eÄŸitin\n",
    "rf_classifier.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Test seti Ã¼zerinde tahminler yapÄ±n\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# DoÄŸruluk skorunu deÄŸerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "66cc5ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã‡apraz DoÄŸrulama Seti 1: DoÄŸruluk = 0.6406995230524642\n",
      "Ã‡apraz DoÄŸrulama Seti 2: DoÄŸruluk = 0.6454689984101749\n",
      "Ã‡apraz DoÄŸrulama Seti 3: DoÄŸruluk = 0.6677265500794912\n",
      "Ã‡apraz DoÄŸrulama Seti 4: DoÄŸruluk = 0.64171974522293\n",
      "Ã‡apraz DoÄŸrulama Seti 5: DoÄŸruluk = 0.6257961783439491\n",
      "\n",
      "5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk: 0.644282199021802\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Ã–zellik ve hedef deÄŸiÅŸkeni seÃ§\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "# Z puanlarÄ±na dayalÄ± olarak aykÄ±rÄ± deÄŸerleri ele\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "\n",
    "# Sabit Ã¶zellikleri Ã§Ä±kar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "\n",
    "# GeniÅŸletilmiÅŸ Ã¶zellik setini oluÅŸtur\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Random Forest sÄ±nÄ±flandÄ±rÄ±cÄ± oluÅŸturun\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# 5-fold Ã§apraz doÄŸrulama iÃ§in StratifiedKFold kullanÄ±n\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# GeniÅŸletilmiÅŸ Ã¶zellik seti ve hedef deÄŸiÅŸkeni ile bir pipeline oluÅŸturun\n",
    "model = make_pipeline(PolynomialFeatures(degree=2), RandomForestClassifier())\n",
    "\n",
    "# 5 katlÄ± Ã§apraz doÄŸrulama ile doÄŸruluk skorlarÄ±nÄ± al\n",
    "cv_scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Her bir Ã§apraz doÄŸrulama seti iÃ§in doÄŸruluk skorlarÄ±nÄ± yazdÄ±r\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: DoÄŸruluk = {score}\")\n",
    "\n",
    "# Ortalama doÄŸruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5156c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "# Ã–zellik ve hedef deÄŸiÅŸkeni seÃ§\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "# AykÄ±rÄ± deÄŸerleri ele\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "\n",
    "# Sabit Ã¶zellikleri Ã§Ä±kar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "\n",
    "# GeniÅŸletilmiÅŸ Ã¶zellik setini oluÅŸtur\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Random Forest sÄ±nÄ±flandÄ±rÄ±cÄ± oluÅŸturun\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Parametre aralÄ±ÄŸÄ±nÄ± belirle\n",
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [50, 100, 200],\n",
    "    'randomforestclassifier__max_depth': [None, 10, 20],\n",
    "    'randomforestclassifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Pipeline ve GridSearchCV kullanarak en iyi parametreleri bulun\n",
    "model = make_pipeline(PolynomialFeatures(degree=2), RandomForestClassifier())\n",
    "grid_search = GridSearchCV(model, param_grid, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring='accuracy')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# En iyi parametreleri gÃ¶rÃ¼ntÃ¼leme\n",
    "print(\"En iyi parametreler:\", grid_search.best_params_)\n",
    "\n",
    "# En iyi modeli kullanma\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 5 katlÄ± Ã§apraz doÄŸrulama ile doÄŸruluk skorlarÄ±nÄ± al\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring='accuracy')\n",
    "\n",
    "# Her bir Ã§apraz doÄŸrulama seti iÃ§in doÄŸruluk skorlarÄ±nÄ± yazdÄ±r\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: DoÄŸruluk = {score}\")\n",
    "\n",
    "# Ortalama doÄŸruluk skorunu hesapla\n",
    "mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "print(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "95ed71c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.6963\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from scipy import stats\n",
    "# Ã–zellik ve hedef deÄŸiÅŸkeni seÃ§\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores <3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "# Sabit Ã¶zellikleri Ã§Ä±kar\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1]\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "# Ã–nceden oluÅŸturulmuÅŸ geniÅŸletilmiÅŸ Ã¶zellik setini ve hedef deÄŸiÅŸkeni kullanarak veri setini oluÅŸturun\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest sÄ±nÄ±flandÄ±rÄ±cÄ± oluÅŸturun\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Modeli eÄŸitin\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Test seti Ã¼zerinde tahminler yapÄ±n\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# DoÄŸruluk skorunu deÄŸerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d027631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import pandas as pd\\nfrom sklearn.preprocessing import MinMaxScaler\\n\\n\\nX = imputed_df.drop(target_column, axis=1)\\n\\n# Min-Max normalizasyonu uygulayÄ±n\\nscaler = MinMaxScaler()\\nX_normalized = scaler.fit_transform(X)\\n\\n# Normalizasyon sonrasÄ± veriyi yeni bir veri Ã§erÃ§evesine ekleyin (isteÄŸe baÄŸlÄ±)\\nnormalized_df = pd.DataFrame(X_normalized, columns=X.columns)\\n\\n# Normalizasyon sonrasÄ± veriyi yazdÄ±rÄ±n (isteÄŸe baÄŸlÄ±)\\nprint(normalized_df)'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "X = imputed_df.drop(target_column, axis=1)\n",
    "\n",
    "# Min-Max normalizasyonu uygulayÄ±n\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Normalizasyon sonrasÄ± veriyi yeni bir veri Ã§erÃ§evesine ekleyin (isteÄŸe baÄŸlÄ±)\n",
    "normalized_df = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "\n",
    "# Normalizasyon sonrasÄ± veriyi yazdÄ±rÄ±n (isteÄŸe baÄŸlÄ±)\n",
    "print(normalized_df)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5bcd8792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import pandas as pd\\nfrom sklearn.preprocessing import RobustScaler\\n\\n# Veriyi yÃ¼kleyin veya oluÅŸturun\\n# Ã–rneÄŸin, imputed_df adlÄ± bir veri Ã§erÃ§evesiniz olduÄŸunu varsayalÄ±m\\n\\n# Hedef deÄŸiÅŸkeni (target attribute) ve Ã¶zellikleri ayÄ±rÄ±n\\ntarget_column = 'Q16'\\ny = imputed_df[target_column]\\nX = imputed_df.drop(target_column, axis=1)\\n\\n# Robust Scaler normalizasyonu uygulayÄ±n\\nscaler = RobustScaler()\\nX_normalized = scaler.fit_transform(X)\\n\\n# Normalizasyon sonrasÄ± veriyi yeni bir veri Ã§erÃ§evesine ekleyin (isteÄŸe baÄŸlÄ±)\\nnormalized_df = pd.DataFrame(X_normalized, columns=X.columns)\\n\\n# Normalizasyon sonrasÄ± veriyi yazdÄ±rÄ±n (isteÄŸe baÄŸlÄ±)\\nprint(normalized_df)\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Veriyi yÃ¼kleyin veya oluÅŸturun\n",
    "# Ã–rneÄŸin, imputed_df adlÄ± bir veri Ã§erÃ§evesiniz olduÄŸunu varsayalÄ±m\n",
    "\n",
    "# Hedef deÄŸiÅŸkeni (target attribute) ve Ã¶zellikleri ayÄ±rÄ±n\n",
    "target_column = 'Q16'\n",
    "y = imputed_df[target_column]\n",
    "X = imputed_df.drop(target_column, axis=1)\n",
    "\n",
    "# Robust Scaler normalizasyonu uygulayÄ±n\n",
    "scaler = RobustScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Normalizasyon sonrasÄ± veriyi yeni bir veri Ã§erÃ§evesine ekleyin (isteÄŸe baÄŸlÄ±)\n",
    "normalized_df = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "\n",
    "# Normalizasyon sonrasÄ± veriyi yazdÄ±rÄ±n (isteÄŸe baÄŸlÄ±)\n",
    "print(normalized_df)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9f73e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.feature_selection import f_classif, SelectKBest\\n\\n\\n\\n# F-Score ile en iyi Ã¶zellikleri seÃ§me\\nf_score_selector = SelectKBest(f_classif, k=\\'all\\')\\nX_f_score = f_score_selector.fit_transform(X, y)\\n\\n# F-Score deÄŸerleri\\nf_scores = f_score_selector.scores_\\n\\n# Her bir sÃ¼tun iÃ§in F-Score deÄŸerlerini yazdÄ±rma\\nfor feature, score in zip(X.columns, f_scores):\\n    print(f\"SÃ¼tun: {feature}, F-Score: {score}\")'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from sklearn.feature_selection import f_classif, SelectKBest\n",
    "\n",
    "\n",
    "\n",
    "# F-Score ile en iyi Ã¶zellikleri seÃ§me\n",
    "f_score_selector = SelectKBest(f_classif, k='all')\n",
    "X_f_score = f_score_selector.fit_transform(X, y)\n",
    "\n",
    "# F-Score deÄŸerleri\n",
    "f_scores = f_score_selector.scores_\n",
    "\n",
    "# Her bir sÃ¼tun iÃ§in F-Score deÄŸerlerini yazdÄ±rma\n",
    "for feature, score in zip(X.columns, f_scores):\n",
    "    print(f\"SÃ¼tun: {feature}, F-Score: {score}\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d8d8649",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.model_selection import cross_validate\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.svm import SVC\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\\nfrom sklearn.ensemble import AdaBoostClassifier\\nfrom sklearn.model_selection import StratifiedKFold\\nfrom sklearn.feature_selection import f_classif, SelectKBest\\n\\n# Assuming df is your DataFrame\\ntarget_column = \\'Q16\\'\\n\\n# Assuming \\'X\\' is your feature matrix and \\'y\\' is your target variable\\nX = imputed_df.drop(target_column, axis=1)  # Feature matrix\\ny = imputed_df[target_column]  # Target variable\\n\\n# F-Score ile en iyi Ã¶zellikleri seÃ§me\\nf_score_selector = SelectKBest(f_classif, k=\\'all\\')\\nX_f_score = f_score_selector.fit_transform(X, y)\\n\\n# F-Score deÄŸerleri\\nf_scores = f_score_selector.scores_\\n\\n# SÃ¼tunlarÄ± F-Score deÄŸerlerine gÃ¶re sÄ±rala\\nsorted_features = [feature for _, feature in sorted(zip(f_scores, X.columns), reverse=True)]\\n\\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # Define your cross-validation strategy\\n\\nclassifiers = {\\n    \\'Random Forest\\': RandomForestClassifier(),\\n    \\'Gradient Boosting\\': GradientBoostingClassifier(),\\n    \\'Logistic Regression\\': LogisticRegression(max_iter=1000),  # Increase max_iter to 1000 or more\\n    \\'SVM\\': SVC(),\\n    \\'K-Nearest Neighbors\\': KNeighborsClassifier(),\\n    \\'Decision Tree\\': DecisionTreeClassifier(),\\n    \\'Gaussian Naive Bayes\\': GaussianNB(),\\n    \\'Neural Network\\': MLPClassifier(max_iter=1000), \\n    \\'QDA\\': QuadraticDiscriminantAnalysis(),\\n    \\'AdaBoost\\': AdaBoostClassifier()\\n    # Add more classifiers here\\n}\\n\\n# Define the metric to be evaluated\\nscoring = {\\n    \\'Accuracy\\': \\'accuracy\\',\\n}\\n\\n# Perform 5-fold cross-validation with each classifier using selected features\\nfor clf_name, clf in classifiers.items():\\n    print(f\"Evaluating {clf_name} with F-Score Selected Features:\")\\n    scores = cross_validate(clf, X[sorted_features], y, cv=skf, scoring=scoring)\\n    \\n    acc_mean = scores[\\'test_Accuracy\\'].mean()\\n    \\n    print(f\"Accuracy: {acc_mean:.4f}\")\\n    print(\"-------------------------------------------\")'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "target_column = 'Q16'\n",
    "\n",
    "# Assuming 'X' is your feature matrix and 'y' is your target variable\n",
    "X = imputed_df.drop(target_column, axis=1)  # Feature matrix\n",
    "y = imputed_df[target_column]  # Target variable\n",
    "\n",
    "# F-Score ile en iyi Ã¶zellikleri seÃ§me\n",
    "f_score_selector = SelectKBest(f_classif, k='all')\n",
    "X_f_score = f_score_selector.fit_transform(X, y)\n",
    "\n",
    "# F-Score deÄŸerleri\n",
    "f_scores = f_score_selector.scores_\n",
    "\n",
    "# SÃ¼tunlarÄ± F-Score deÄŸerlerine gÃ¶re sÄ±rala\n",
    "sorted_features = [feature for _, feature in sorted(zip(f_scores, X.columns), reverse=True)]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # Define your cross-validation strategy\n",
    "\n",
    "classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),  # Increase max_iter to 1000 or more\n",
    "    'SVM': SVC(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'Neural Network': MLPClassifier(max_iter=1000), \n",
    "    'QDA': QuadraticDiscriminantAnalysis(),\n",
    "    'AdaBoost': AdaBoostClassifier()\n",
    "    # Add more classifiers here\n",
    "}\n",
    "\n",
    "# Define the metric to be evaluated\n",
    "scoring = {\n",
    "    'Accuracy': 'accuracy',\n",
    "}\n",
    "\n",
    "# Perform 5-fold cross-validation with each classifier using selected features\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"Evaluating {clf_name} with F-Score Selected Features:\")\n",
    "    scores = cross_validate(clf, X[sorted_features], y, cv=skf, scoring=scoring)\n",
    "    \n",
    "    acc_mean = scores['test_Accuracy'].mean()\n",
    "    \n",
    "    print(f\"Accuracy: {acc_mean:.4f}\")\n",
    "    print(\"-------------------------------------------\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091fead4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5554f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\n\\n# Her bir Ã¶zelliÄŸi ve onun F-Score deÄŸerini iÃ§eren bir tuple listesi\\nfeature_score_pairs = list(zip(X.columns, f_scores))\\n\\n# F-Score deÄŸerlerine gÃ¶re sÄ±ralama\\nfeature_score_pairs.sort(key=lambda x: x[1], reverse=True)\\n\\n# En fazla k Ã¶zelliÄŸi seÃ§me (k'i istediÄŸiniz sayÄ±ya ayarlayabilirsiniz)\\nmax_k = 10\\nfor k in range(1, max_k + 1):\\n    # En gÃ¼Ã§lÃ¼ k Ã¶zellikleri seÃ§me\\n    top_k_features = [feature for feature, _ in feature_score_pairs[:k]]\\n    \\n    # SeÃ§ilen en gÃ¼Ã§lÃ¼ Ã¶zelliklere sahip veri Ã§erÃ§evesini oluÅŸturma\\n    selected_df = imputed_df[top_k_features + ['Q16']]\\n    \\n    # Hedef deÄŸiÅŸkeni ve Ã¶zellikleri ayÄ±rma\\n    X_selected = selected_df.drop('Q16', axis=1)\\n    y_selected = selected_df['Q16']\\n    \\n    # Veriyi eÄŸitim ve test setlerine ayÄ±rma\\n    X_train, X_test, y_train, y_test = train_test_split(X_selected, y_selected, test_size=0.2, random_state=42)\\n    \\n    # SÄ±nÄ±flandÄ±rÄ±cÄ± modelini oluÅŸturma (Random Forest kullanÄ±ldÄ±)\\n    classifier = RandomForestClassifier(random_state=42)\\n    classifier.fit(X_train, y_train)\\n    \\n    # Test seti Ã¼zerinde tahmin yapma\\n    y_pred = classifier.predict(X_test)\\n    \\n    # DoÄŸruluk hesapla\\n    accuracy = accuracy_score(y_test, y_pred)\\n    print(f'k={k}, DoÄŸruluk: {accuracy}')\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Her bir Ã¶zelliÄŸi ve onun F-Score deÄŸerini iÃ§eren bir tuple listesi\n",
    "feature_score_pairs = list(zip(X.columns, f_scores))\n",
    "\n",
    "# F-Score deÄŸerlerine gÃ¶re sÄ±ralama\n",
    "feature_score_pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# En fazla k Ã¶zelliÄŸi seÃ§me (k'i istediÄŸiniz sayÄ±ya ayarlayabilirsiniz)\n",
    "max_k = 10\n",
    "for k in range(1, max_k + 1):\n",
    "    # En gÃ¼Ã§lÃ¼ k Ã¶zellikleri seÃ§me\n",
    "    top_k_features = [feature for feature, _ in feature_score_pairs[:k]]\n",
    "    \n",
    "    # SeÃ§ilen en gÃ¼Ã§lÃ¼ Ã¶zelliklere sahip veri Ã§erÃ§evesini oluÅŸturma\n",
    "    selected_df = imputed_df[top_k_features + ['Q16']]\n",
    "    \n",
    "    # Hedef deÄŸiÅŸkeni ve Ã¶zellikleri ayÄ±rma\n",
    "    X_selected = selected_df.drop('Q16', axis=1)\n",
    "    y_selected = selected_df['Q16']\n",
    "    \n",
    "    # Veriyi eÄŸitim ve test setlerine ayÄ±rma\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y_selected, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # SÄ±nÄ±flandÄ±rÄ±cÄ± modelini oluÅŸturma (Random Forest kullanÄ±ldÄ±)\n",
    "    classifier = RandomForestClassifier(random_state=42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Test seti Ã¼zerinde tahmin yapma\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # DoÄŸruluk hesapla\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'k={k}, DoÄŸruluk: {accuracy}')\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "617eb0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"numeric_columns = imputed_df.select_dtypes(include=np.number).columns\\ndf_numeric = imputed_df[numeric_columns].apply(pd.to_numeric)\\n# Veriyi standartlaÅŸtÄ±rÄ±n (PCA, verinin standartlaÅŸtÄ±rÄ±lmÄ±ÅŸ olmasÄ±nÄ± ister)\\nscaler = StandardScaler()\\ndf_scaled = scaler.fit_transform(df_numeric)\\n\\n# PCA modelini oluÅŸturun ve uygulayÄ±n\\npca = PCA()\\npca_result = pca.fit_transform(df_scaled)\\n\\n# Elde edilen bileÅŸenlerin varyans oranlarÄ±nÄ± ve kÃ¼mÃ¼latif varyans oranlarÄ±nÄ± Ã§izin\\nexplained_variance_ratio = pca.explained_variance_ratio_\\ncumulative_explained_variance = np.cumsum(explained_variance_ratio)\\n\\nplt.figure(figsize=(12, 6))\\nplt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, label='Explained Variance Ratio')\\nplt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o', linestyle='--', color='orange', label='Cumulative Explained Variance')\\nplt.title('PCA - Explained Variance')\\nplt.xlabel('Principal Components')\\nplt.ylabel('Variance Ratio')\\nplt.legend()\\nplt.show()\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"numeric_columns = imputed_df.select_dtypes(include=np.number).columns\n",
    "df_numeric = imputed_df[numeric_columns].apply(pd.to_numeric)\n",
    "# Veriyi standartlaÅŸtÄ±rÄ±n (PCA, verinin standartlaÅŸtÄ±rÄ±lmÄ±ÅŸ olmasÄ±nÄ± ister)\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_numeric)\n",
    "\n",
    "# PCA modelini oluÅŸturun ve uygulayÄ±n\n",
    "pca = PCA()\n",
    "pca_result = pca.fit_transform(df_scaled)\n",
    "\n",
    "# Elde edilen bileÅŸenlerin varyans oranlarÄ±nÄ± ve kÃ¼mÃ¼latif varyans oranlarÄ±nÄ± Ã§izin\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, label='Explained Variance Ratio')\n",
    "plt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o', linestyle='--', color='orange', label='Cumulative Explained Variance')\n",
    "plt.title('PCA - Explained Variance')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Variance Ratio')\n",
    "plt.legend()\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac5988f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"plt.figure(figsize=(16, 8))\\nsns.boxplot(data=imputed_df, orient='h', palette='Set2')\\nplt.title('TÃ¼m SayÄ±sal DeÄŸiÅŸkenlerin Box Plot'u')\\nplt.show()\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"plt.figure(figsize=(16, 8))\n",
    "sns.boxplot(data=imputed_df, orient='h', palette='Set2')\n",
    "plt.title('TÃ¼m SayÄ±sal DeÄŸiÅŸkenlerin Box Plot\\'u')\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b738f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# IQR tabanlÄ± aykÄ±rÄ± deÄŸer tespiti\\nQ1 = df_numeric.quantile(0.25)\\nQ3 = df_numeric.quantile(0.75)\\nIQR = Q3 - Q1\\n\\n# AykÄ±rÄ± deÄŸerleri iÃ§eren bir maske oluÅŸturun\\noutlier_mask_iqr = ((df_numeric < (Q1 - 1.5 * IQR)) | (df_numeric > (Q3 + 1.5 * IQR))).any(axis=1)\\n\\n# AykÄ±rÄ± deÄŸerlere sahip olan satÄ±rlarÄ± gÃ¶ster\\noutliers_iqr = df_best_imputed[outlier_mask_iqr]\\nprint(outliers_iqr)\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# IQR tabanlÄ± aykÄ±rÄ± deÄŸer tespiti\n",
    "Q1 = df_numeric.quantile(0.25)\n",
    "Q3 = df_numeric.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# AykÄ±rÄ± deÄŸerleri iÃ§eren bir maske oluÅŸturun\n",
    "outlier_mask_iqr = ((df_numeric < (Q1 - 1.5 * IQR)) | (df_numeric > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "# AykÄ±rÄ± deÄŸerlere sahip olan satÄ±rlarÄ± gÃ¶ster\n",
    "outliers_iqr = df_best_imputed[outlier_mask_iqr]\n",
    "print(outliers_iqr)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a62fe53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# IQR tabanlÄ± outlier'larÄ± tespit etme\\nQ1 = df_numeric.quantile(0.25)\\nQ3 = df_numeric.quantile(0.75)\\nIQR = Q3 - Q1\\n\\n# AykÄ±rÄ± deÄŸerlere sahip olmayan satÄ±rlarÄ± seÃ§me\\ndf_no_outliers_iqr = df_numeric[~((df_numeric < (Q1 - 1.5 * IQR)) | (df_numeric > (Q3 + 1.5 * IQR))).any(axis=1)]\\n\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# IQR tabanlÄ± outlier'larÄ± tespit etme\n",
    "Q1 = df_numeric.quantile(0.25)\n",
    "Q3 = df_numeric.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# AykÄ±rÄ± deÄŸerlere sahip olmayan satÄ±rlarÄ± seÃ§me\n",
    "df_no_outliers_iqr = df_numeric[~((df_numeric < (Q1 - 1.5 * IQR)) | (df_numeric > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a71702b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#outlier Ã§Ä±kardÄ±kran sonra PCA \\nnumeric_columns = df_no_outliers_iqr.select_dtypes(include=np.number).columns\\ndf_numeric = df_no_outliers_iqr[numeric_columns].apply(pd.to_numeric)\\n# Veriyi standartlaÅŸtÄ±rÄ±n (PCA, verinin standartlaÅŸtÄ±rÄ±lmÄ±ÅŸ olmasÄ±nÄ± ister)\\nscaler = StandardScaler()\\ndf_scaled = scaler.fit_transform(df_numeric)\\n\\n# PCA modelini oluÅŸturun ve uygulayÄ±n\\npca = PCA()\\npca_result = pca.fit_transform(df_scaled)\\n\\n# Elde edilen bileÅŸenlerin varyans oranlarÄ±nÄ± ve kÃ¼mÃ¼latif varyans oranlarÄ±nÄ± Ã§izin\\nexplained_variance_ratio = pca.explained_variance_ratio_\\ncumulative_explained_variance = np.cumsum(explained_variance_ratio)\\n\\nplt.figure(figsize=(12, 6))\\nplt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, label='Explained Variance Ratio')\\nplt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o', linestyle='--', color='orange', label='Cumulative Explained Variance')\\nplt.title('PCA - Explained Variance')\\nplt.xlabel('Principal Components')\\nplt.ylabel('Variance Ratio')\\nplt.legend()\\nplt.show()\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#outlier Ã§Ä±kardÄ±kran sonra PCA \n",
    "numeric_columns = df_no_outliers_iqr.select_dtypes(include=np.number).columns\n",
    "df_numeric = df_no_outliers_iqr[numeric_columns].apply(pd.to_numeric)\n",
    "# Veriyi standartlaÅŸtÄ±rÄ±n (PCA, verinin standartlaÅŸtÄ±rÄ±lmÄ±ÅŸ olmasÄ±nÄ± ister)\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_numeric)\n",
    "\n",
    "# PCA modelini oluÅŸturun ve uygulayÄ±n\n",
    "pca = PCA()\n",
    "pca_result = pca.fit_transform(df_scaled)\n",
    "\n",
    "# Elde edilen bileÅŸenlerin varyans oranlarÄ±nÄ± ve kÃ¼mÃ¼latif varyans oranlarÄ±nÄ± Ã§izin\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, label='Explained Variance Ratio')\n",
    "plt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o', linestyle='--', color='orange', label='Cumulative Explained Variance')\n",
    "plt.title('PCA - Explained Variance')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Variance Ratio')\n",
    "plt.legend()\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8a68d756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#Outlier Ã§Ä±kardÄ±kran sonra box plot\\nplt.figure(figsize=(16, 8))\\nsns.boxplot(data=df_no_outliers_iqr, orient='h', palette='Set2')\\nplt.title('TÃ¼m SayÄ±sal DeÄŸiÅŸkenlerin Box Plot'u')\\nplt.show()\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Outlier Ã§Ä±kardÄ±kran sonra box plot\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.boxplot(data=df_no_outliers_iqr, orient='h', palette='Set2')\n",
    "plt.title('TÃ¼m SayÄ±sal DeÄŸiÅŸkenlerin Box Plot\\'u')\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8ce7726f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Normalizasyon\\n# Min-Max normalizasyonu iÃ§in Ã¶lÃ§ekleyiciyi oluÅŸturun\\nscaler = MinMaxScaler()\\n\\n# Normalizasyon iÅŸlemini uygulayÄ±n ve NumPy dizisini DataFrame\\'e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n\\ndf_normalized = pd.DataFrame(scaler.fit_transform(df_no_outliers_iqr), columns=df_no_outliers_iqr.columns)\\n\\n# Veri seti Ã¶zet istatistikleri\\nprint(df_normalized.describe())\\n\\n# Histogramlar\\ndf_normalized.hist(figsize=(10, 8), bins=20)\\nplt.show()\\n\\n# Kutu Grafikleri\\nplt.figure(figsize=(12, 8))\\nsns.boxplot(data=df_normalized)\\nplt.show()\\n\\n# Korelasyon Matrisi\\ncorrelation_matrix = df_normalized.corr()\\nsns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\")\\nplt.show()'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Normalizasyon\n",
    "# Min-Max normalizasyonu iÃ§in Ã¶lÃ§ekleyiciyi oluÅŸturun\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizasyon iÅŸlemini uygulayÄ±n ve NumPy dizisini DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df_no_outliers_iqr), columns=df_no_outliers_iqr.columns)\n",
    "\n",
    "# Veri seti Ã¶zet istatistikleri\n",
    "print(df_normalized.describe())\n",
    "\n",
    "# Histogramlar\n",
    "df_normalized.hist(figsize=(10, 8), bins=20)\n",
    "plt.show()\n",
    "\n",
    "# Kutu Grafikleri\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(data=df_normalized)\n",
    "plt.show()\n",
    "\n",
    "# Korelasyon Matrisi\n",
    "correlation_matrix = df_normalized.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\")\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440d2bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
