{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7db9985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2675bd3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_excel('Course Project - Data for Classification - Electric Vehicles.xls')\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7593525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23070e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df['Q16'].unique()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f0af2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Q16'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5a39c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd25157f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q11_1</th>\n",
       "      <th>Q11_2</th>\n",
       "      <th>Q11_3</th>\n",
       "      <th>Q11_4</th>\n",
       "      <th>Q11_5</th>\n",
       "      <th>Q11_6</th>\n",
       "      <th>Q11_7</th>\n",
       "      <th>Q11_8</th>\n",
       "      <th>Q11_9</th>\n",
       "      <th>Q11_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q18_17</th>\n",
       "      <th>Q18_18</th>\n",
       "      <th>Q18_19</th>\n",
       "      <th>Q18_20</th>\n",
       "      <th>Q18_21</th>\n",
       "      <th>Q18_22</th>\n",
       "      <th>Q18_23</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q11_1  Q11_2  Q11_3  Q11_4  Q11_5  Q11_6  Q11_7  Q11_8  Q11_9  Q11_10  ...  \\\n",
       "0      0      0      0      1      1      0      0      1      0       0  ...   \n",
       "1      1      0      0      1      0      0      1      0      0       1  ...   \n",
       "2      1      1      0      1      0      0      1      1      0       1  ...   \n",
       "3      0      0      0      0      0      0      0      0      0       0  ...   \n",
       "4      1      1      0      1      0      0      1      1      0       1  ...   \n",
       "\n",
       "   Q18_17  Q18_18  Q18_19  Q18_20  Q18_21  Q18_22  Q18_23  Q20  Q21  Q16  \n",
       "0     5.0     5.0     5.0     5.0     5.0     5.0     5.0    3    3    1  \n",
       "1     4.0     2.0     4.0     2.0     2.0     2.0     2.0    3    3    0  \n",
       "2     4.0     4.0     NaN     NaN     4.0     2.0     4.0    4    1    1  \n",
       "3     NaN     NaN     NaN     NaN     NaN     NaN     NaN    3    3    0  \n",
       "4     NaN     NaN     1.0     1.0     NaN     NaN     NaN    3    3    0  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace non-numeric values with NaN\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "df.head()\n",
    "\n",
    "# Assuming you want to replace 'A' with 1 and 'B', 'C', 'D' with 0\n",
    "df['Q16'] = df['Q16'].replace({'A': 1, 'B': 0, 'C': 0, 'D': 0})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "273caba3-4506-4a95-9c97-086c89b07519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Replace '?' with NaN for proper handling\n",
    "df.replace('?', pd.NA, inplace=True)\n",
    "original_df = df.copy()\n",
    "# Specify the imputation strategy (mean or median)\n",
    "strategy = 'mean'  # or 'median'\n",
    "df = df.drop(columns=['Q16'])\n",
    "# Create the imputer\n",
    "imputer = SimpleImputer(strategy=strategy)\n",
    "\n",
    "# Apply imputation\n",
    "imputed_data = imputer.fit_transform(df)\n",
    "\n",
    "# Convert the result back to a DataFrame\n",
    "imputed_df = pd.DataFrame(imputed_data, columns=df.columns)\n",
    "imputed_df['Q16'] = original_df['Q16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe1c6427-068b-4fa1-96bb-bad6d7fcb6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked Features:\n",
      "Q17              0.133749\n",
      "Q14              0.109140\n",
      "Q18_14           0.091056\n",
      "Q18_1            0.071025\n",
      "Q12_14           0.064993\n",
      "                   ...   \n",
      "Q12_Dont_Know    0.000000\n",
      "Q13_13           0.000000\n",
      "Q13_10           0.000000\n",
      "Q13_8            0.000000\n",
      "Q13_9            0.000000\n",
      "Length: 74, dtype: float64\n",
      "Ranked Features:\n",
      "Q17              0.133749\n",
      "Q14              0.109140\n",
      "Q18_14           0.091056\n",
      "Q18_1            0.071025\n",
      "Q12_14           0.064993\n",
      "Q21              0.063983\n",
      "Q13_2            0.049037\n",
      "Q13_16           0.048113\n",
      "Q18_2            0.039923\n",
      "Q18_8            0.037495\n",
      "Q18_10           0.032731\n",
      "Q18_3            0.029614\n",
      "Q18_13           0.026691\n",
      "Q18_17           0.026427\n",
      "Q18_7            0.026211\n",
      "Q18_20           0.024899\n",
      "Q18_11           0.024653\n",
      "Q11_5            0.024515\n",
      "Q18_4            0.023635\n",
      "Q20              0.023464\n",
      "Q18_6            0.023244\n",
      "Q18_5            0.021767\n",
      "Q18_9            0.021243\n",
      "Q18_21           0.019821\n",
      "Q18_15           0.019153\n",
      "Q12_4            0.018581\n",
      "Q12_10           0.018522\n",
      "Q12_2            0.014806\n",
      "Q11_1            0.014027\n",
      "Q12_1            0.012472\n",
      "Q18_16           0.011933\n",
      "Q13_7            0.011578\n",
      "Q12_5            0.011008\n",
      "Q13_5            0.010882\n",
      "Q11_Dont_Know    0.010583\n",
      "Q12_3            0.010326\n",
      "Q18_19           0.009762\n",
      "Q18_23           0.009188\n",
      "Q11_10           0.009100\n",
      "Q13_12           0.008885\n",
      "Q13_6            0.008463\n",
      "Q13_3            0.008341\n",
      "Q18_12           0.008280\n",
      "Q11_13           0.007332\n",
      "Q18_22           0.007027\n",
      "Q12_13           0.006911\n",
      "Q12_9            0.005904\n",
      "Q13_Dont_Know    0.005651\n",
      "Q13_11           0.005000\n",
      "Q11_4            0.004152\n",
      "Q15              0.003718\n",
      "Q13_15           0.003375\n",
      "Q13_14           0.003218\n",
      "Q12_8            0.002833\n",
      "Q11_2            0.002728\n",
      "Q13_1            0.002658\n",
      "Q13_4            0.002289\n",
      "Q11_3            0.002008\n",
      "Q12_12           0.001527\n",
      "Q12_11           0.001406\n",
      "Q18_18           0.000432\n",
      "Q11_6            0.000000\n",
      "Q11_7            0.000000\n",
      "Q12_7            0.000000\n",
      "Q11_8            0.000000\n",
      "Q11_9            0.000000\n",
      "Q11_11           0.000000\n",
      "Q11_12           0.000000\n",
      "Q12_6            0.000000\n",
      "Q12_Dont_Know    0.000000\n",
      "Q13_13           0.000000\n",
      "Q13_10           0.000000\n",
      "Q13_8            0.000000\n",
      "Q13_9            0.000000\n",
      "dtype: float64\n",
      "Non-zero Mutual Information Scores for Features:\n",
      "Q17              0.133749\n",
      "Q14              0.109140\n",
      "Q18_14           0.091056\n",
      "Q18_1            0.071025\n",
      "Q12_14           0.064993\n",
      "Q21              0.063983\n",
      "Q13_2            0.049037\n",
      "Q13_16           0.048113\n",
      "Q18_2            0.039923\n",
      "Q18_8            0.037495\n",
      "Q18_10           0.032731\n",
      "Q18_3            0.029614\n",
      "Q18_13           0.026691\n",
      "Q18_17           0.026427\n",
      "Q18_7            0.026211\n",
      "Q18_20           0.024899\n",
      "Q18_11           0.024653\n",
      "Q11_5            0.024515\n",
      "Q18_4            0.023635\n",
      "Q20              0.023464\n",
      "Q18_6            0.023244\n",
      "Q18_5            0.021767\n",
      "Q18_9            0.021243\n",
      "Q18_21           0.019821\n",
      "Q18_15           0.019153\n",
      "Q12_4            0.018581\n",
      "Q12_10           0.018522\n",
      "Q12_2            0.014806\n",
      "Q11_1            0.014027\n",
      "Q12_1            0.012472\n",
      "Q18_16           0.011933\n",
      "Q13_7            0.011578\n",
      "Q12_5            0.011008\n",
      "Q13_5            0.010882\n",
      "Q11_Dont_Know    0.010583\n",
      "Q12_3            0.010326\n",
      "Q18_19           0.009762\n",
      "Q18_23           0.009188\n",
      "Q11_10           0.009100\n",
      "Q13_12           0.008885\n",
      "Q13_6            0.008463\n",
      "Q13_3            0.008341\n",
      "Q18_12           0.008280\n",
      "Q11_13           0.007332\n",
      "Q18_22           0.007027\n",
      "Q12_13           0.006911\n",
      "Q12_9            0.005904\n",
      "Q13_Dont_Know    0.005651\n",
      "Q13_11           0.005000\n",
      "Q11_4            0.004152\n",
      "Q15              0.003718\n",
      "Q13_15           0.003375\n",
      "Q13_14           0.003218\n",
      "Q12_8            0.002833\n",
      "Q11_2            0.002728\n",
      "Q13_1            0.002658\n",
      "Q13_4            0.002289\n",
      "Q11_3            0.002008\n",
      "Q12_12           0.001527\n",
      "Q12_11           0.001406\n",
      "Q18_18           0.000432\n",
      "Q11_6            0.000000\n",
      "Q11_7            0.000000\n",
      "Q12_7            0.000000\n",
      "Q11_8            0.000000\n",
      "Q11_9            0.000000\n",
      "Q11_11           0.000000\n",
      "Q11_12           0.000000\n",
      "Q12_6            0.000000\n",
      "Q12_Dont_Know    0.000000\n",
      "Q13_13           0.000000\n",
      "Q13_10           0.000000\n",
      "Q13_8            0.000000\n",
      "Q13_9            0.000000\n",
      "dtype: float64\n",
      "        Q17       Q14    Q18_14     Q18_1  Q12_14  Q21  Q13_2  Q13_16  \\\n",
      "0  3.000000  1.000000  5.000000  5.000000     0.0  3.0    0.0     0.0   \n",
      "1  3.000000  3.000000  4.000000  4.000000     0.0  3.0    0.0     0.0   \n",
      "2  1.000000  1.000000  4.000000  5.000000     0.0  1.0    1.0     0.0   \n",
      "3  2.182072  2.383222  3.280962  3.479726     1.0  3.0    0.0     1.0   \n",
      "4  2.182072  2.383222  3.280962  3.479726     0.0  3.0    0.0     0.0   \n",
      "\n",
      "      Q18_2     Q18_8  ...  Q11_9  Q11_11  Q11_12  Q12_6  Q12_Dont_Know  \\\n",
      "0  5.000000  5.000000  ...    0.0     1.0     0.0    0.0            0.0   \n",
      "1  3.000000  3.000000  ...    0.0     0.0     0.0    0.0            0.0   \n",
      "2  3.555279  4.000000  ...    0.0     0.0     0.0    0.0            0.0   \n",
      "3  3.555279  3.185137  ...    0.0     0.0     0.0    0.0            0.0   \n",
      "4  4.000000  3.185137  ...    0.0     1.0     0.0    0.0            0.0   \n",
      "\n",
      "   Q13_13  Q13_10  Q13_8  Q13_9  Q16  \n",
      "0     1.0     0.0    0.0    1.0    1  \n",
      "1     0.0     0.0    0.0    1.0    0  \n",
      "2     0.0     0.0    0.0    1.0    1  \n",
      "3     0.0     0.0    0.0    0.0    0  \n",
      "4     0.0     0.0    0.0    0.0    0  \n",
      "\n",
      "[5 rows x 75 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "###MUTUAL INFO\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "target_column = 'Q16'\n",
    "threshold = 0.01  # Set your desired correlation threshold\n",
    "\n",
    "# Copy the DataFrame to avoid modifying the original\n",
    "imputed_df_copy = imputed_df.copy()\n",
    "\n",
    "# Use mutual_info_classif for feature selection with categorical target\n",
    "X = imputed_df_copy.drop(columns=[target_column])\n",
    "y = imputed_df_copy[target_column]\n",
    "\n",
    "# Calculate mutual information between features and target\n",
    "mutual_info_values = mutual_info_classif(X, y)\n",
    "\n",
    "# Create a Series with feature names and their mutual information scores\n",
    "feature_mutual_info = pd.Series(mutual_info_values, index=X.columns)\n",
    "\n",
    "# Select features based on the mutual information threshold\n",
    "selected_features = feature_mutual_info[feature_mutual_info > threshold].index.tolist()\n",
    "\n",
    "# Rank features by mutual information scores\n",
    "ranked_features = feature_mutual_info.sort_values(ascending=False)\n",
    "\n",
    "# Display the ranked features\n",
    "print(\"Ranked Features:\")\n",
    "print(ranked_features)\n",
    "\n",
    "# Set pandas display options to show all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Print the ranked features\n",
    "print(\"Ranked Features:\")\n",
    "print(ranked_features)\n",
    "\n",
    "\n",
    "non_zero_features = ranked_features[ranked_features >= 0]\n",
    "\n",
    "# Display non-zero features and their mutual information scores\n",
    "print(\"Non-zero Mutual Information Scores for Features:\")\n",
    "print(non_zero_features)\n",
    "pd.reset_option('display.max_rows')\n",
    "\n",
    "non_zero_columns = non_zero_features.index.tolist()\n",
    "\n",
    "# Create a new DataFrame with only the non-zero columns\n",
    "new_df = imputed_df[non_zero_columns].copy()\n",
    "new_df['Q16'] = imputed_df['Q16']\n",
    "print(new_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0883737f-abc1-493c-9374-b70638af2cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dilav\\AppData\\Local\\Temp\\ipykernel_27628\\2977594141.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  new_df = new_df.applymap(lambda x: bin(int(x))[2:] if isinstance(x, (int, float)) else x)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret '<built-in function bin>' as a data type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m new_df \u001b[38;5;241m=\u001b[39m new_df\u001b[38;5;241m.\u001b[39mapplymap(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mbin\u001b[39m(\u001b[38;5;28mint\u001b[39m(x))[\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)) \u001b[38;5;28;01melse\u001b[39;00m x)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Convert to integer to make them binary\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m new_df\u001b[38;5;241m.\u001b[39miloc[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnew_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbin\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m new_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:6534\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6530\u001b[0m     results \u001b[38;5;241m=\u001b[39m [ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[0;32m   6532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6533\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6534\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6535\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    412\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    614\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 616\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    618\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    620\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:232\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    226\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected an instance of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got the class instead. Try instantiating \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m     )\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 232\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[43mpandas_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, NumpyEADtype):\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# Ensure we don't end up with a NumpyExtensionArray\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\common.py:1636\u001b[0m, in \u001b[0;36mpandas_dtype\u001b[1;34m(dtype)\u001b[0m\n\u001b[0;32m   1631\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m   1632\u001b[0m         \u001b[38;5;66;03m# GH#51523 - Series.astype(np.integer) doesn't show\u001b[39;00m\n\u001b[0;32m   1633\u001b[0m         \u001b[38;5;66;03m# numpy deprecation warning of np.integer\u001b[39;00m\n\u001b[0;32m   1634\u001b[0m         \u001b[38;5;66;03m# Hence enabling DeprecationWarning\u001b[39;00m\n\u001b[0;32m   1635\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malways\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m-> 1636\u001b[0m         npdtype \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1637\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1638\u001b[0m     \u001b[38;5;66;03m# np.dtype uses `eval` which can raise SyntaxError\u001b[39;00m\n\u001b[0;32m   1639\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not understood\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot interpret '<built-in function bin>' as a data type"
     ]
    }
   ],
   "source": [
    "new_df.head()\n",
    "\n",
    "\n",
    "\n",
    "scaled_columns = new_df.iloc[:, :-1].apply(lambda x: (x - x.min()) / (x.max() - x.min()) if pd.api.types.is_numeric_dtype(x) else x, axis=0)\n",
    "\n",
    "# Concatenate the original DataFrame with the scaled columns\n",
    "new_df = pd.concat([scaled_columns, new_df['Q16']], axis=1)\n",
    "\n",
    "# Convert values to binary (0 or 1) based on the condition\n",
    "new_df.iloc[:, :-1] = new_df.iloc[:, :-1].apply(lambda x: x.map(lambda val: 1 if pd.notna(val) and float(val) > 0.80 else 0))\n",
    "\n",
    "# Convert to integer to make them binary\n",
    "new_df.iloc[:, :-1] = new_df.iloc[:, :-1].astype(float)\n",
    "\n",
    "\n",
    "new_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24f6f6ad-7ec5-488b-a152-3c9c0319ecf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts:\n",
      "Q16\n",
      "0    3225\n",
      "1    2883\n",
      "Name: count, dtype: int64\n",
      "Total Count of Data: 6108\n",
      "Class Counts after outlier:\n",
      "Q16\n",
      "0    3225\n",
      "1    2883\n",
      "Name: count, dtype: int64\n",
      "Total Count of Data: 6108\n",
      "Class Counts after Class Balancing:\n",
      "Q16\n",
      "1    3225\n",
      "0    3225\n",
      "Name: count, dtype: int64\n",
      "Total Count of Data: 6450\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 64\u001b[0m\n\u001b[0;32m     61\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m  rf_classifier\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# DoÄŸruluk skorunu deÄŸerlendirin\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, RobustScaler\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "\n",
    "# Ã–zellik ve hedef deÄŸiÅŸkeni seÃ§\n",
    "X = new_df.drop('Q16', axis=1)\n",
    "y = new_df['Q16']\n",
    "\n",
    "\n",
    "\n",
    "print(\"Class Counts:\")\n",
    "print(y.value_counts())\n",
    "print(\"Total Count of Data:\", X.shape[0])\n",
    "\n",
    "# # AykÄ±rÄ± deÄŸerleri ele //\n",
    "# z_scores = stats.zscore(X)\n",
    "# abs_z_scores = np.abs(z_scores)\n",
    "# filtered_entries = (abs_z_scores < 5.5).all(axis=1)\n",
    "# X = X[filtered_entries]\n",
    "# y = y[filtered_entries]\n",
    "\n",
    "print(\"Class Counts after outlier:\")\n",
    "print(y.value_counts())\n",
    "print(\"Total Count of Data:\", X.shape[0])\n",
    "\n",
    "# GeniÅŸletilmiÅŸ Ã¶zellik setini oluÅŸtur\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X = poly.fit_transform(X)\n",
    "\n",
    "# Ã–zellikleri RobustScaler ile Ã¶lÃ§eklendirme\n",
    "scaler = RobustScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Apply SMOTE to the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X, y = smote.fit_resample(X, y)\n",
    "\n",
    "print(\"Class Counts after Class Balancing:\")\n",
    "print(y.value_counts())\n",
    "print(\"Total Count of Data:\", X.shape[0])\n",
    "\n",
    "#previosly calculated class weights\n",
    "class_weight_dict = {'A': 0.5246993127147767, 'B': 1.0078382838283828, 'C': 1.6918282548476453, 'D': 1.9575320512820513}\n",
    "\n",
    "# Veriyi train ve test setlerine ayÄ±rma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Create RandomForestClassifier with the best parameters\n",
    "rf_classifier = RandomForestClassifier(max_depth= 10, min_samples_leaf= 2, min_samples_split= 5, n_estimators= 200)\n",
    "\n",
    "# Modeli eÄŸitin\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Test seti Ã¼zerinde tahminler yapÄ±n\n",
    "y_pred =  rf_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# DoÄŸruluk skorunu deÄŸerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Precision, Recall, and F1-score\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# Area under the ROC curve\n",
    "# Note: For multi-class classification, you need to use one-hot encoded labels or a binary problem\n",
    "# Here, assuming binary classification for demonstration\n",
    "roc_auc = roc_auc_score(y_test, rf_classifier.predict_proba(X_test), multi_class='ovr')\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "\n",
    "# # Cross-validation\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# cv_accuracy = cross_val_score(rf_classifier, X, y, cv=cv, scoring='accuracy')\n",
    "# cv_precision = cross_val_score(rf_classifier, X, y, cv=cv, scoring='precision_weighted')\n",
    "# cv_recall = cross_val_score(rf_classifier, X, y, cv=cv, scoring='recall_weighted')\n",
    "# cv_f1 = cross_val_score(rf_classifier, X, y, cv=cv, scoring='f1_weighted')\n",
    "\n",
    "# print(f\"Cross-Validation Accuracy: {cv_accuracy.mean():.4f}\")\n",
    "# print(f\"Cross-Validation Precision: {cv_precision.mean():.4f}\")\n",
    "# print(f\"Cross-Validation Recall: {cv_recall.mean():.4f}\")\n",
    "# print(f\"Cross-Validation F1-score: {cv_f1.mean():.4f}\")\n",
    "\n",
    "# print(f\"Cross-Validation ROC AUC: {cv_roc_auc.mean():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c6d888-103a-468a-a9d3-8fc100adc352",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
