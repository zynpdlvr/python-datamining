{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7db9985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2675bd3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_excel('Course Project - Data for Classification - Electric Vehicles.xls')\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7593525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23070e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df['Q16'].unique()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f0af2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Q16'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5a39c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd25157f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q11_1</th>\n",
       "      <th>Q11_2</th>\n",
       "      <th>Q11_3</th>\n",
       "      <th>Q11_4</th>\n",
       "      <th>Q11_5</th>\n",
       "      <th>Q11_6</th>\n",
       "      <th>Q11_7</th>\n",
       "      <th>Q11_8</th>\n",
       "      <th>Q11_9</th>\n",
       "      <th>Q11_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q18_17</th>\n",
       "      <th>Q18_18</th>\n",
       "      <th>Q18_19</th>\n",
       "      <th>Q18_20</th>\n",
       "      <th>Q18_21</th>\n",
       "      <th>Q18_22</th>\n",
       "      <th>Q18_23</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q11_1  Q11_2  Q11_3  Q11_4  Q11_5  Q11_6  Q11_7  Q11_8  Q11_9  Q11_10  ...  \\\n",
       "0      0      0      0      1      1      0      0      1      0       0  ...   \n",
       "1      1      0      0      1      0      0      1      0      0       1  ...   \n",
       "2      1      1      0      1      0      0      1      1      0       1  ...   \n",
       "3      0      0      0      0      0      0      0      0      0       0  ...   \n",
       "4      1      1      0      1      0      0      1      1      0       1  ...   \n",
       "\n",
       "   Q18_17  Q18_18  Q18_19  Q18_20  Q18_21  Q18_22  Q18_23  Q20  Q21  Q16  \n",
       "0     5.0     5.0     5.0     5.0     5.0     5.0     5.0    3    3    A  \n",
       "1     4.0     2.0     4.0     2.0     2.0     2.0     2.0    3    3    D  \n",
       "2     4.0     4.0     NaN     NaN     4.0     2.0     4.0    4    1    A  \n",
       "3     NaN     NaN     NaN     NaN     NaN     NaN     NaN    3    3    C  \n",
       "4     NaN     NaN     1.0     1.0     NaN     NaN     NaN    3    3    D  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace non-numeric values with NaN\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36ed904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'exclude_column_name' is the column to exclude\n",
    "exclude_column_name = 'Q16'\n",
    "column_to_exclude = df[exclude_column_name]\n",
    "\n",
    "# Create a list of k values\n",
    "k_values = [1, 3, 5, 7, 9,11]\n",
    "\n",
    "# Loop through each k value\n",
    "for k in k_values:\n",
    "    # Drop the column you want to exclude\n",
    "    columns_to_impute = df.drop(columns=[exclude_column_name])\n",
    "    \n",
    "    # Apply KNN imputation for the current k value\n",
    "    imputer = KNNImputer(n_neighbors=k)\n",
    "    imputed_data = imputer.fit_transform(columns_to_impute)\n",
    "    \n",
    "    \n",
    "    imputed_df = pd.DataFrame(imputed_data, columns=columns_to_impute.columns)\n",
    "    imputed_df[exclude_column_name] = column_to_exclude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0883737f-abc1-493c-9374-b70638af2cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q11_1</th>\n",
       "      <th>Q11_2</th>\n",
       "      <th>Q11_3</th>\n",
       "      <th>Q11_4</th>\n",
       "      <th>Q11_5</th>\n",
       "      <th>Q11_6</th>\n",
       "      <th>Q11_7</th>\n",
       "      <th>Q11_8</th>\n",
       "      <th>Q11_9</th>\n",
       "      <th>Q11_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q18_17</th>\n",
       "      <th>Q18_18</th>\n",
       "      <th>Q18_19</th>\n",
       "      <th>Q18_20</th>\n",
       "      <th>Q18_21</th>\n",
       "      <th>Q18_22</th>\n",
       "      <th>Q18_23</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q11_1  Q11_2  Q11_3  Q11_4  Q11_5  Q11_6  Q11_7  Q11_8  Q11_9  Q11_10  ...  \\\n",
       "0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    1.0    0.0     0.0  ...   \n",
       "1    1.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0     1.0  ...   \n",
       "2    1.0    1.0    0.0    1.0    0.0    0.0    1.0    1.0    0.0     1.0  ...   \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0  ...   \n",
       "4    1.0    1.0    0.0    1.0    0.0    0.0    1.0    1.0    0.0     1.0  ...   \n",
       "\n",
       "   Q18_17  Q18_18  Q18_19  Q18_20  Q18_21  Q18_22  Q18_23  Q20  Q21  Q16  \n",
       "0     1.0     1.0     1.0     1.0     1.0     1.0     1.0  0.0  0.0    A  \n",
       "1     1.0     0.0     1.0     0.0     0.0     0.0     0.0  0.0  0.0    D  \n",
       "2     1.0     1.0     1.0     0.0     1.0     0.0     1.0  1.0  0.0    A  \n",
       "3     0.0     0.0     0.0     1.0     0.0     0.0     0.0  0.0  0.0    C  \n",
       "4     0.0     0.0     0.0     0.0     0.0     0.0     0.0  0.0  0.0    D  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_df.head()\n",
    "scaled_columns = imputed_df.iloc[:, :-1].apply(lambda x: (x - x.min()) / (x.max() - x.min()) if pd.api.types.is_numeric_dtype(x) else x, axis=0)\n",
    "\n",
    "# Concatenate the original DataFrame with the scaled columns\n",
    "imputed_df = pd.concat([scaled_columns, imputed_df['Q16']], axis=1)\n",
    "\n",
    "# Convert values to binary (0 or 1) based on the condition\n",
    "imputed_df.iloc[:, :-1] = imputed_df.iloc[:, :-1].apply(lambda x: x.map(lambda val: 1 if pd.notna(val) and float(val) > 0.70 else 0))\n",
    "\n",
    "# Convert to integer to make them binary\n",
    "imputed_df.iloc[:, :-1] = imputed_df.iloc[:, :-1].astype(int)\n",
    "\n",
    "\n",
    "imputed_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24f6f6ad-7ec5-488b-a152-3c9c0319ecf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.6497\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, RobustScaler\n",
    "from scipy import stats\n",
    "\n",
    "# Ã–zellik ve hedef deÄŸiÅŸkeni seÃ§\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "# AykÄ±rÄ± deÄŸerleri ele\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "\n",
    "# GeniÅŸletilmiÅŸ Ã¶zellik setini oluÅŸtur\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Ã–zellikleri RobustScaler ile Ã¶lÃ§eklendirme\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X_poly)\n",
    "\n",
    "# Veriyi train ve test setlerine ayÄ±rma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Create RandomForestClassifier with the best parameters\n",
    "rf_classifier = RandomForestClassifier(max_depth= 10, min_samples_leaf= 2, min_samples_split= 5, n_estimators= 200)\n",
    "\n",
    "# Modeli eÄŸitin\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Test seti Ã¼zerinde tahminler yapÄ±n\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# DoÄŸruluk skorunu deÄŸerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5e88f40-05bc-4e4c-a72f-2e0214a31c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.preprocessing import PolynomialFeatures\\nfrom sklearn.feature_selection import RFECV\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.model_selection import train_test_split, cross_val_score\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Ã–zellik ve hedef deÄŸiÅŸkeni seÃ§\\nX = imputed_df.drop(\\'Q16\\', axis=1)\\ny = imputed_df[\\'Q16\\']\\n\\n# AykÄ±rÄ± deÄŸerleri ele\\nz_scores = stats.zscore(X)\\nabs_z_scores = np.abs(z_scores)\\nfiltered_entries = (abs_z_scores < 3).all(axis=1)\\nX = X[filtered_entries]\\ny = y[filtered_entries]\\n\\n# GeniÅŸletilmiÅŸ Ã¶zellik setini oluÅŸtur\\npoly = PolynomialFeatures(degree=2)\\nX_poly = poly.fit_transform(X)\\n\\n# Ã–zellikleri RobustScaler ile Ã¶lÃ§eklendirme\\nscaler = StandardScaler()\\nX_scaled = scaler.fit_transform(X_poly)\\n\\n# Veriyi train ve test setlerine ayÄ±rma\\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\\n\\n# Logistic Regression modeli\\nlogreg = LogisticRegression(max_iter=1000)\\n\\n# RFECV\\'yi kullanarak Ã¶zellik seÃ§imi yapÄ±n\\nrfecv = RFECV(estimator=logreg, step=1, cv=5, scoring=\\'accuracy\\')  # cv=5, 5-fold cross-validation kullanÄ±yoruz\\nX_train_rfecv = rfecv.fit_transform(X_train, y_train)\\n\\n# Modeli eÄŸitin\\nlogreg.fit(X_train_rfecv, y_train)\\n\\n# Test seti Ã¼zerinde tahminler yapÄ±n\\nX_test_rfecv = rfecv.transform(X_test)\\ny_pred = logreg.predict(X_test_rfecv)\\n\\n# DoÄŸruluk skorunu deÄŸerlendirin\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(f\"Logistic Regression Model Accuracy with RFECV: {accuracy:.4f}\")\\n\\n# Modelin performansÄ±nÄ± 5 katlÄ± Ã§apraz doÄŸrulama ile deÄŸerlendirin\\ncv_scores = cross_val_score(logreg, X_train_rfecv, y_train, cv=5, scoring=\\'accuracy\\')\\n\\n# Her bir Ã§apraz doÄŸrulama seti iÃ§in doÄŸruluk skorlarÄ±nÄ± yazdÄ±r\\nfor i, score in enumerate(cv_scores, start=1):\\n    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: DoÄŸruluk = {score}\")\\n\\n# Ortalama doÄŸruluk skorunu hesapla\\nmean_accuracy = cv_scores.mean()\\n\\nprint(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk:\", mean_accuracy)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Ã–zellik ve hedef deÄŸiÅŸkeni seÃ§\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "# AykÄ±rÄ± deÄŸerleri ele\n",
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "X = X[filtered_entries]\n",
    "y = y[filtered_entries]\n",
    "\n",
    "# GeniÅŸletilmiÅŸ Ã¶zellik setini oluÅŸtur\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Ã–zellikleri RobustScaler ile Ã¶lÃ§eklendirme\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_poly)\n",
    "\n",
    "# Veriyi train ve test setlerine ayÄ±rma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression modeli\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# RFECV'yi kullanarak Ã¶zellik seÃ§imi yapÄ±n\n",
    "rfecv = RFECV(estimator=logreg, step=1, cv=5, scoring='accuracy')  # cv=5, 5-fold cross-validation kullanÄ±yoruz\n",
    "X_train_rfecv = rfecv.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eÄŸitin\n",
    "logreg.fit(X_train_rfecv, y_train)\n",
    "\n",
    "# Test seti Ã¼zerinde tahminler yapÄ±n\n",
    "X_test_rfecv = rfecv.transform(X_test)\n",
    "y_pred = logreg.predict(X_test_rfecv)\n",
    "\n",
    "# DoÄŸruluk skorunu deÄŸerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Model Accuracy with RFECV: {accuracy:.4f}\")\n",
    "\n",
    "# Modelin performansÄ±nÄ± 5 katlÄ± Ã§apraz doÄŸrulama ile deÄŸerlendirin\n",
    "cv_scores = cross_val_score(logreg, X_train_rfecv, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Her bir Ã§apraz doÄŸrulama seti iÃ§in doÄŸruluk skorlarÄ±nÄ± yazdÄ±r\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Ã‡apraz DoÄŸrulama Seti {i}: DoÄŸruluk = {score}\")\n",
    "\n",
    "# Ortalama doÄŸruluk skorunu hesapla\n",
    "mean_accuracy = cv_scores.mean()\n",
    "\n",
    "print(\"\\n5 KatlÄ± Ã‡apraz DoÄŸrulama Ä°le Ortalama DoÄŸruluk:\", mean_accuracy)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d767b487-8642-4e64-bd93-881c1e521545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Accuracy with RFECV: 0.6820\n",
      "Logistic Regression Model Accuracy with RFECV and Scaling: 0.6820\n",
      "Random Forest Model Accuracy: 0.6868\n",
      "Gradient Boosting Model Accuracy: 0.6916\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Ã–nceden belirlenmiÅŸ X ve y'yi kullanalÄ±m\n",
    "# X: Ã–zellik matrisi, y: Hedef deÄŸiÅŸken\n",
    "# Ã–rneÄŸin, new_X ve new_y'yi kullanalÄ±m\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression modeli\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# RFECV'yi kullanarak Ã¶zellik seÃ§imi yapÄ±n\n",
    "rfecv = RFECV(estimator=logreg, step=1, cv=5, scoring='accuracy')  # cv=5, 5-fold cross-validation kullanÄ±yoruz\n",
    "X_train_rfecv = rfecv.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eÄŸitin\n",
    "logreg.fit(X_train_rfecv, y_train)\n",
    "\n",
    "# Test seti Ã¼zerinde tahminler yapÄ±n\n",
    "X_test_rfecv = rfecv.transform(X_test)\n",
    "y_pred = logreg.predict(X_test_rfecv)\n",
    "\n",
    "# DoÄŸruluk skorunu deÄŸerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Model Accuracy with RFECV: {accuracy:.4f}\")\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_rfecv)\n",
    "X_test_scaled = scaler.transform(X_test_rfecv)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "y_pred_scaled = logreg.predict(X_test_scaled)\n",
    "\n",
    "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
    "print(f\"Logistic Regression Model Accuracy with RFECV and Scaling: {accuracy_scaled:.4f}\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Model Accuracy: {accuracy_rf:.4f}\")\n",
    "\n",
    "# Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "print(f\"Gradient Boosting Model Accuracy: {accuracy_gb:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f9afc2e-686a-469c-b5fa-95bc98a284c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Accuracy with RFECV: 0.6820\n",
      "Logistic Regression Model Accuracy with RFECV and Scaling: 0.6820\n",
      "Random Forest Model Accuracy with MinMax Scaling: 0.6868\n",
      "Gradient Boosting Model Accuracy with MinMax Scaling: 0.6916\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Ã–nceden belirlenmiÅŸ X ve y'yi kullanalÄ±m\n",
    "# X: Ã–zellik matrisi, y: Hedef deÄŸiÅŸken\n",
    "# Ã–rneÄŸin, new_X ve new_y'yi kullanalÄ±m\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression modeli\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# RFECV'yi kullanarak Ã¶zellik seÃ§imi yapÄ±n\n",
    "rfecv = RFECV(estimator=logreg, step=1, cv=5, scoring='accuracy')  # cv=5, 5-fold cross-validation kullanÄ±yoruz\n",
    "X_train_rfecv = rfecv.fit_transform(X_train, y_train)\n",
    "\n",
    "# Modeli eÄŸitin\n",
    "logreg.fit(X_train_rfecv, y_train)\n",
    "\n",
    "# Test seti Ã¼zerinde tahminler yapÄ±n\n",
    "X_test_rfecv = rfecv.transform(X_test)\n",
    "y_pred = logreg.predict(X_test_rfecv)\n",
    "\n",
    "# DoÄŸruluk skorunu deÄŸerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Model Accuracy with RFECV: {accuracy:.4f}\")\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_rfecv)\n",
    "X_test_scaled = scaler.transform(X_test_rfecv)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "y_pred_scaled = logreg.predict(X_test_scaled)\n",
    "\n",
    "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
    "print(f\"Logistic Regression Model Accuracy with RFECV and Scaling: {accuracy_scaled:.4f}\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Model Accuracy with MinMax Scaling: {accuracy_rf:.4f}\")\n",
    "\n",
    "# Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "print(f\"Gradient Boosting Model Accuracy with MinMax Scaling: {accuracy_gb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00a1ce8d-1885-4cd1-922b-c6aac67d6f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weighted Class Counts:\n",
      "  Class  Weighted Count\n",
      "0     A     1512.708119\n",
      "1     D     1537.961221\n",
      "2     C     1509.110803\n",
      "3     B     1579.728365\n",
      "Random Forest Accuracy with Class Weights: 0.6375\n",
      "SVC Accuracy with Class Weights: 0.6170\n",
      "Logistic Regression Model Accuracy with RFECV: 0.5835\n",
      "Logistic Regression Model Accuracy with RFECV and Scaling: 0.5827\n",
      "Random Forest Model Accuracy with MinMax Scaling: 0.6105\n",
      "Gradient Boosting Model Accuracy with MinMax Scaling: 0.6620\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "\n",
    "\n",
    "# Extract features and target variable\n",
    "X = imputed_df.drop('Q16', axis=1)\n",
    "y = imputed_df['Q16']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "##################################################################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have already calculated class weights\n",
    "class_weight_dict = {'A': 0.5246993127147767, 'B': 1.0078382838283828, 'C': 1.6918282548476453, 'D': 1.9575320512820513}\n",
    "class_counts = Counter(y)\n",
    "weighted_counts_df = pd.DataFrame({'Class': list(class_counts.keys()), 'Weighted Count': [class_counts[class_] * weight for class_, weight in class_weight_dict.items()]})\n",
    "print(\"\\nWeighted Class Counts:\")\n",
    "print(weighted_counts_df)\n",
    "# Random Forest Classifier with class weights\n",
    "rf_classifier = RandomForestClassifier(random_state=42, class_weight=class_weight_dict)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy with Class Weights: {accuracy_rf:.4f}\")\n",
    "\n",
    "# Support Vector Classifier (SVC) with class weights\n",
    "svc_classifier = SVC(random_state=42, class_weight=class_weight_dict)\n",
    "svc_classifier.fit(X_train, y_train)\n",
    "y_pred_svc = svc_classifier.predict(X_test)\n",
    "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
    "print(f\"SVC Accuracy with Class Weights: {accuracy_svc:.4f}\")\n",
    "\n",
    "##################################################################\n",
    "\n",
    "\n",
    "# Logistic Regression modeli\n",
    "logreg = LogisticRegression(max_iter=1000, class_weight=class_weight_dict)\n",
    "\n",
    "# RFECV'yi kullanarak Ã¶zellik seÃ§imi yapÄ±n\n",
    "rfecv = RFECV(estimator=logreg, step=1, cv=5, scoring='accuracy')  # cv=5, 5-fold cross-validation kullanÄ±yoruz\n",
    "X_train_rfecv = rfecv.fit_transform(X_train, y_train)\n",
    "\n",
    "quantile_transformer = QuantileTransformer(output_distribution='normal',random_state=0)\n",
    "X_train_quantile = quantile_transformer.fit_transform(X_train_rfecv)\n",
    "X_test_quantile = quantile_transformer.transform(rfecv.transform(X_test))\n",
    "\n",
    "\n",
    "# Modeli eÄŸitin\n",
    "logreg.fit(X_train_quantile, y_train)\n",
    "\n",
    "# Test seti Ã¼zerinde tahminler yapÄ±n\n",
    "X_test_rfecv = rfecv.transform(X_test)\n",
    "y_pred = logreg.predict(X_test_quantile)\n",
    "\n",
    "# DoÄŸruluk skorunu deÄŸerlendirin\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Model Accuracy with RFECV: {accuracy:.4f}\")\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_quantile)\n",
    "X_test_scaled = scaler.transform(X_test_quantile)\n",
    "\n",
    "\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "y_pred_scaled = logreg.predict(X_test_scaled)\n",
    "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
    "print(f\"Logistic Regression Model Accuracy with RFECV and Scaling: {accuracy_scaled:.4f}\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Model Accuracy with MinMax Scaling: {accuracy_rf:.4f}\")\n",
    "\n",
    "# Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test_scaled)\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "print(f\"Gradient Boosting Model Accuracy with MinMax Scaling: {accuracy_gb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0758ec-2671-4a03-9013-e2be640cad7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
